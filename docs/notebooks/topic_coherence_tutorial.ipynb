{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration of the topic coherence pipeline in Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the `u_mass` and `c_v` coherence for two different LDA models: a \"good\" and a \"bad\" LDA model. The good LDA model will be trained over 50 iterations and the bad one for 1 iteration. Hence in theory, the good LDA model will be able come up with better or more human-understandable topics. Therefore the coherence measure output for the good LDA model should be more (better) than that for the bad LDA model. This is because, simply, the good LDA model usually comes up with better topics that are more human interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssreehari10/anaconda2/envs/gensim2/lib/python3.5/site-packages/funcy/decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "/home/ssreehari10/anaconda2/envs/gensim2/lib/python3.5/site-packages/funcy/decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "/home/ssreehari10/anaconda2/envs/gensim2/lib/python3.5/site-packages/funcy/decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "/home/ssreehari10/anaconda2/envs/gensim2/lib/python3.5/site-packages/funcy/decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "/home/ssreehari10/anaconda2/envs/gensim2/lib/python3.5/site-packages/funcy/decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "/home/ssreehari10/anaconda2/envs/gensim2/lib/python3.5/site-packages/funcy/decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "try:\n",
    "    import pyLDAvis.gensim\n",
    "except ImportError:\n",
    "    ValueError(\"SKIP: please install pyLDAvis\")\n",
    "    \n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # To ignore all warnings that arise here to enhance clarity\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.hdpmodel import HdpModel\n",
    "from gensim.models.wrappers import LdaVowpalWabbit, LdaMallet\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:test\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.debug(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated in table 2 from [this](http://www.cs.bham.ac.uk/~pxt/IDA/lsa_ind.pdf) paper, this corpus essentially has two classes of documents. First five are about human-computer interaction and the other four are about graphs. We will be setting up two LDA models. One with 50 iterations of training and the other with just 1. Hence the one with 50 iterations (\"better\" model) should be able to capture this underlying pattern of the corpus better than the \"bad\" LDA model. Therefore, in theory, our topic coherence for the good LDA model should be greater than the one for the bad LDA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = [['human', 'interface', 'computer'],\n",
    "         ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
    "         ['eps', 'user', 'interface', 'system'],\n",
    "         ['system', 'human', 'system', 'eps'],\n",
    "         ['user', 'response', 'time'],\n",
    "         ['trees'],\n",
    "         ['graph', 'trees'],\n",
    "         ['graph', 'minors', 'trees'],\n",
    "         ['graph', 'minors', 'survey']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.corpora.dictionary:adding document #0 to Dictionary(0 unique tokens: [])\n",
      "INFO:gensim.corpora.dictionary:built Dictionary(12 unique tokens: ['trees', 'system', 'response', 'computer', 'graph']...) from 9 documents (total 29 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up two topic models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be setting up two different LDA Topic models. A good one and bad one. To build a \"good\" topic model, we'll simply train it using more iterations than the bad one. Therefore the `u_mass` coherence should in theory be better for the good model than the bad one since it would be producing more \"human-interpretable\" topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:using symmetric alpha at 0.5\n",
      "INFO:gensim.models.ldamodel:using symmetric eta at 0.5\n",
      "INFO:gensim.models.ldamodel:using serial LDA version on this node\n",
      "INFO:gensim.models.ldamodel:running online LDA training, 2 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-3.599 per-word bound, 12.1 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 0, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:6/9 documents converged within 50 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.146*system + 0.117*graph + 0.116*trees + 0.103*minors + 0.089*user + 0.087*eps + 0.073*human + 0.071*survey + 0.057*interface + 0.050*computer\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.107*user + 0.102*time + 0.101*response + 0.097*system + 0.097*computer + 0.090*interface + 0.079*trees + 0.077*graph + 0.075*survey + 0.073*human\n",
      "INFO:gensim.models.ldamodel:topic diff=0.375490, rho=1.000000\n",
      "INFO:gensim.models.ldamodel:using symmetric alpha at 0.5\n",
      "INFO:gensim.models.ldamodel:using symmetric eta at 0.5\n",
      "INFO:gensim.models.ldamodel:using serial LDA version on this node\n",
      "INFO:gensim.models.ldamodel:running online LDA training, 2 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "DEBUG:gensim.models.ldamodel:bound: at document #0\n",
      "INFO:gensim.models.ldamodel:-3.598 per-word bound, 12.1 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 0, at document #9/9\n",
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:0/9 documents converged within 1 iterations\n",
      "DEBUG:gensim.models.ldamodel:updating topics\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.500): 0.121*system + 0.108*user + 0.101*graph + 0.091*trees + 0.079*interface + 0.078*human + 0.076*response + 0.074*minors + 0.072*survey + 0.072*computer\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.500): 0.123*system + 0.104*trees + 0.094*graph + 0.087*user + 0.086*time + 0.080*eps + 0.075*computer + 0.074*survey + 0.072*minors + 0.070*response\n",
      "INFO:gensim.models.ldamodel:topic diff=0.246156, rho=1.000000\n"
     ]
    }
   ],
   "source": [
    "goodLdaModel = LdaModel(corpus=corpus, id2word=dictionary, iterations=50, num_topics=2)\n",
    "badLdaModel = LdaModel(corpus=corpus, id2word=dictionary, iterations=1, num_topics=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using U_Mass Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "goodcm = CoherenceModel(model=goodLdaModel, corpus=corpus, dictionary=dictionary, coherence='u_mass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "badcm = CoherenceModel(model=badLdaModel, corpus=corpus, dictionary=dictionary, coherence='u_mass')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the pipeline parameters for one coherence model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are the pipeline parameters for `u_mass` coherence. By pipeline parameters, we mean the functions being used to calculate segmentation, probability estimation, confirmation measure and aggregation as shown in figure 1 in [this](http://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf) paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence_Measure(seg=<function s_one_pre at 0x7f90272c4620>, prob=<function p_boolean_document at 0x7f90272c4b70>, conf=<function log_conditional_probability at 0x7f90272c4c80>, aggr=<function arithmetic_mean at 0x7f90272c4f28>)\n"
     ]
    }
   ],
   "source": [
    "print(goodcm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will see below using LDA visualization, the better model comes up with two topics composed of the following words:\n",
    "1. goodLdaModel:\n",
    "    - __Topic 1__: More weightage assigned to words such as \"system\", \"user\", \"eps\", \"interface\" etc which captures the first set of documents.\n",
    "    - __Topic 2__: More weightage assigned to words such as \"graph\", \"trees\", \"survey\" which captures the topic in the second set of documents.\n",
    "2. badLdaModel:\n",
    "    - __Topic 1__: More weightage assigned to words such as \"system\", \"user\", \"trees\", \"graph\" which doesn't make the topic clear enough.\n",
    "    - __Topic 2__: More weightage assigned to words such as \"system\", \"trees\", \"graph\", \"user\" which is similar to the first topic. Hence both topics are not human-interpretable.\n",
    "\n",
    "Therefore, the topic coherence for the goodLdaModel should be greater for this than the badLdaModel since the topics it comes up with are more human-interpretable. We will see this using `u_mass` and `c_v` topic coherence measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize topic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:9/9 documents converged within 50 iterations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el171681402571202530569366540980\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el171681402571202530569366540980_data = {\"plot.opts\": {\"ylab\": \"PC2\", \"xlab\": \"PC1\"}, \"lambda.step\": 0.01, \"mdsDat\": {\"cluster\": [1, 1], \"topics\": [1, 2], \"Freq\": [50.900004571039304, 49.099995428960696], \"x\": [0.01549283841989717, -0.01549283841989717], \"y\": [0.0, 0.0]}, \"token.table\": {\"Topic\": [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2], \"Term\": [\"computer\", \"computer\", \"eps\", \"eps\", \"graph\", \"graph\", \"human\", \"human\", \"interface\", \"interface\", \"minors\", \"minors\", \"response\", \"response\", \"survey\", \"survey\", \"system\", \"system\", \"time\", \"time\", \"trees\", \"trees\", \"user\", \"user\"], \"Freq\": [0.4726108789619547, 0.4726108789619547, 0.47048111248291197, 0.47048111248291197, 0.7056361283484688, 0.3528180641742344, 0.47128084432737966, 0.47128084432737966, 0.47218718475528826, 0.47218718475528826, 0.9391844743410963, 0.46959223717054815, 0.4728191016498241, 0.4728191016498241, 0.4713635871397365, 0.4713635871397365, 0.5645276169484541, 0.28226380847422705, 0.4728562536259848, 0.4728562536259848, 0.7057119256608728, 0.3528559628304364, 0.353730407455544, 0.707460814911088]}, \"topic.order\": [1, 2], \"tinfo\": {\"Total\": [2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.1295070932716813, 2.834321996353802, 3.5427850471000357, 2.8340175747024183, 2.1254838365829625, 2.121877033697853, 2.1215045609866943, 2.8270116985226315, 2.1178041935175593, 2.1159055885391505, 2.1149737743476633, 2.114807602377551, 2.114807602377551, 2.1149737743476633, 2.1159055885391505, 2.1178041935175593, 2.8270116985226315, 2.1215045609866943, 2.121877033697853, 2.1254838365829625, 2.8340175747024183, 3.5427850471000357, 2.834321996353802, 2.1295070932716813], \"logprob\": [12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.276, -2.143, -1.923, -2.1532, -2.4422, -2.6189, -2.6391, -2.422, -2.8653, -3.0048, -3.0811, -3.0953, -2.2867, -2.2932, -2.3307, -2.4116, -2.2392, -2.591, -2.6109, -2.8283, -2.5426, -2.3302, -2.5582, -3.1443], \"Freq\": [2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.5158314897036804, 1.7315521264296088, 2.157666741433196, 1.7139956873252489, 1.2838044287656616, 1.0757948639866772, 1.0543138213546563, 1.3099566251770385, 0.8409082510211984, 0.7314129423430915, 0.6776738635521927, 0.6680904845091488, 1.446717117868402, 1.4372999107954707, 1.3844926461960587, 1.276895942496361, 1.5170550733455932, 1.067190739632038, 1.046082169711176, 0.8416794078173009, 1.1200218873771692, 1.3851183056668397, 1.1027698699241937, 0.6136756035680011], \"loglift\": [12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.3354, 0.1825, 0.1794, 0.1724, 0.1711, -0.0039, -0.0239, -0.0939, -0.2483, -0.387, -0.4628, -0.477, 0.3316, 0.325, 0.2872, 0.2054, 0.0889, 0.0242, 0.0041, -0.215, -0.217, -0.2278, -0.2327, -0.5329], \"Term\": [\"time\", \"minors\", \"response\", \"computer\", \"interface\", \"system\", \"graph\", \"trees\", \"eps\", \"user\", \"survey\", \"human\", \"minors\", \"graph\", \"system\", \"trees\", \"eps\", \"human\", \"survey\", \"user\", \"interface\", \"computer\", \"response\", \"time\", \"time\", \"response\", \"computer\", \"interface\", \"user\", \"survey\", \"human\", \"eps\", \"trees\", \"system\", \"graph\", \"minors\"], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"]}, \"R\": 12};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el171681402571202530569366540980\", ldavis_el171681402571202530569366540980_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el171681402571202530569366540980\", ldavis_el171681402571202530569366540980_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el171681402571202530569366540980\", ldavis_el171681402571202530569366540980_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=            Freq  cluster  topics         x    y\n",
       "topic                                           \n",
       "0      50.900005        1       1  0.015493  0.0\n",
       "1      49.099995        1       2 -0.015493  0.0, topic_info=     Category      Freq       Term     Total  loglift  logprob\n",
       "term                                                          \n",
       "11    Default  2.000000       time  2.000000  12.0000  12.0000\n",
       "7     Default  2.000000     minors  2.000000  11.0000  11.0000\n",
       "2     Default  2.000000   response  2.000000  10.0000  10.0000\n",
       "3     Default  2.000000   computer  2.000000   9.0000   9.0000\n",
       "10    Default  2.000000  interface  2.000000   8.0000   8.0000\n",
       "1     Default  3.000000     system  3.000000   7.0000   7.0000\n",
       "4     Default  2.000000      graph  2.000000   6.0000   6.0000\n",
       "0     Default  2.000000      trees  2.000000   5.0000   5.0000\n",
       "6     Default  2.000000        eps  2.000000   4.0000   4.0000\n",
       "9     Default  2.000000       user  2.000000   3.0000   3.0000\n",
       "5     Default  2.000000     survey  2.000000   2.0000   2.0000\n",
       "8     Default  2.000000      human  2.000000   1.0000   1.0000\n",
       "7      Topic1  1.515831     minors  2.129507   0.3354  -2.2760\n",
       "4      Topic1  1.731552      graph  2.834322   0.1825  -2.1430\n",
       "1      Topic1  2.157667     system  3.542785   0.1794  -1.9230\n",
       "0      Topic1  1.713996      trees  2.834018   0.1724  -2.1532\n",
       "6      Topic1  1.283804        eps  2.125484   0.1711  -2.4422\n",
       "8      Topic1  1.075795      human  2.121877  -0.0039  -2.6189\n",
       "5      Topic1  1.054314     survey  2.121505  -0.0239  -2.6391\n",
       "9      Topic1  1.309957       user  2.827012  -0.0939  -2.4220\n",
       "10     Topic1  0.840908  interface  2.117804  -0.2483  -2.8653\n",
       "3      Topic1  0.731413   computer  2.115906  -0.3870  -3.0048\n",
       "2      Topic1  0.677674   response  2.114974  -0.4628  -3.0811\n",
       "11     Topic1  0.668090       time  2.114808  -0.4770  -3.0953\n",
       "11     Topic2  1.446717       time  2.114808   0.3316  -2.2867\n",
       "2      Topic2  1.437300   response  2.114974   0.3250  -2.2932\n",
       "3      Topic2  1.384493   computer  2.115906   0.2872  -2.3307\n",
       "10     Topic2  1.276896  interface  2.117804   0.2054  -2.4116\n",
       "9      Topic2  1.517055       user  2.827012   0.0889  -2.2392\n",
       "5      Topic2  1.067191     survey  2.121505   0.0242  -2.5910\n",
       "8      Topic2  1.046082      human  2.121877   0.0041  -2.6109\n",
       "6      Topic2  0.841679        eps  2.125484  -0.2150  -2.8283\n",
       "0      Topic2  1.120022      trees  2.834018  -0.2170  -2.5426\n",
       "1      Topic2  1.385118     system  3.542785  -0.2278  -2.3302\n",
       "4      Topic2  1.102770      graph  2.834322  -0.2327  -2.5582\n",
       "7      Topic2  0.613676     minors  2.129507  -0.5329  -3.1443, token_table=      Topic      Freq       Term\n",
       "term                            \n",
       "3         1  0.472611   computer\n",
       "3         2  0.472611   computer\n",
       "6         1  0.470481        eps\n",
       "6         2  0.470481        eps\n",
       "4         1  0.705636      graph\n",
       "4         2  0.352818      graph\n",
       "8         1  0.471281      human\n",
       "8         2  0.471281      human\n",
       "10        1  0.472187  interface\n",
       "10        2  0.472187  interface\n",
       "7         1  0.939184     minors\n",
       "7         2  0.469592     minors\n",
       "2         1  0.472819   response\n",
       "2         2  0.472819   response\n",
       "5         1  0.471364     survey\n",
       "5         2  0.471364     survey\n",
       "1         1  0.564528     system\n",
       "1         2  0.282264     system\n",
       "11        1  0.472856       time\n",
       "11        2  0.472856       time\n",
       "0         1  0.705712      trees\n",
       "0         2  0.352856      trees\n",
       "9         1  0.353730       user\n",
       "9         2  0.707461       user, R=12, lambda_step=0.01, plot_opts={'ylab': 'PC2', 'xlab': 'PC1'}, topic_order=[1, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.gensim.prepare(goodLdaModel, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:gensim.models.ldamodel:performing inference on a chunk of 9 documents\n",
      "DEBUG:gensim.models.ldamodel:0/9 documents converged within 1 iterations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el171681402571044592408969088731\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el171681402571044592408969088731_data = {\"plot.opts\": {\"ylab\": \"PC2\", \"xlab\": \"PC1\"}, \"lambda.step\": 0.01, \"mdsDat\": {\"cluster\": [1, 1], \"topics\": [1, 2], \"Freq\": [52.04872638474759, 47.95127361525241], \"x\": [0.0013727783400227164, -0.0013727783400227164], \"y\": [0.0, 0.0]}, \"token.table\": {\"Topic\": [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2], \"Term\": [\"computer\", \"computer\", \"eps\", \"eps\", \"graph\", \"graph\", \"human\", \"human\", \"interface\", \"interface\", \"minors\", \"minors\", \"response\", \"response\", \"survey\", \"survey\", \"system\", \"system\", \"time\", \"time\", \"trees\", \"trees\", \"user\", \"user\"], \"Freq\": [0.4713497676997323, 0.4713497676997323, 0.47165179341871616, 0.47165179341871616, 0.7066758281068829, 0.35333791405344145, 0.4709851098824751, 0.4709851098824751, 0.47091202707059676, 0.47091202707059676, 0.47118992140673194, 0.47118992140673194, 0.47108267739716175, 0.47108267739716175, 0.4713255652677244, 0.4713255652677244, 0.5655691065186095, 0.5655691065186095, 0.4720015358018731, 0.4720015358018731, 0.35365514956279187, 0.35365514956279187, 0.7061943724045174, 0.3530971862022587]}, \"topic.order\": [1, 2], \"tinfo\": {\"Total\": [2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.83208147523211, 2.12353888309182, 2.1232093733271737, 2.1227696283064916, 2.8301519882996553, 2.1222864806074626, 3.5362610456414525, 2.121675702933652, 2.121566761091602, 2.8276132872269937, 2.120208200103746, 2.118637174137838, 2.118637174137838, 2.120208200103746, 2.8276132872269937, 2.121566761091602, 2.121675702933652, 3.5362610456414525, 2.1222864806074626, 2.8301519882996553, 2.1227696283064916, 2.1232093733271737, 2.12353888309182, 2.83208147523211], \"logprob\": [12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.2264, -2.5381, -2.5536, -2.5746, -2.2945, -2.5982, -2.114, -2.6289, -2.6345, -2.3917, -2.7067, -2.7973, -2.4514, -2.5256, -2.2629, -2.5946, -2.6003, -2.0938, -2.6331, -2.3635, -2.6598, -2.6848, -2.7039, -2.4473], \"Freq\": [2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.6288649292510629, 1.1926402069388395, 1.1743365806511095, 1.1499096003790579, 1.521685684421598, 1.1230716857749192, 1.8227322836890698, 1.0891441744056376, 1.083092667051587, 1.3806657794723307, 1.0076272475745525, 0.920359811967034, 1.198277362170804, 1.1125809525291934, 1.4469475077546632, 1.0384740940400146, 1.0325315285280143, 1.7135287619523827, 0.9992147948325433, 1.3084663038780573, 0.9728600279274338, 0.9488727926760644, 0.9308986761529806, 1.203216545981047], \"loglift\": [12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.0999, 0.0761, 0.0608, 0.04, 0.0325, 0.0166, -0.0097, -0.0138, -0.0193, -0.0639, -0.0909, -0.1808, 0.1651, 0.0902, 0.065, 0.0206, 0.0148, 0.0105, -0.0183, -0.0365, -0.0453, -0.0704, -0.0897, -0.121], \"Term\": [\"time\", \"eps\", \"trees\", \"user\", \"system\", \"computer\", \"survey\", \"interface\", \"human\", \"minors\", \"graph\", \"response\", \"user\", \"interface\", \"human\", \"response\", \"graph\", \"minors\", \"system\", \"survey\", \"computer\", \"trees\", \"eps\", \"time\", \"time\", \"eps\", \"trees\", \"computer\", \"survey\", \"system\", \"minors\", \"graph\", \"response\", \"human\", \"interface\", \"user\"], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"]}, \"R\": 12};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el171681402571044592408969088731\", ldavis_el171681402571044592408969088731_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el171681402571044592408969088731\", ldavis_el171681402571044592408969088731_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el171681402571044592408969088731\", ldavis_el171681402571044592408969088731_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=            Freq  cluster  topics         x    y\n",
       "topic                                           \n",
       "0      52.048726        1       1  0.001373  0.0\n",
       "1      47.951274        1       2 -0.001373  0.0, topic_info=     Category      Freq       Term     Total  loglift  logprob\n",
       "term                                                          \n",
       "11    Default  2.000000       time  2.000000  12.0000  12.0000\n",
       "6     Default  2.000000        eps  2.000000  11.0000  11.0000\n",
       "0     Default  2.000000      trees  2.000000  10.0000  10.0000\n",
       "9     Default  2.000000       user  2.000000   9.0000   9.0000\n",
       "1     Default  3.000000     system  3.000000   8.0000   8.0000\n",
       "3     Default  2.000000   computer  2.000000   7.0000   7.0000\n",
       "5     Default  2.000000     survey  2.000000   6.0000   6.0000\n",
       "10    Default  2.000000  interface  2.000000   5.0000   5.0000\n",
       "8     Default  2.000000      human  2.000000   4.0000   4.0000\n",
       "7     Default  2.000000     minors  2.000000   3.0000   3.0000\n",
       "4     Default  2.000000      graph  2.000000   2.0000   2.0000\n",
       "2     Default  2.000000   response  2.000000   1.0000   1.0000\n",
       "9      Topic1  1.628865       user  2.832081   0.0999  -2.2264\n",
       "10     Topic1  1.192640  interface  2.123539   0.0761  -2.5381\n",
       "8      Topic1  1.174337      human  2.123209   0.0608  -2.5536\n",
       "2      Topic1  1.149910   response  2.122770   0.0400  -2.5746\n",
       "4      Topic1  1.521686      graph  2.830152   0.0325  -2.2945\n",
       "7      Topic1  1.123072     minors  2.122286   0.0166  -2.5982\n",
       "1      Topic1  1.822732     system  3.536261  -0.0097  -2.1140\n",
       "5      Topic1  1.089144     survey  2.121676  -0.0138  -2.6289\n",
       "3      Topic1  1.083093   computer  2.121567  -0.0193  -2.6345\n",
       "0      Topic1  1.380666      trees  2.827613  -0.0639  -2.3917\n",
       "6      Topic1  1.007627        eps  2.120208  -0.0909  -2.7067\n",
       "11     Topic1  0.920360       time  2.118637  -0.1808  -2.7973\n",
       "11     Topic2  1.198277       time  2.118637   0.1651  -2.4514\n",
       "6      Topic2  1.112581        eps  2.120208   0.0902  -2.5256\n",
       "0      Topic2  1.446948      trees  2.827613   0.0650  -2.2629\n",
       "3      Topic2  1.038474   computer  2.121567   0.0206  -2.5946\n",
       "5      Topic2  1.032532     survey  2.121676   0.0148  -2.6003\n",
       "1      Topic2  1.713529     system  3.536261   0.0105  -2.0938\n",
       "7      Topic2  0.999215     minors  2.122286  -0.0183  -2.6331\n",
       "4      Topic2  1.308466      graph  2.830152  -0.0365  -2.3635\n",
       "2      Topic2  0.972860   response  2.122770  -0.0453  -2.6598\n",
       "8      Topic2  0.948873      human  2.123209  -0.0704  -2.6848\n",
       "10     Topic2  0.930899  interface  2.123539  -0.0897  -2.7039\n",
       "9      Topic2  1.203217       user  2.832081  -0.1210  -2.4473, token_table=      Topic      Freq       Term\n",
       "term                            \n",
       "3         1  0.471350   computer\n",
       "3         2  0.471350   computer\n",
       "6         1  0.471652        eps\n",
       "6         2  0.471652        eps\n",
       "4         1  0.706676      graph\n",
       "4         2  0.353338      graph\n",
       "8         1  0.470985      human\n",
       "8         2  0.470985      human\n",
       "10        1  0.470912  interface\n",
       "10        2  0.470912  interface\n",
       "7         1  0.471190     minors\n",
       "7         2  0.471190     minors\n",
       "2         1  0.471083   response\n",
       "2         2  0.471083   response\n",
       "5         1  0.471326     survey\n",
       "5         2  0.471326     survey\n",
       "1         1  0.565569     system\n",
       "1         2  0.565569     system\n",
       "11        1  0.472002       time\n",
       "11        2  0.472002       time\n",
       "0         1  0.353655      trees\n",
       "0         2  0.353655      trees\n",
       "9         1  0.706194       user\n",
       "9         2  0.353097       user, R=12, lambda_step=0.01, plot_opts={'ylab': 'PC2', 'xlab': 'PC1'}, topic_order=[1, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.gensim.prepare(badLdaModel, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13.8440816966\n"
     ]
    }
   ],
   "source": [
    "print(goodcm.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-14.1608330118\n"
     ]
    }
   ],
   "source": [
    "print(badcm.get_coherence())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using C_V coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "goodcm = CoherenceModel(model=goodLdaModel, texts=texts, dictionary=dictionary, coherence='c_v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "badcm = CoherenceModel(model=badLdaModel, texts=texts, dictionary=dictionary, coherence='c_v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline parameters for C_V coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence_Measure(seg=<function s_one_set at 0x7f90272c4a60>, prob=<function p_boolean_sliding_window at 0x7f90272c4bf8>, conf=<function cosine_similarity at 0x7f90272c4ea0>, aggr=<function arithmetic_mean at 0x7f90272c4f28>)\n"
     ]
    }
   ],
   "source": [
    "print(goodcm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print coherence values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.375262855326\n"
     ]
    }
   ],
   "source": [
    "print(goodcm.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.358036284922\n"
     ]
    }
   ],
   "source": [
    "print(badcm.get_coherence())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support for wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This API supports gensim's _ldavowpalwabbit_ and _ldamallet_ wrappers as input parameter to `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.wrappers.ldavowpalwabbit:using /tmp/tmp5c5c2ll7 as temp dir\n",
      "DEBUG:gensim.models.wrappers.ldavowpalwabbit:Training new model from corpus\n",
      "DEBUG:gensim.models.wrappers.ldavowpalwabbit:Writing corpus to: /tmp/tmp5c5c2ll7/corpus.vw\n",
      "INFO:gensim.models.wrappers.ldavowpalwabbit:Running Vowpal Wabbit command: /home/devashish/vw-8 -d /tmp/tmp5c5c2ll7/corpus.vw --power_t 0.5 --initial_t 1 --minibatch 256 --lda_D 9 --passes 50 --cache_file /tmp/tmp5c5c2ll7/cache.vw --lda_epsilon 0.001 --readable_model /tmp/tmp5c5c2ll7/topics.vw -k -f /tmp/tmp5c5c2ll7/model.vw --lda 2 -b 4 --lda_alpha 0.1 --lda_rho 0.1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "SKIP: Please change the path",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-1c245f2fb678>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLdaVowpalWabbit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/devashish/vw-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLdaVowpalWabbit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/devashish/vw-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ssreehari10/anaconda2/envs/gensim2/lib/python3.5/site-packages/gensim-0.13.2-py3.5-linux-x86_64.egg/gensim/models/wrappers/ldavowpalwabbit.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vw_path, corpus, num_topics, id2word, chunksize, passes, alpha, eta, decay, offset, gamma_threshold, random_seed, cleanup_files, tmp_prefix)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ssreehari10/anaconda2/envs/gensim2/lib/python3.5/site-packages/gensim-0.13.2-py3.5-linux-x86_64.egg/gensim/models/wrappers/ldavowpalwabbit.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, corpus)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0m_run_vw_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ssreehari10/anaconda2/envs/gensim2/lib/python3.5/site-packages/gensim-0.13.2-py3.5-linux-x86_64.egg/gensim/models/wrappers/ldavowpalwabbit.py\u001b[0m in \u001b[0;36m_run_vw_command\u001b[0;34m(cmd)\u001b[0m\n\u001b[1;32m    546\u001b[0m     proc = subprocess.Popen(cmd, stdout=subprocess.PIPE,\n\u001b[0;32m--> 547\u001b[0;31m                             stderr=subprocess.STDOUT)\n\u001b[0m\u001b[1;32m    548\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ssreehari10/anaconda2/envs/gensim2/lib/python3.5/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds)\u001b[0m\n\u001b[1;32m    946\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    948\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ssreehari10/anaconda2/envs/gensim2/lib/python3.5/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1550\u001b[0m                                 \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_executable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/devashish/vw-8'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-1c245f2fb678>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLdaVowpalWabbit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/devashish/vw-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SKIP: Please change the path\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: SKIP: Please change the path"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model1 = LdaVowpalWabbit('/home/devashish/vw-8', corpus=corpus, num_topics=2, id2word=dictionary, passes=50)\n",
    "    model2 = LdaVowpalWabbit('/home/devashish/vw-8', corpus=corpus, num_topics=2, id2word=dictionary, passes=1)\n",
    "except FileNotFoundError:\n",
    "    raise ValueError(\"SKIP: Please change the path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f1fe61f8fd7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCoherenceModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'u_mass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcm2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCoherenceModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'u_mass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model1' is not defined"
     ]
    }
   ],
   "source": [
    "cm1 = CoherenceModel(model=model1, corpus=corpus, coherence='u_mass')\n",
    "cm2 = CoherenceModel(model=model2, corpus=corpus, coherence='u_mass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cm1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-de2297cfdf59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_coherence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_coherence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cm1' is not defined"
     ]
    }
   ],
   "source": [
    "print(cm1.get_coherence())\n",
    "print(cm2.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model1 = LdaMallet('/home/devashish/mallet-2.0.8RC3/bin/mallet',corpus=corpus , num_topics=2, id2word=dictionary, iterations=50)\n",
    "model2 = LdaMallet('/home/devashish/mallet-2.0.8RC3/bin/mallet',corpus=corpus , num_topics=2, id2word=dictionary, iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm1 = CoherenceModel(model=model1, texts=texts, coherence='c_v')\n",
    "cm2 = CoherenceModel(model=model2, texts=texts, coherence='c_v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.581114877802\n",
      "0.549865328265\n"
     ]
    }
   ],
   "source": [
    "print cm1.get_coherence()\n",
    "print cm2.get_coherence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support for other topic models\n",
    "The gensim topics coherence pipeline can be used with other topics models too. Only the tokenized `topics` should be made available for the pipeline. Eg. with the gensim HDP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hm = HdpModel(corpus=corpus, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To get the topic words from the model\n",
    "topics = []\n",
    "for topic_id, topic in hm.show_topics(num_topics=10, formatted=False):\n",
    "    topic = [word for word, _ in topic]\n",
    "    topics.append(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'minors',\n",
       "  u'system',\n",
       "  u'graph',\n",
       "  u'human',\n",
       "  u'interface',\n",
       "  u'eps',\n",
       "  u'trees',\n",
       "  u'computer',\n",
       "  u'user',\n",
       "  u'response',\n",
       "  u'survey',\n",
       "  u'time'],\n",
       " [u'minors',\n",
       "  u'trees',\n",
       "  u'time',\n",
       "  u'interface',\n",
       "  u'user',\n",
       "  u'survey',\n",
       "  u'system',\n",
       "  u'response',\n",
       "  u'human',\n",
       "  u'computer',\n",
       "  u'graph',\n",
       "  u'eps']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize CoherenceModel using `topics` parameter\n",
    "cm = CoherenceModel(topics=topics, corpus=corpus, dictionary=dictionary, coherence='u_mass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-14.640667699204982"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.get_coherence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence as we can see, the `u_mass` and `c_v` coherence for the good LDA model is much more (better) than that for the bad LDA model. This is because, simply, the good LDA model usually comes up with better topics that are more human interpretable. The badLdaModel however fails to decipher between these two topics and comes up with topics which are not clear to a human. The `u_mass` and `c_v` topic coherences capture this wonderfully by giving the interpretability of these topics a number as we can see above. Hence this coherence measure can be used to compare difference topic models based on their human-interpretability."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

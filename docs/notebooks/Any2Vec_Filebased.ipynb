{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *2Vec File-based Training: API Tutorial\n",
    "\n",
    "This tutorial introduces a new file-based training mode for **`gensim.models.{Word2Vec, FastText, Doc2Vec}`** which leads to (much) faster training on machines with many cores. It documents how to use it, with Python examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this tutorial\n",
    "\n",
    "1. We will show how to use the new training mode.\n",
    "2. Evaluate its performance on the English Wikipedia and compare it to the existing mode.\n",
    "3. Show that model quality (analogy accuracies on `question-words.txt`) are almost the same for both modes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "The original implementation of Word2Vec training in Gensim is already super fast (covered in [this blog series](https://rare-technologies.com/word2vec-in-python-part-two-optimizing/), [benchmarks against other implementations](https://rare-technologies.com/machine-learning-hardware-benchmarks/)) and flexible, allowing you to train on arbitrary Python streams. We had to jump through some serious hoops to make it so, avoiding the Global Interpreter Lock (the dreaded GIL, the main bottleneck for any serious high performance computation in Python).\n",
    "\n",
    "The end result worked great for modest machines (< 8 cores), but for higher-end servers, the GIL reared its ugly head again. Simply managing the input stream iterators and worker queues (which has to be done in Python) was becoming the bottleneck. Simply put, the Python implementation didn't scale linearly with cores, as the original C implementation by Tomáš Mikolov did."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FIXME ADD IMAGE: x-axis CPU cores, y-axis performance (words/second)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to change that. After [much](https://github.com/RaRe-Technologies/gensim/pull/2127) [experimentation](https://github.com/RaRe-Technologies/gensim/pull/2048#issuecomment-401494412) and [benchmarking](https://persiyanov.github.io/jekyll/update/2018/05/28/gsoc-first-weeks.html), including some pretty [hardcore outlandish ideas](https://github.com/RaRe-Technologies/gensim/pull/2127#issuecomment-405937741), we figured there's no way around the GIL limitations, at least not at this level of required performance. Remember, we're talking >500k words (training instances) per second, using highly optimized C code. Way past the naive \"vectorize with NumPy arrays\" territory.\n",
    "\n",
    "So we decided to introduce a new code path, which has *less flexibility* in favour of *more performance*. We call this code path **`file-based training`**, and it's realized by passing a **new `corpus_file` parameter** to training (instead of the old `sentences` parameter, which is still available)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How it works\n",
    "\n",
    "<style>\n",
    ".rendered_html tr, .rendered_html th, .rendered_html td {\n",
    "    text-align: \"left\";\n",
    "}\n",
    "</style>\n",
    "\n",
    "| *code path* | *input parameter* | *advantages* | *disadvantages*\n",
    "| :-------- | :-------- | :--------- | :----------- |\n",
    "| Python-stream training (existing) | `sentences` (Python iterable) | Input can be generated dynamically from any storage, or even on-the-fly. | Scaling plateaus after 8 cores. |\n",
    "| file-based training (new) | `corpus_file` (file on disk) | Scales linearly with CPU cores. | Training corpus must be serialized to disk in a specific format. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you specify `corpus_file`, the model will read and process different portions of the file with different workers. The entire bulk of work is done outside of GIL, using no Python structures at all. The workers update the same weight matrix, but otherwise there's no communication, each worker munches on its data portion completely independently. This is the same approach the original C tool uses. \n",
    "\n",
    "Training with `corpus_file` yields a **significant performance boost**: for example, in the experiment belows training is 3.7x faster with 32 workers in comparison to training with `sentences` argument. It even outperforms the original Word2Vec C tool in terms of words/sec processing speed on high-core machines.\n",
    "\n",
    "The limitation of this approach is that `corpus_file` argument accepts a path to your corpus file, which must be stored on disk in a specific format. The format is simply the well-known [gensim.models.word2vec.LineSentence](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.LineSentence): one sentence per line, with words separated by spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use it\n",
    "\n",
    "You only need to:\n",
    "\n",
    "1. Save your corpus in the LineSentence format to disk (you may use [gensim.utils.save_as_line_sentence(your_corpus, your_corpus_file)](https://radimrehurek.com/gensim/utils.html#gensim.utils.save_as_line_sentence) for convenience).\n",
    "2. Change `sentences=your_corpus` argument to `corpus_file=your_corpus_file` in `Word2Vec.__init__`, `Word2Vec.build_vocab`, `Word2Vec.train` calls.\n",
    "\n",
    "\n",
    "A short Word2Vec example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - word2vec.py:1567 - collecting all words and their counts\n",
      "INFO - word2vec.py:1552 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - word2vec.py:1575 - collected 253854 word types from a corpus of 17005207 raw words and 1701 sentences\n",
      "INFO - word2vec.py:1626 - Loading a fresh vocabulary\n",
      "INFO - word2vec.py:1650 - effective_min_count=5 retains 71290 unique words (28% of original 253854, drops 182564)\n",
      "INFO - word2vec.py:1656 - effective_min_count=5 leaves 16718844 word corpus (98% of original 17005207, drops 286363)\n",
      "INFO - word2vec.py:1715 - deleting the raw counts dictionary of 253854 items\n",
      "INFO - word2vec.py:1718 - sample=0.001 downsamples 38 most-common words\n",
      "INFO - word2vec.py:1721 - downsampling leaves estimated 12506280 word corpus (74.8% of prior 16718844)\n",
      "INFO - base_any2vec.py:1020 - estimated required memory for 71290 words and 300 dimensions: 206741000 bytes\n",
      "INFO - word2vec.py:1834 - resetting layer weights\n",
      "INFO - base_any2vec.py:1208 - training model with 14 workers on 71290 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO - base_any2vec.py:1303 - EPOCH 1 - PROGRESS: at 7.17% examples, 93032 words/s, in_qsize -1, out_qsize 1\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - base_any2vec.py:1342 - EPOCH - 1 : training on 17114282 raw words (8584470 effective words) took 6.7s, 1273834 effective words/s\n",
      "WARNING - base_any2vec.py:1349 - EPOCH - 1 : supplied example count (1718) did not equal expected count (1701)\n",
      "WARNING - base_any2vec.py:1354 - EPOCH - 1 : supplied raw word count (17114282) did not equal expected count (17005207)\n",
      "INFO - base_any2vec.py:1303 - EPOCH 2 - PROGRESS: at 7.17% examples, 82736 words/s, in_qsize -1, out_qsize 1\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - base_any2vec.py:1342 - EPOCH - 2 : training on 17114282 raw words (8584460 effective words) took 7.6s, 1124630 effective words/s\n",
      "WARNING - base_any2vec.py:1349 - EPOCH - 2 : supplied example count (1718) did not equal expected count (1701)\n",
      "WARNING - base_any2vec.py:1354 - EPOCH - 2 : supplied raw word count (17114282) did not equal expected count (17005207)\n",
      "INFO - base_any2vec.py:1303 - EPOCH 3 - PROGRESS: at 7.17% examples, 74467 words/s, in_qsize -1, out_qsize 1\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - base_any2vec.py:1342 - EPOCH - 3 : training on 17114282 raw words (8584460 effective words) took 8.4s, 1023096 effective words/s\n",
      "WARNING - base_any2vec.py:1349 - EPOCH - 3 : supplied example count (1718) did not equal expected count (1701)\n",
      "WARNING - base_any2vec.py:1354 - EPOCH - 3 : supplied raw word count (17114282) did not equal expected count (17005207)\n",
      "INFO - base_any2vec.py:1303 - EPOCH 4 - PROGRESS: at 7.17% examples, 76818 words/s, in_qsize -1, out_qsize 1\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - base_any2vec.py:1342 - EPOCH - 4 : training on 17114282 raw words (8584475 effective words) took 8.2s, 1043194 effective words/s\n",
      "WARNING - base_any2vec.py:1349 - EPOCH - 4 : supplied example count (1718) did not equal expected count (1701)\n",
      "WARNING - base_any2vec.py:1354 - EPOCH - 4 : supplied raw word count (17114282) did not equal expected count (17005207)\n",
      "INFO - base_any2vec.py:1303 - EPOCH 5 - PROGRESS: at 7.17% examples, 74233 words/s, in_qsize -1, out_qsize 0\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 11 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - base_any2vec.py:1342 - EPOCH - 5 : training on 17114282 raw words (8584261 effective words) took 8.5s, 1014357 effective words/s\n",
      "WARNING - base_any2vec.py:1349 - EPOCH - 5 : supplied example count (1718) did not equal expected count (1701)\n",
      "WARNING - base_any2vec.py:1354 - EPOCH - 5 : supplied raw word count (17114282) did not equal expected count (17005207)\n",
      "INFO - base_any2vec.py:1374 - training on a 85571410 raw words (42922126 effective words) took 40.8s, 1051084 effective words/s\n",
      "WARNING - base_any2vec.py:1378 - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.utils import save_as_line_sentence\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(filename)s:%(lineno)s - %(message)s')\n",
    "\n",
    "print(gensim.models.word2vec.CORPUSFILE_VERSION)  # must be >= 0, i.e. optimized compiled version\n",
    "\n",
    "corpus = api.load(\"text8\")\n",
    "save_as_line_sentence(corpus, \"my_corpus.txt\")\n",
    "\n",
    "model = Word2Vec(corpus_file=\"my_corpus.txt\", iter=5, size=300, workers=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FIXME: I see warnings in the training on my machine (macbook pro, using Gensim code at #0b0383).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's prepare the full Wikipedia dataset as training corpus\n",
    "\n",
    "We load wikipedia dump from `gensim-data`, perform text preprocessing with Gensim functions, and finally save processed corpus in LineSentence format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno socket error] [SSL: TLSV1_ALERT_PROTOCOL_VERSION] tlsv1 alert protocol version (_ssl.c:590)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-82c667fe91cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# serialize the preprocessed corpus into a single file on disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0msave_as_line_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCORPUS_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Volumes/work/workspace/gensim/trunk/gensim/utils.pyc\u001b[0m in \u001b[0;36msave_as_line_sentence\u001b[0;34m(corpus, filename)\u001b[0m\n\u001b[1;32m   2040\u001b[0m     \"\"\"\n\u001b[1;32m   2041\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2043\u001b[0m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0many2unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m             \u001b[0mfout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-82c667fe91cd>\u001b[0m in \u001b[0;36mprocessed_corpus\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocessed_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mraw_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wiki-english-20171001'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0marticle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_corpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# concatenate all section titles and texts of each Wikipedia article into a single \"sentence\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/work/workspace/gensim/trunk/gensim/downloader.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, return_path)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         \u001b[0m_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/work/workspace/gensim/trunk/gensim/downloader.py\u001b[0m in \u001b[0;36m_download\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mtmp_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdtemp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0minit_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__init__.py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m     \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_load_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m     \u001b[0mtotal_parts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_parts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtotal_parts\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib.pyc\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data, context)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_urlopener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreporthook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0murlcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_urlopener\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self, url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib.pyc\u001b[0m in \u001b[0;36mopen_https\u001b[0;34m(self, url, data)\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrealhost\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Host'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealhost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddheaders\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m             \u001b[0merrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetreply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body)\u001b[0m\n\u001b[1;32m   1047\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body)\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmessage_body\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0mmessage_body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage_body\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0;31m#message_body was not a string (i.e. it is a file) and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotConnected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m             self.sock = self._context.wrap_socket(self.sock,\n\u001b[0;32m-> 1274\u001b[0;31m                                                   server_hostname=server_hostname)\n\u001b[0m\u001b[1;32m   1275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[0m__all__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HTTPSConnection\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/ssl.pyc\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname)\u001b[0m\n\u001b[1;32m    350\u001b[0m                          \u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                          \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m                          _context=self)\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_npn_protocols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpn_protocols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/ssl.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sock, keyfile, certfile, server_side, cert_reqs, ssl_version, ca_certs, do_handshake_on_connect, family, type, proto, fileno, suppress_ragged_eofs, npn_protocols, ciphers, server_hostname, _context)\u001b[0m\n\u001b[1;32m    577\u001b[0m                         \u001b[0;31m# non-blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/ssl.pyc\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m    806\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno socket error] [SSL: TLSV1_ALERT_PROTOCOL_VERSION] tlsv1 alert protocol version (_ssl.c:590)"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "\n",
    "CORPUS_FILE = 'wiki-en-20171001.txt'\n",
    "\n",
    "def processed_corpus():\n",
    "    raw_corpus = api.load('wiki-english-20171001')\n",
    "    for article in raw_corpus:\n",
    "        # concatenate all section titles and texts of each Wikipedia article into a single \"sentence\"\n",
    "        doc = '\\n'.join(itertools.chain.from_iterable(zip(article['section_titles'], article['section_texts'])))\n",
    "        yield preprocess_string(doc)\n",
    "\n",
    "# serialize the preprocessed corpus into a single file on disk\n",
    "save_as_line_sentence(processed_corpus(), CORPUS_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XXX: Doesn't work for me (Radim). Some `gensim.downloader` issues on macbook, unrelated to *2vec training.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "\n",
    "We train two models:\n",
    "* With `sentences` argument\n",
    "* With `corpus_file` argument\n",
    "\n",
    "\n",
    "Then, we compare the timings and accuracy on `question-words.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import LineSentence\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "model_sent = Word2Vec(sentences=LineSentence(CORPUS_FILE), iter=5, size=300, workers=32)\n",
    "print(\"Training model with `sentences` took {:.3f} seconds\".format(time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "model_corp_file = Word2Vec(corpus_file=CORPUS_FILE, iter=5, size=300, workers=32)\n",
    "print(\"Training model with `corpus_file` took {:.3f} seconds\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training with `corpus_file` took 3.7x less time!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compare the accuracies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/persiyanov/gensim/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word analogy accuracy with `sentences`: 0.754\n",
      "Word analogy accuracy with `corpus_file`: 0.744\n"
     ]
    }
   ],
   "source": [
    "model_sent_accuracy = model_sent.wv.evaluate_word_analogies(datapath('questions-words.txt'))[0]\n",
    "print(\"Word analogy accuracy with `sentences`: {:.1f} %%\".format(100.0 * model_sent_accuracy))\n",
    "\n",
    "model_corp_file_accuracy = model_corp_file.wv.evaluate_word_analogies(datapath('questions-words.txt'))[0]\n",
    "print(\"Word analogy accuracy with `corpus_file`: {:.1f} %%\".format(100.0 * model_corp_file_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracies are approximately the same.\n",
    "\n",
    "**FIXME: why \"approximately\"? What is the \"expected jitter\" due to the randomness in training? For example, what's the accuracy spread of multiple runs in the same mode (e.g., for corpus_file only)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - word2vec.py:1567 - collecting all words and their counts\n",
      "INFO - word2vec.py:1552 - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - word2vec.py:1575 - collected 253854 word types from a corpus of 17005207 raw words and 1701 sentences\n",
      "INFO - word2vec.py:1626 - Loading a fresh vocabulary\n",
      "INFO - word2vec.py:1650 - effective_min_count=5 retains 71290 unique words (28% of original 253854, drops 182564)\n",
      "INFO - word2vec.py:1656 - effective_min_count=5 leaves 16718844 word corpus (98% of original 17005207, drops 286363)\n",
      "INFO - word2vec.py:1715 - deleting the raw counts dictionary of 253854 items\n",
      "INFO - word2vec.py:1718 - sample=0.001 downsamples 38 most-common words\n",
      "INFO - word2vec.py:1721 - downsampling leaves estimated 12506280 word corpus (74.8% of prior 16718844)\n",
      "INFO - fasttext.py:551 - estimated required memory for 71290 words, 306868 buckets and 300 dimensions: 591929400 bytes\n",
      "INFO - word2vec.py:1834 - resetting layer weights\n",
      "INFO - fasttext.py:1011 - Total number of ngrams is 306868\n",
      "INFO - base_any2vec.py:1208 - training model with 14 workers on 71290 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO - base_any2vec.py:1303 - EPOCH 1 - PROGRESS: at 7.17% examples, 12899 words/s, in_qsize -1, out_qsize 1\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - base_any2vec.py:1303 - EPOCH 1 - PROGRESS: at 64.79% examples, 113990 words/s, in_qsize -1, out_qsize 0\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - base_any2vec.py:1342 - EPOCH - 1 : training on 17114282 raw words (8584470 effective words) took 48.9s, 175462 effective words/s\n",
      "WARNING - base_any2vec.py:1349 - EPOCH - 1 : supplied example count (1718) did not equal expected count (1701)\n",
      "WARNING - base_any2vec.py:1354 - EPOCH - 1 : supplied raw word count (17114282) did not equal expected count (17005207)\n",
      "INFO - base_any2vec.py:1303 - EPOCH 2 - PROGRESS: at 7.17% examples, 6283 words/s, in_qsize -1, out_qsize 1\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - base_any2vec.py:1303 - EPOCH 2 - PROGRESS: at 35.86% examples, 30873 words/s, in_qsize -1, out_qsize 1\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - base_any2vec.py:1303 - EPOCH 2 - PROGRESS: at 64.67% examples, 54701 words/s, in_qsize -1, out_qsize 1\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - base_any2vec.py:1303 - EPOCH 2 - PROGRESS: at 93.71% examples, 78222 words/s, in_qsize -1, out_qsize 1\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - base_any2vec.py:1342 - EPOCH - 2 : training on 17114282 raw words (8584460 effective words) took 102.5s, 83728 effective words/s\n",
      "WARNING - base_any2vec.py:1349 - EPOCH - 2 : supplied example count (1718) did not equal expected count (1701)\n",
      "WARNING - base_any2vec.py:1354 - EPOCH - 2 : supplied raw word count (17114282) did not equal expected count (17005207)\n",
      "INFO - base_any2vec.py:1303 - EPOCH 3 - PROGRESS: at 7.17% examples, 2923 words/s, in_qsize -1, out_qsize 1\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - base_any2vec.py:1303 - EPOCH 3 - PROGRESS: at 43.15% examples, 17489 words/s, in_qsize -1, out_qsize 1\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - base_any2vec.py:1303 - EPOCH 3 - PROGRESS: at 93.71% examples, 37689 words/s, in_qsize -1, out_qsize 1\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - base_any2vec.py:1342 - EPOCH - 3 : training on 17114282 raw words (8584460 effective words) took 211.4s, 40614 effective words/s\n",
      "WARNING - base_any2vec.py:1349 - EPOCH - 3 : supplied example count (1718) did not equal expected count (1701)\n",
      "WARNING - base_any2vec.py:1354 - EPOCH - 3 : supplied raw word count (17114282) did not equal expected count (17005207)\n",
      "INFO - base_any2vec.py:1303 - EPOCH 4 - PROGRESS: at 7.17% examples, 4099 words/s, in_qsize -1, out_qsize 1\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - base_any2vec.py:1303 - EPOCH 4 - PROGRESS: at 21.52% examples, 12213 words/s, in_qsize -1, out_qsize 1\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - base_any2vec.py:1303 - EPOCH 4 - PROGRESS: at 50.21% examples, 28262 words/s, in_qsize -1, out_qsize 1\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - base_any2vec.py:1303 - EPOCH 4 - PROGRESS: at 86.54% examples, 48363 words/s, in_qsize -1, out_qsize 1\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - base_any2vec.py:1342 - EPOCH - 4 : training on 17114282 raw words (8584475 effective words) took 153.1s, 56088 effective words/s\n",
      "WARNING - base_any2vec.py:1349 - EPOCH - 4 : supplied example count (1718) did not equal expected count (1701)\n",
      "WARNING - base_any2vec.py:1354 - EPOCH - 4 : supplied raw word count (17114282) did not equal expected count (17005207)\n",
      "INFO - base_any2vec.py:1303 - EPOCH 5 - PROGRESS: at 7.17% examples, 4141 words/s, in_qsize -1, out_qsize 1\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - base_any2vec.py:1303 - EPOCH 5 - PROGRESS: at 28.69% examples, 16413 words/s, in_qsize -1, out_qsize 1\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - base_any2vec.py:1303 - EPOCH 5 - PROGRESS: at 79.13% examples, 44928 words/s, in_qsize -1, out_qsize 1\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - base_any2vec.py:347 - worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - base_any2vec.py:1342 - EPOCH - 5 : training on 17114282 raw words (8584261 effective words) took 150.2s, 57142 effective words/s\n",
      "WARNING - base_any2vec.py:1349 - EPOCH - 5 : supplied example count (1718) did not equal expected count (1701)\n",
      "WARNING - base_any2vec.py:1354 - EPOCH - 5 : supplied raw word count (17114282) did not equal expected count (17005207)\n",
      "INFO - base_any2vec.py:1374 - training on a 85571410 raw words (42922126 effective words) took 669.0s, 64160 effective words/s\n",
      "WARNING - base_any2vec.py:1378 - under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.utils import save_as_line_sentence\n",
    "from gensim.models.fasttext import FastText\n",
    "\n",
    "corpus = api.load(\"text8\")\n",
    "save_as_line_sentence(corpus, \"my_corpus.txt\")\n",
    "\n",
    "model = FastText(corpus_file=\"my_corpus.txt\", iter=5, size=300, workers=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FIXME: I see some warnings in the output.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's compare the timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models.fasttext import FastText\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "model_corp_file = FastText(corpus_file=CORPUS_FILE, iter=5, size=300, workers=32)\n",
    "print(\"Training model with `sentences` took {:.3f} seconds\".format(time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "model_sent = FastText(sentences=LineSentence(CORPUS_FILE), iter=5, size=300, workers=32)\n",
    "print(\"Training model with `corpus_file` took {:.3f} seconds\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We see a 1.5x performance boost!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, accuracies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/persiyanov/gensim/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word analogy accuracy with `sentences`: 0.646\n",
      "Word analogy accuracy with `corpus_file`: 0.659\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "\n",
    "model_sent_accuracy = model_sent.wv.evaluate_word_analogies(datapath('questions-words.txt'))[0]\n",
    "print(\"Word analogy accuracy with `sentences`: {:.1f} %%\".format(100.0 * model_sent_accuracy))\n",
    "\n",
    "model_corp_file_accuracy = model_corp_file.wv.evaluate_word_analogies(datapath('questions-words.txt'))[0]\n",
    "print(\"Word analogy accuracy with `corpus_file`: {:.1f} %%\".format(100.0 * model_corp_file_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.utils import save_as_line_sentence\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "corpus = api.load(\"text8\")\n",
    "save_as_line_sentence(corpus, \"my_corpus.txt\")\n",
    "\n",
    "model = Doc2Vec(corpus_file=\"my_corpus.txt\", epochs=5, vector_size=300, workers=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's compare the timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedLineDocument\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "model_corp_file = Doc2Vec(corpus_file=CORPUS_FILE, epochs=5, vector_size=300, workers=32)\n",
    "print(\"Training model with `sentences` took {:.3f} seconds\".format(time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "model_sent = Doc2Vec(documents=TaggedLineDocument(CORPUS_FILE), epochs=5, vector_size=300, workers=32)\n",
    "print(\"Training model with `corpus_file` took {:.3f} seconds\".format(time.time() - st_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A 6x speedup!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/persiyanov/gensim/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word analogy accuracy with `sentences`: 0.718\n",
      "Word analogy accuracy with `corpus_file`: 0.685\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "\n",
    "model_sent_accuracy = model_sent.wv.evaluate_word_analogies(datapath('questions-words.txt'))[0]\n",
    "print(\"Word analogy accuracy with `sentences`: {:.1f} %%\".format(100.0 * model_sent_accuracy))\n",
    "\n",
    "model_corp_file_accuracy = model_corp_file.wv.evaluate_word_analogies(datapath('questions-words.txt'))[0]\n",
    "print(\"Word analogy accuracy with `corpus_file`: {:.1f} %%\".format(100.0 * model_corp_file_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FIXME: That's a big difference. A bug?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TL;DR: Conclusion\n",
    "\n",
    "In case your training corpus already lives on disk, you lose nothing by switching to the new `corpus_file` training mode. Training will be much faster.\n",
    "\n",
    "In case your corpus is generated dynamically, you can either serialize it to disk first with `gensim.utils.save_as_line_sentence` (and then use the fast `corpus_file`), or if that's not possible continue using the existing `sentences` training mode.\n",
    "\n",
    "------\n",
    "\n",
    "This new code branch was created by [@persiyanov](https://github.com/persiyanov) as a Google Summer of Code 2018 project in the [RARE Student Incubator](https://rare-technologies.com/incubator/).\n",
    "\n",
    "Questions, comments? Use our Gensim [mailing list](https://groups.google.com/forum/#!forum/gensim) and [twitter](https://twitter.com/gensim_py). Happy training!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

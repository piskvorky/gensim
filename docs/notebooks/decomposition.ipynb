{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of different methods for decomposition\n",
    "\n",
    "In this notebook, we study two widely popular methods for decomposition: Singular Value Decomposition and Non-Negative Matrix Factorization.\n",
    "\n",
    "1. SVD\n",
    "    - using scipy.linalg\n",
    "2. NMF\n",
    "    - using sklearn.NMF\n",
    "    - using SGD, numpy\n",
    "\n",
    "\n",
    "- Mentee: Manoj Pandey\n",
    "- Mentor: Ivan, RaRe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg as la\n",
    "from sklearn import decomposition\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Data source](http://scikit-learn.org/stable/datasets/twenty_newsgroups.html): Newsgroups are discussion groups on Usenet, which was popular in the 80s and 90s before the web really took off.  This dataset includes 18,000 newsgroups posts with 20 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMF is included with scikit-learn, but we are not going to use it\n",
    "# from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "INFO:sklearn.datasets.twenty_newsgroups:Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n",
      "INFO:sklearn.datasets.twenty_newsgroups:Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=remove)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2034,), (2034,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.filenames.shape, newsgroups_train.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['comp.graphics', 'talk.religion.misc', 'sci.space', 'alt.atheism',\n",
       "       'sci.space', 'alt.atheism', 'sci.space', 'comp.graphics',\n",
       "       'sci.space', 'comp.graphics'],\n",
       "      dtype='<U18')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(newsgroups_train.target_names)[newsgroups_train.target[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n",
      "\n",
      "\n",
      "Seems to be, barring evidence to the contrary, that Koresh was simply\n",
      "another deranged fanatic who thought it neccessary to take a whole bunch of\n",
      "folks with him, children and all, to satisfy his delusional mania. Jim\n",
      "Jones, circa 1993.\n",
      "\n",
      "\n",
      "Nope - fruitcakes like Koresh have been demonstrating such evil corruption\n",
      "for centuries.\n",
      "\n",
      " >In article <1993Apr19.020359.26996@sq.sq.com>, msb@sq.sq.com (Mark Brader) \n",
      "\n",
      "MB>                                                             So the\n",
      "MB> 1970 figure seems unlikely to actually be anything but a perijove.\n",
      "\n",
      "JG>Sorry, _perijoves_...I'm not used to talking this language.\n",
      "\n",
      "Couldn't we just say periapsis or apoapsis?\n",
      "\n",
      " \n",
      "I have a request for those who would like to see Charley Wingate\n",
      "respond to the \"Charley Challenges\" (and judging from my e-mail, there\n",
      "appear to be quite a few of you.)  \n",
      "\n",
      "It is clear that Mr. Wingate intends to continue to post tangential or\n",
      "unrelated articles while ingoring the Challenges themselves.  Between\n",
      "the last two re-postings of the Challenges, I noted perhaps a dozen or\n",
      "more posts by Mr. Wingate, none of which answered a single Challenge.  \n",
      "\n",
      "It seems unmistakable to me that Mr. Wingate hopes that the questions\n",
      "will just go away, and he is doing his level best to change the\n",
      "subject.  Given that this seems a rather common net.theist tactic, I\n",
      "would like to suggest that we impress upon him our desire for answers,\n",
      "in the following manner:\n",
      "\n",
      "1. Ignore any future articles by Mr. Wingate that do not address the\n",
      "Challenges, until he answers them or explictly announces that he\n",
      "refuses to do so.\n",
      "\n",
      "--or--\n",
      "\n",
      "2. If you must respond to one of his articles, include within it\n",
      "something similar to the following:\n",
      "\n",
      "    \"Please answer the questions posed to you in the Charley Challenges.\"\n",
      "\n",
      "Really, I'm not looking to humiliate anyone here, I just want some\n",
      "honest answers.  You wouldn't think that honesty would be too much to\n",
      "ask from a devout Christian, would you?  \n",
      "\n",
      "Nevermind, that was a rhetorical question.\n",
      "AW&ST  had a brief blurb on a Manned Lunar Exploration confernce\n",
      "May 7th  at Crystal City Virginia, under the auspices of AIAA.\n",
      "\n",
      "Does anyone know more about this?  How much, to attend????\n",
      "\n",
      "Anyone want to go?\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(newsgroups_train.data[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we can see above, there are three paragraphs. Reading through them, it seems like:\n",
    "- 1 -> Graphics\n",
    "- 2 -> religion or atheism\n",
    "- 3 -> ??\n",
    "- 4 -> can see the word \"theism\", so maybe atheism\n",
    "- 5 -> space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['comp.graphics', 'talk.religion.misc', 'sci.space', 'alt.atheism',\n",
       "       'sci.space'],\n",
       "      dtype='<U18')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check it from the data\n",
    "np.array(newsgroups_train.target_names)[newsgroups_train.target[:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization using CountVectorizer / TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit a tf-idf model on our dataset below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics, num_top_words = 6, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 26576)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorizer = CountVectorizer(stop_words='english') # also can use tf-idf\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data).todense() # (documents, vocab)\n",
    "vectors.shape #, vectors.nnz / vectors.shape[0], row_means.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, (2034, 26576))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroups_train.data), vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = np.array(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26576,)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cosmonauts', 'cosmos', 'cosponsored', 'cost', 'costa', 'costar',\n",
       "       'costing', 'costly', 'costruction', 'costs', 'cosy', 'cote',\n",
       "       'couched', 'couldn', 'council', 'councils', 'counsel', 'counselees',\n",
       "       'counselor', 'count', 'countdown', 'counted', 'counter',\n",
       "       'counter_clockwise', 'counterargument', 'counterclockwise',\n",
       "       'countered', 'counterexamples', 'counterfactual', 'counterpart',\n",
       "       'counterproductive', 'counters', 'counting', 'countless',\n",
       "       'countries', 'country', 'countryside', 'counts', 'county', 'coup',\n",
       "       'couple', 'coupled', 'couples', 'courage', 'courageous', 'courant',\n",
       "       'cournoyer', 'course', 'courses', 'court', 'courteous', 'courtesy',\n",
       "       'courts', 'cousin', 'coutesy', 'cov', 'covalt', 'covenant',\n",
       "       'covenent', 'coventry', 'cover', 'coverage', 'coverages', 'covered',\n",
       "       'covering', 'coverings', 'covers', 'cow', 'coward', 'cowboy',\n",
       "       'cowboys', 'cowdery', 'cowen', 'cowgirls', 'coy', 'coyote', 'cozy',\n",
       "       'cp2', 'cpa', 'cpac', 'cpp', 'cps', 'cpu', 'cpus', 'cquel', 'cr',\n",
       "       'crabtree', 'crack', 'cracking', 'crackle', 'cracks', 'cradle',\n",
       "       'craf', 'craft', 'crafts', 'craftsmen', 'craig', 'crandall',\n",
       "       'crane', 'cranial'],\n",
       "      dtype='<U80')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[7000:7100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition\n",
    "- `using scipy.linalg.SVG`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://halmusreeftank.com/images/IMG_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: http://halmusreeftank.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://csiu.github.io/blog//img/figure/2017-04-16/svd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://csiu.github.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 26576)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 30s, sys: 3.01 s, total: 1min 33s\n",
      "Wall time: 48.1 s\n"
     ]
    }
   ],
   "source": [
    "%time U, s, Vh = la.svd(vectors, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2034, 2034), (2034,), (2034, 26576))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape, s.shape, Vh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Result\n",
    "\n",
    "> `(2034, 26576) => ((2034, 2034), (2034,), (2034, 26576))`\n",
    "\n",
    "> `.  vectors             U           s           Vh     .`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if the result is actually a decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vectors = U @ np.diag(s) @ Vh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 26576)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(vectors, new_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(U @ U.T, np.eye(U.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(Vh @ Vh.T, np.eye(Vh.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to get topics\n",
    "\n",
    "num_top_words=8\n",
    "\n",
    "def show_topics(a):\n",
    "    top_words = lambda t: [vocab[i] for i in np.argsort(t)[:-num_top_words-1:-1]]\n",
    "    topic_words = ([top_words(t) for t in a])\n",
    "    return [' '.join(t) for t in topic_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ditto critus 141592654 point_node n4 do_sphere pnp asg',\n",
       " 'space graphics thanks program files image nasa ftp',\n",
       " 'space nasa launch shuttle moon orbit lunar station',\n",
       " 'ico bobbe tek beauchaine bronx manhattan sank queens',\n",
       " 'objective think morality don just people moral values',\n",
       " 'objective morality values moral god science space subjective',\n",
       " 'graphics comp god software group objective aspects edu',\n",
       " 'image file cview graphics data use just images',\n",
       " 'jesus objective christ christian software christians bible did',\n",
       " 'edu space jesus ftp file nasa files pub']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_topics(Vh[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non Negative Matrix Factorization\n",
    "- first, using NMF from scikit-learn\n",
    "- then, using numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://image.slidesharecdn.com/nlpmeetupsept2016derekgreene-160929091010/95/dynamic-topic-modeling-via-nonnegative-matrix-factorization-dr-derek-greene-4-638.jpg?cb=1475140310)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: Slideshare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://mmolano.files.wordpress.com/2014/10/nmf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://mmolano.files.wordpress.com/2014/10/nmf.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = decomposition.NMF(n_components=num_topics, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.2 s, sys: 1.92 s, total: 32.2 s\n",
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "%time W = clf.fit_transform(vectors)\n",
    "H = clf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 26576)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2034, 5), (5, 26576))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape, H.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Result\n",
    "\n",
    "> `(2034, 26576) => ((2034, 5), (5, 26576))`\n",
    "\n",
    "> `.     vectors        W          H      .`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(vectors , W@H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.712926057951641"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.norm(vectors - W@H)\n",
    "# I think this is because NMF is approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['people don think just like objective say morality',\n",
       " 'graphics thanks files image file program windows know',\n",
       " 'space nasa launch shuttle orbit moon lunar earth',\n",
       " 'ico bobbe tek beauchaine bronx manhattan sank queens',\n",
       " 'god jesus bible believe christian atheism does belief']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_topics(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy to rescue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal**: Decompose $V_{(m \\times n)}$ into $V \\approx WH$ ;\n",
    "\n",
    "   where $W_{(m \\times d)}$ and $H_{(d \\times n)}$, $W,\\;H\\;>=\\;0$, and we've minimized the Frobenius norm of $V-WH$.\n",
    "\n",
    "**Approach**: We will pick random positive $W$ & $H$, and then use SGD to optimize.\n",
    "\n",
    "**Sources**:\n",
    "- Optimality and gradients of NMF: http://users.wfu.edu/plemmons/papers/chu_ple.pdf\n",
    "- Projected gradients: https://www.csie.ntu.edu.tw/~cjlin/papers/pgradnmf.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 1e3 # lambda\n",
    "lr = 1e-2 # learning rate = 0.01\n",
    "m, n = vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 26576)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 1e-6 # Âµ\n",
    "# gradients\n",
    "def grads(M, W, H):\n",
    "    R = W@H-M\n",
    "    return R@H.T + penalty(W, mu)*lam, W.T@R + penalty(H, mu)*lam # dW, dH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate penalty\n",
    "def penalty(M, mu):\n",
    "    return np.where(M>=mu,0, np.min(M - mu, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update\n",
    "def update(M, W, H, lr):\n",
    "    dW,dH = grads(M,W,H)\n",
    "    W -= lr*dW; H -= lr*dH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(M,W,H): \n",
    "    # Prints frobenius norm and other info\n",
    "    print ((la.norm(M-W@H)), W.min(), H.min(), (W<0).sum(), (H<0).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.abs(np.random.normal(scale=0.01, size=(m,num_topics)))\n",
    "H = np.abs(np.random.normal(scale=0.01, size=(num_topics,n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.4246561087 1.54643492996e-07 6.43139263611e-08 0 0\n"
     ]
    }
   ],
   "source": [
    "report(vectors, W, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "update(vectors, W, H, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.4169857252 -0.00121131318517 -6.40467278636e-05 159 282\n"
     ]
    }
   ],
   "source": [
    "report(vectors, W, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0/500: 43.8778272029 -0.00208808547441 -0.00170167658404 159 9409\n",
      "Iteration 10/500: 43.8648893136 -0.00176954883833 -0.000862236048491 191 9076\n",
      "Iteration 20/500: 43.8512642102 -0.00411962115736 -0.00184820736821 165 8966\n",
      "Iteration 30/500: 43.8415948928 -0.00162798536787 -0.002165842963 166 8888\n",
      "Iteration 40/500: 43.8339574782 -0.00149451050905 -0.00201874943895 178 9403\n",
      "Iteration 50/500: 43.8261295056 -0.00240548813281 -0.0011585879677 175 8945\n",
      "Iteration 60/500: 43.8207097623 -0.003328709076 -0.00170209761967 151 9157\n",
      "Iteration 70/500: 43.8126931604 -0.00225727273457 -0.00198283600801 157 9239\n",
      "Iteration 80/500: 43.8080371293 -0.00286052139051 -0.00113164132538 173 9293\n",
      "Iteration 90/500: 43.8049970039 -0.000853666222654 -0.00233603374422 152 9114\n",
      "Iteration 100/500: 43.8014331618 -0.00261673279944 -0.000652801971096 168 9050\n",
      "Iteration 110/500: 43.8001897979 -0.00154614967032 -0.00194432212029 167 9469\n",
      "Iteration 120/500: 43.7955471929 -0.000986127478639 -0.00119401821373 163 9414\n",
      "Iteration 130/500: 43.7923082279 -0.0019154340545 -0.0024788742774 186 9214\n",
      "Iteration 140/500: 43.7910261123 -0.00297339165243 -0.00289716026092 171 9365\n",
      "Iteration 150/500: 43.7880961774 -0.00200733868769 -0.00172296787242 181 9372\n",
      "Iteration 160/500: 43.7853250022 -0.00192145543814 -0.00174684326955 180 9452\n",
      "Iteration 170/500: 43.7836595377 -0.00214281114035 -0.00265748635141 176 9588\n",
      "Iteration 180/500: 43.7828043004 -0.00128418940882 -0.00213870401767 155 9793\n",
      "Iteration 190/500: 43.781250345 -0.00130067548095 -0.00239176908282 165 9502\n",
      "Iteration 200/500: 43.7770568122 -0.00239165150319 -0.00210895201621 188 9416\n",
      "Iteration 210/500: 43.7748641103 -0.00275715479622 -0.00155490034273 166 9318\n",
      "Iteration 220/500: 43.7739742339 -0.00204419309106 -0.0024147430567 160 9340\n",
      "Iteration 230/500: 43.7726383609 -0.00123790971532 -0.00219951011644 166 9643\n",
      "Iteration 240/500: 43.7690377244 -0.000866679719496 -0.00278565459673 172 9561\n",
      "Iteration 250/500: 43.7670062168 -0.00122504134777 -0.00232499669379 174 9346\n",
      "Iteration 260/500: 43.764123588 -0.0032896608136 -0.00195767487571 166 9221\n",
      "Iteration 270/500: 43.7639876509 -0.000626641247555 -0.00508069350701 176 9188\n",
      "Iteration 280/500: 43.763284805 -0.00149118909013 -0.00308435843497 171 9878\n",
      "Iteration 290/500: 43.7616787489 -0.00215666080382 -0.00142532210538 181 9886\n",
      "Iteration 300/500: 43.7587086522 -0.00142371477495 -0.00162445948674 158 9768\n",
      "Iteration 310/500: 43.7575939791 -0.000864953584558 -0.00208988765448 179 9878\n",
      "Iteration 320/500: 43.755074153 -0.00138260377349 -0.0010194585835 168 9345\n",
      "Iteration 330/500: 43.7526958354 -0.0020649828224 -0.00133495338908 186 9510\n",
      "Iteration 340/500: 43.7517898887 -0.00130555727934 -0.0013597470108 179 9431\n",
      "Iteration 350/500: 43.7519220941 -0.00142824876618 -0.00097910396056 184 9382\n",
      "Iteration 360/500: 43.7489682307 -0.0014521249952 -0.000727945635746 203 9472\n",
      "Iteration 370/500: 43.747434798 -0.0015199507766 -0.00146426856454 186 9464\n",
      "Iteration 380/500: 43.7462963898 -0.00107656073446 -0.000909899540988 182 9365\n",
      "Iteration 390/500: 43.7454615363 -0.00127272763934 -0.00201125510263 201 9574\n",
      "Iteration 400/500: 43.7455454476 -0.000598579404976 -0.00125174319268 185 9565\n",
      "Iteration 410/500: 43.742761823 -0.00137488647325 -0.00489898674939 180 9444\n",
      "Iteration 420/500: 43.7414976583 -0.00137857264711 -0.000943370351395 166 9600\n",
      "Iteration 430/500: 43.7408796871 -0.00136805837693 -0.00100746139274 194 9189\n",
      "Iteration 440/500: 43.7398135838 -0.00151659335155 -0.00105117335519 191 9403\n",
      "Iteration 450/500: 43.7403871929 -0.00128293961943 -0.000754658897789 177 9364\n",
      "Iteration 460/500: 43.739081447 -0.000785425834741 -0.00106201660372 176 9294\n",
      "Iteration 470/500: 43.7387076976 -0.00132859968467 -0.000787769924766 180 9555\n",
      "Iteration 480/500: 43.7359671377 -0.00103290499475 -0.00077460396304 206 9108\n",
      "Iteration 490/500: 43.7362470554 -0.00150785879522 -0.000897547968122 205 8904\n",
      "\n",
      "--Done--\n",
      "Time took: 664.6675848960876s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for i in range(500): \n",
    "    update(vectors,W,H,lr)\n",
    "    if i % 10 == 0: \n",
    "        print (\"Iteration {}/500: \".format(i), end='')\n",
    "        report(vectors,W,H)\n",
    "print(\"\\n--Done--\")\n",
    "print(\"Time took: {}s\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['space nasa launch shuttle orbit lunar moon earth',\n",
       " 'ico bobbe tek bronx beauchaine manhattan sank queens',\n",
       " 'god people jesus bible believe atheism christian objective',\n",
       " 'just don like think know did say people',\n",
       " 'thanks graphics files image file program windows format']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_topics(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| SVD from linalg module | NMF from sklearn | NMF using SGD & numpy |\n",
    "|---|---|---|\n",
    "|48.1s|12.6s|664.67s|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: NMF with SGD & numpy takes this much time, because of the large number of iterations. We also get a decent result with less number of iterations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

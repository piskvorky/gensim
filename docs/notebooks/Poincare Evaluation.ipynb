{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Poincare Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how well poincare embeddings trained using this [implementation](https://github.com/TatsuyaShirakawa/poincare-embedding) perform on the tasks detailed in the [original paper](https://arxiv.org/pdf/1705.08039.pdf).\n",
    "\n",
    "This is the list of tasks - \n",
    "1. WordNet reconstruction\n",
    "2. WordNet link prediction\n",
    "3. Link prediction in collaboration networks\n",
    "4. Lexical entailment on HyperLex\n",
    "\n",
    "A more detailed explanation of the tasks and the evaluation methodology is present in the individual evaluation subsections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "The following code clones the `poincare-embedding` repository containing the C++ implementation of the Poincare embeddings, and applies a patch containing minor additions to the implementation. Please set the variable `parent_directory` below to define the directory to which the repository is cloned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The poincare datasets, models and c++ source code are downloaded to this directory\n",
    "parent_directory = './poincare/'\n",
    "! mkdir -p {parent_directory}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jayant/projects/gensim/docs/notebooks/poincare\n",
      "Cloning into 'poincare-embedding'...\n",
      "remote: Counting objects: 96, done.\u001b[K\n",
      "remote: Total 96 (delta 0), reused 0 (delta 0), pack-reused 96\u001b[K\n",
      "Unpacking objects: 100% (96/96), done.\n",
      "Checking connectivity... done.\n",
      "/home/jayant/projects/gensim/docs/notebooks/poincare/poincare-embedding\n"
     ]
    }
   ],
   "source": [
    "# Clone repo\n",
    "% cd {parent_directory}\n",
    "repo_name = 'poincare-embedding'\n",
    "! git clone https://github.com/TatsuyaShirakawa/poincare-embedding.git {repo_name}\n",
    "% cd {repo_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jayant/projects/gensim/docs/notebooks\n"
     ]
    }
   ],
   "source": [
    "# Apply patch\n",
    "! git apply ../poincare_burn_in_eps.patch\n",
    "% cd {current_directory}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the instructions in the [README](https://github.com/TatsuyaShirakawa/poincare-embedding/blob/master/README.md) to compile the sources in the poincare directory and create the binaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training\n",
    "\n",
    "### 2.1 Create the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These directories are auto created in the current directory for storing poincare datasets and models\n",
    "data_directory = os.path.join(parent_directory, 'data')\n",
    "models_directory = os.path.join(parent_directory, 'models')\n",
    "\n",
    "# Create directories\n",
    "! mkdir -p {data_directory}\n",
    "! mkdir -p {models_directory}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82115 nouns\n",
      "743241 hypernyms\n"
     ]
    }
   ],
   "source": [
    "# Prepare the WordNet data\n",
    "wordnet_file = os.path.join(data_directory, 'wordnet_noun_hypernyms.tsv')\n",
    "! python {parent_directory}/poincare-embedding/scripts/create_wordnet_noun_hierarchy.py {wordnet_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-10-23 12:50:28--  http://people.ds.cam.ac.uk/iv250/paper/hyperlex/hyperlex-data.zip\n",
      "Resolving people.ds.cam.ac.uk (people.ds.cam.ac.uk)... 131.111.3.47\n",
      "Connecting to people.ds.cam.ac.uk (people.ds.cam.ac.uk)|131.111.3.47|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 183900 (180K) [application/zip]\n",
      "Saving to: ‘./poincare/data/hyperlex-data.zip’\n",
      "\n",
      "./poincare/data/hyp 100%[===================>] 179.59K  --.-KB/s    in 0.06s   \n",
      "\n",
      "2017-10-23 12:50:28 (2.93 MB/s) - ‘./poincare/data/hyperlex-data.zip’ saved [183900/183900]\n",
      "\n",
      "Archive:  ./poincare/data/hyperlex-data.zip\n",
      "   creating: ./poincare/data/nouns-verbs/\n",
      "  inflating: ./poincare/data/nouns-verbs/hyperlex-verbs.txt  \n",
      "  inflating: ./poincare/data/nouns-verbs/hyperlex-nouns.txt  \n",
      "   creating: ./poincare/data/splits/\n",
      "   creating: ./poincare/data/splits/random/\n",
      "  inflating: ./poincare/data/splits/random/hyperlex_training_all_random.txt  \n",
      "  inflating: ./poincare/data/splits/random/hyperlex_test_all_random.txt  \n",
      "  inflating: ./poincare/data/splits/random/hyperlex_dev_all_random.txt  \n",
      "   creating: ./poincare/data/splits/lexical/\n",
      "  inflating: ./poincare/data/splits/lexical/hyperlex_dev_all_lexical.txt  \n",
      "  inflating: ./poincare/data/splits/lexical/hyperlex_test_all_lexical.txt  \n",
      "  inflating: ./poincare/data/splits/lexical/hyperlex_training_all_lexical.txt  \n",
      "  inflating: ./poincare/data/hyperlex-all.txt  \n",
      "  inflating: ./poincare/data/README.txt  \n"
     ]
    }
   ],
   "source": [
    "# Prepare the HyperLex data\n",
    "hyperlex_url = \"http://people.ds.cam.ac.uk/iv250/paper/hyperlex/hyperlex-data.zip\"\n",
    "! wget {hyperlex_url} -O {data_directory}/hyperlex-data.zip\n",
    "! unzip {data_directory}/hyperlex-data.zip -d {data_directory}\n",
    "hyperlex_file = os.path.join(data_directory, 'nouns-verbs', 'hyperlex-nouns.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Training C++ embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import check_output\n",
    "\n",
    "def train_cpp_model(\n",
    "    binary_path, data_file, output_file, dim, epochs, neg,\n",
    "    num_threads, epsilon, burn_in, seed=0):\n",
    "    \"\"\"Train a poincare embedding using the c++ implementation\n",
    "    \n",
    "    Args:\n",
    "        binary_path (str): Path to the compiled c++ implementation binary\n",
    "        data_file (str): Path to tsv file containing relation pairs\n",
    "        output_file (str): Path to output file containing model\n",
    "        dim (int): Number of dimensions of the trained model\n",
    "        epochs (int): Number of epochs to use\n",
    "        neg (int): Number of negative samples to use\n",
    "        num_threads (int): Number of threads to use for training the model\n",
    "        epsilon (float): Constant used for clipping below a norm of one\n",
    "        burn_in (int): Number of epochs to use for burn-in init (0 means no burn-in)\n",
    "    \n",
    "    Notes: \n",
    "        If `output_file` already exists, skips training\n",
    "    \"\"\"\n",
    "    if os.path.exists(output_file):\n",
    "        print('File %s exists, skipping' % output_file)\n",
    "        return\n",
    "    args = {\n",
    "        'dim': dim,\n",
    "        'max_epoch': epochs,\n",
    "        'neg_size': neg,\n",
    "        'num_thread': num_threads,\n",
    "        'epsilon': epsilon,\n",
    "        'burn_in': burn_in,\n",
    "        'learning_rate_init': 0.1,\n",
    "        'learning_rate_final': 0.0001,\n",
    "    }\n",
    "    cmd = [binary_path, data_file, output_file]\n",
    "    for option, value in args.items():\n",
    "        cmd.append(\"--%s\" % option)\n",
    "        cmd.append(str(value))\n",
    "    \n",
    "    return check_output(args=cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpp_binary_path = os.path.join(parent_directory, 'poincare-embedding', 'work', 'poincare_embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sizes = [5, 10, 20, 50, 100, 200]\n",
    "default_params = {\n",
    "    'neg': 20,\n",
    "    'epochs': 50,\n",
    "    'threads': 8,\n",
    "    'eps': 1e-6,\n",
    "    'burn_in': 0,\n",
    "}\n",
    "\n",
    "non_default_params = {\n",
    "    'neg': [10],\n",
    "    'epochs': [100, 200],\n",
    "    'threads': [1],\n",
    "    'eps': [1e-5],\n",
    "    'burn_in': [5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_files = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def model_name_from_params(params, prefix):\n",
    "    name = ['%s_%s' % (key, params[key]) for key in sorted(params.keys())]\n",
    "    return '%s_%s' % (prefix, '_'.join(name))\n",
    "\n",
    "\n",
    "def train_model_with_params(params, train_file, model_sizes, prefix):\n",
    "    \"\"\"Trains models with given params for multiple model sizes using the C++ implementation\n",
    "    \n",
    "    Args:\n",
    "        params (dict): parameters to train the model with, passed to `train_cpp_model`\n",
    "        train_file (str): Path to tsv file containing relation pairs\n",
    "        model_sizes (list): list of dimension sizes (integer) to train the model with\n",
    "        prefix (str): prefix to use for the saved model filenames\n",
    "   \n",
    "   Returns:\n",
    "        tuple (model_name, model_files)\n",
    "        model_files is a dict of (size, filename) pairs\n",
    "        Example: ('cpp_model_epochs_50', {5: 'models/cpp_model_epochs_50_dim_5'})\n",
    "    \"\"\"\n",
    "    files = {}\n",
    "    model_name = model_name_from_params(params, prefix)\n",
    "    for model_size in model_sizes:\n",
    "        output_file_name = '%s_dim_%d' % (model_name, model_size)\n",
    "        output_file = os.path.join(models_directory, output_file_name)\n",
    "        print('Training model %s' % output_file)\n",
    "        out = train_cpp_model(\n",
    "            cpp_binary_path, train_file, output_file, model_size,\n",
    "            params['epochs'], params['neg'], params['threads'],\n",
    "            params['eps'], params['burn_in'], seed=0)\n",
    "        files[model_size] = output_file\n",
    "    return (model_name, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train models with default params\n",
    "model_name, files = train_model_with_params(default_params, wordnet_file, model_sizes, 'cpp_model')\n",
    "model_files[model_name] = {}\n",
    "for dim, filepath in files.items():\n",
    "    model_files[model_name][dim] = filepath\n",
    "# Train models with non-default params\n",
    "for param, values in non_default_params.items():\n",
    "    params = default_params.copy()\n",
    "    for value in values:\n",
    "        params[param] = value\n",
    "        model_name, files = train_model_with_params(params, wordnet_file, model_sizes, 'cpp_model')\n",
    "        model_files[model_name] = {}\n",
    "        for dim, filepath in files.items():\n",
    "            model_files[model_name][dim] = filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 C++ embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import numpy as np\n",
    "from pygtrie import Trie\n",
    "from scipy.spatial.distance import euclidean, pdist\n",
    "from smart_open import smart_open\n",
    "\n",
    "def transform_cpp_embedding_to_kv(input_file, output_file, encoding='utf8'):\n",
    "    \"\"\"Given a C++ embedding tsv filepath, converts it to a KeyedVector-supported file\"\"\"\n",
    "    with smart_open(input_file, 'rb') as f:\n",
    "        lines = [line.decode(encoding) for line in f]\n",
    "    if not len(lines):\n",
    "         raise ValueError(\"file is empty\")\n",
    "    first_line = lines[0]\n",
    "    parts = first_line.rstrip().split(\"\\t\")\n",
    "    model_size = len(parts) - 1\n",
    "    vocab_size = len(lines)\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write('%d %d\\n' % (vocab_size, model_size))\n",
    "        for line in lines:\n",
    "            f.write(line.replace('\\t', ' '))\n",
    "\n",
    "        \n",
    "class PoincareEmbedding(object):\n",
    "    \"\"\"Load and perform distance operations on poincare embedding\"\"\"\n",
    "\n",
    "    def __init__(self, keyed_vectors):\n",
    "        \"\"\"Initialize PoincareEmbedding via a KeyedVectors instance\"\"\"\n",
    "        self.kv = keyed_vectors\n",
    "        self.init_key_trie()\n",
    "        \n",
    "    def init_key_trie(self):\n",
    "        \"\"\"Setup trie containing vocab keys for quick prefix lookups\"\"\"\n",
    "        self.key_trie = Trie()\n",
    "        for key in self.kv.vocab:\n",
    "            self.key_trie[key] = True\n",
    "    \n",
    "    @staticmethod\n",
    "    def poincare_dist(vector_1, vector_2):\n",
    "        \"\"\"Return poincare distance between two vectors\"\"\"\n",
    "        norm_1 = np.linalg.norm(vector_1)\n",
    "        norm_2 = np.linalg.norm(vector_2)\n",
    "        euclidean_dist = euclidean(vector_1, vector_2)\n",
    "        return np.arccosh(\n",
    "            1 + 2 * (\n",
    "                (euclidean_dist ** 2) / ((1 - norm_1 ** 2) * (1 - norm_2 ** 2))\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    @classmethod\n",
    "    def load_poincare_cpp(cls, input_filename):\n",
    "        \"\"\"Load embedding trained via C++ Poincare model\n",
    "\n",
    "        Args:\n",
    "            filepath (str): Path to tsv file containing embedding\n",
    "\n",
    "        Returns:\n",
    "            PoincareEmbedding instance\n",
    "\n",
    "        \"\"\"\n",
    "        keyed_vectors_filename = input_filename + '.kv'\n",
    "        transform_cpp_embedding_to_kv(input_filename, keyed_vectors_filename)\n",
    "        keyed_vectors = KeyedVectors.load_word2vec_format(keyed_vectors_filename)\n",
    "        os.unlink(keyed_vectors_filename)\n",
    "        return cls(keyed_vectors)\n",
    "\n",
    "    @classmethod\n",
    "    def load_poincare_numpy(cls, input_filename):\n",
    "        \"\"\"Load embedding trained via Python numpy Poincare model\n",
    "\n",
    "        Args:\n",
    "            filepath (str): Path to pkl file containing embedding\n",
    "\n",
    "        Returns:\n",
    "            PoincareEmbedding instance\n",
    "\n",
    "        \"\"\"\n",
    "        keyed_vectors_filename = input_filename + '.kv'\n",
    "        transform_numpy_embedding_to_kv(input_filename, keyed_vectors_filename)\n",
    "        keyed_vectors = KeyedVectors.load_word2vec_format(keyed_vectors_filename)\n",
    "        os.unlink(keyed_vectors_filename)\n",
    "        return cls(keyed_vectors)\n",
    "    \n",
    "    def find_matching_keys(self, word):\n",
    "        \"\"\"Find all senses of given word in embedding vocabulary\"\"\"\n",
    "        matches = self.key_trie.items('%s.' % word)\n",
    "        matching_keys = [''.join(key_chars) for key_chars, value in matches]\n",
    "        return matching_keys\n",
    "\n",
    "    def get_vector(self, term):\n",
    "        \"\"\"Return vector for given term\"\"\"\n",
    "        return self.kv.word_vec(term)\n",
    "        \n",
    "    def get_all_distances(self, term):\n",
    "        \"\"\"Return distances to all terms for given term, including itself\"\"\"\n",
    "        term_vector = self.kv.word_vec(term)\n",
    "        all_vectors = self.kv.syn0\n",
    "        \n",
    "        euclidean_dists = np.linalg.norm(term_vector - all_vectors, axis=1)\n",
    "        norm = np.linalg.norm(term_vector)\n",
    "        all_norms = np.linalg.norm(all_vectors, axis=1)\n",
    "        return np.arccosh(\n",
    "            1 + 2 * (\n",
    "                (euclidean_dists ** 2) / ((1 - norm ** 2) * (1 - all_norms ** 2))\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    def get_distance(self, term_1, term_2):\n",
    "        \"\"\"Returns distance between vectors for input terms\n",
    "\n",
    "        Args:\n",
    "            term_1 (str)\n",
    "            term_2 (str)\n",
    "\n",
    "        Returns:\n",
    "            Poincare distance between the two terms (float)\n",
    "        \n",
    "        Note:\n",
    "            Raises KeyError if either term_1 or term_2 is absent from vocabulary\n",
    "\n",
    "        \"\"\"\n",
    "        vector_1, vector_2 = self.kv[term_1], self.kv[term_2]\n",
    "        return self.poincare_dist(vector_1, vector_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, models in model_files.items():\n",
    "    embeddings[model_name] = {}\n",
    "    for model_size, model_file in models.items():\n",
    "        embeddings[model_name][model_size] = PoincareEmbedding.load_poincare_cpp(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Numpy embeddings\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def display_results(task_name, results):\n",
    "    \"\"\"Display evaluation results of multiple embeddings on a single task in a tabular format\n",
    "    \n",
    "    Args:\n",
    "        task_name (str): name the task being evaluated\n",
    "        results (dict): mapping between embeddings and corresponding results\n",
    "    \n",
    "    \"\"\"\n",
    "    data = PrettyTable()\n",
    "    data.field_names = [\"Model Description\", \"Metric\"] + [str(dim) for dim in sorted(model_sizes)]\n",
    "    for model_name, model_results in results.items():\n",
    "        metrics = [metric for metric in model_results.keys()]\n",
    "        dims = sorted([dim for dim in model_results[metrics[0]].keys()])\n",
    "        row = [model_name, '\\n'.join(metrics) + '\\n']\n",
    "        for dim in dims:\n",
    "            scores = ['%.2f' % model_results[metric][dim] for metric in metrics]\n",
    "            row.append('\\n'.join(scores))\n",
    "        data.add_row(row)\n",
    "    data.align = 'r'\n",
    "    data_cols = data.get_string().split('\\n')[0].split('+')[1:-1]\n",
    "    col_lengths = [len(col) for col in data_cols]\n",
    "    header_col_1_length = col_lengths[0] + col_lengths[1] - 1\n",
    "    header_col_2_length = sum(col_lengths[2:]) + len(col_lengths[2:-1]) - 2\n",
    "    \n",
    "    header_col_2_content = \"Model Dimensions\"\n",
    "    header_col_2_left_margin = (header_col_2_length - len(header_col_2_content)) // 2\n",
    "    header_col_2_right_margin = header_col_2_length - len(header_col_2_content) - header_col_2_left_margin\n",
    "    header_col_2_string = \"%s%s%s\" % (\n",
    "        \" \" * header_col_2_left_margin, header_col_2_content, \" \" * header_col_2_right_margin)\n",
    "    header = PrettyTable()\n",
    "    header.field_names = [\" \" * header_col_1_length, header_col_2_string]\n",
    "    header_lines = header.get_string(start=0, end=0).split(\"\\n\")[:2]\n",
    "    print('Results for %s task' % task_name)\n",
    "    print(\"\\n\".join(header_lines))\n",
    "    print(data)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 WordNet reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict, OrderedDict\n",
    "import itertools\n",
    "\n",
    "\n",
    "class ReconstructionEvaluation(object):\n",
    "    \"\"\"Evaluating reconstruction on given network for given embedding\"\"\"\n",
    "    def __init__(self, filepath, embedding):\n",
    "        \"\"\"Initialize evaluation instance with tsv file containing relation pairs and embedding to be evaluated\n",
    "        \n",
    "        Args:\n",
    "            filepath (str): path to tsv file containing relation pairs\n",
    "            embedding (PoincareEmbedding instance): embedding to be evaluated\n",
    "        \n",
    "        Returns\n",
    "            ReconstructionEvaluation instance\n",
    "\n",
    "        \"\"\"\n",
    "        items = set()\n",
    "        embedding_vocab = embedding.kv.vocab\n",
    "        relations = defaultdict(set)\n",
    "        with smart_open(filepath, 'r') as f:\n",
    "            reader = csv.reader(f, delimiter='\\t')\n",
    "            for row in reader:\n",
    "                assert len(row) == 2, 'Hypernym pair has more than two items'\n",
    "                item_1_index = embedding_vocab[row[0]].index\n",
    "                item_2_index = embedding_vocab[row[1]].index\n",
    "                relations[item_1_index].add(item_2_index)\n",
    "                items.update([item_1_index, item_2_index])\n",
    "        self.items = items\n",
    "        self.relations = relations\n",
    "        self.embedding = embedding\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def get_positive_relation_ranks_and_avg_prec(all_distances, positive_relations):\n",
    "        \"\"\"\n",
    "        Given a numpy array of all distances from an item and indices of its positive relations,\n",
    "        compute ranks and Average Precision of positive relations\n",
    "        \n",
    "        Args:\n",
    "            distances (numpy float array): np array of all distances for a specific item\n",
    "            positive_relations (list): list of indices of positive relations for the item\n",
    "        \n",
    "        Returns:\n",
    "            tuple of (ranks, avg_precision)\n",
    "            `ranks` is a list of ranks (int) of positive relations in the same order as `positive_relations`\n",
    "            `avg_precision` is a float representing the Average Precision of the ranking\n",
    "        \"\"\"\n",
    "        positive_relation_distances = all_distances[positive_relations]\n",
    "        negative_relation_distances = np.ma.array(all_distances, mask=False)\n",
    "        negative_relation_distances.mask[positive_relations] = True\n",
    "        # Compute how many negative relation distances are less than each positive relation distance, plus 1 for rank\n",
    "        ranks = (negative_relation_distances < positive_relation_distances[:, np.newaxis]).sum(axis=1) + 1\n",
    "        map_ranks = np.sort(ranks) + np.arange(len(ranks))\n",
    "        avg_precision = ((np.arange(1, len(map_ranks) + 1) / np.sort(map_ranks)).mean())\n",
    "        return list(ranks), avg_precision\n",
    "    \n",
    "    def evaluate(self, max_n=None):\n",
    "        \"\"\"Evaluate all defined metrics for the reconstruction task\n",
    "            \n",
    "        Args:\n",
    "            max_n (int or None): Maximum number of positive relations to evaluate, all if max_n is None\n",
    "        \n",
    "        Returns:\n",
    "            dict containing (metric_name, metric_value) pairs\n",
    "            e.g. {'mean_rank': 50.3, 'MAP': 0.31}\n",
    "\n",
    "        \"\"\"\n",
    "        mean_rank, map_ = self.evaluate_mean_rank_and_map(max_n)\n",
    "        return {'mean_rank': mean_rank, 'MAP': map_}\n",
    "\n",
    "    def evaluate_mean_rank_and_map(self, max_n=None):\n",
    "        \"\"\"Evaluate mean rank and MAP for reconstruction\n",
    "            \n",
    "        Args:\n",
    "            max_n (int or None): Maximum number of positive relations to evaluate, all if max_n is None\n",
    "        \n",
    "        Returns:\n",
    "            tuple of (mean_rank, MAP)\n",
    "\n",
    "        \"\"\"\n",
    "        ranks = []\n",
    "        avg_precision_scores = []\n",
    "        for i, item in enumerate(self.items, start=1):\n",
    "            if item not in self.relations:\n",
    "                continue\n",
    "            item_relations = list(self.relations[item])\n",
    "            item_term = self.embedding.kv.index2word[item]\n",
    "            item_distances = self.embedding.get_all_distances(item_term)\n",
    "            positive_relation_ranks, avg_precision = self.get_positive_relation_ranks_and_avg_prec(item_distances, item_relations)\n",
    "            ranks += positive_relation_ranks\n",
    "            avg_precision_scores.append(avg_precision)\n",
    "            if max_n is not None and i > max_n:\n",
    "                break\n",
    "        return np.mean(ranks), np.mean(avg_precision_scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_results = {}\n",
    "metrics = ['mean_rank', 'MAP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for model_name, models in embeddings.items():\n",
    "    reconstruction_results[model_name] = OrderedDict()\n",
    "    for metric in metrics:\n",
    "        reconstruction_results[model_name][metric] = {}\n",
    "    for model_size, embedding in models.items():\n",
    "        print('Evaluating model %s of size %d' % (model_name, model_size))\n",
    "        eval_instance = ReconstructionEvaluation(wordnet_file, embedding)\n",
    "        eval_result = eval_instance.evaluate(max_n=1000)\n",
    "        for metric in metrics:\n",
    "            reconstruction_results[model_name][metric][model_size] = eval_result[metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for WordNet Reconstruction task\n",
      "+-----------------------------------------------------------------------+-----------------------------------------------------+\n",
      "|                                                                       |                  Model Dimensions                   |\n",
      "+-----------------------------------------------------------+-----------+--------+--------+--------+--------+--------+--------+\n",
      "|                                         Model Description |    Metric |      5 |     10 |     20 |     50 |    100 |    200 |\n",
      "+-----------------------------------------------------------+-----------+--------+--------+--------+--------+--------+--------+\n",
      "|  cpp_model_burn_in_0_epochs_50_eps_1e-06_neg_20_threads_8 | mean_rank | 265.72 | 116.94 |  90.81 |  59.47 |  55.14 |  54.31 |\n",
      "|                                                           |       MAP |   0.28 |   0.41 |   0.49 |   0.56 |   0.58 |   0.59 |\n",
      "|                                                           |           |        |        |        |        |        |        |\n",
      "| cpp_model_burn_in_0_epochs_100_eps_1e-06_neg_20_threads_8 | mean_rank | 228.70 | 112.40 |  81.00 |  64.81 |  57.15 |  70.87 |\n",
      "|                                                           |       MAP |   0.31 |   0.42 |   0.49 |   0.53 |   0.56 |   0.54 |\n",
      "|                                                           |           |        |        |        |        |        |        |\n",
      "|  cpp_model_burn_in_0_epochs_50_eps_1e-06_neg_10_threads_8 | mean_rank | 280.17 | 129.46 |  92.06 |  80.41 |  71.42 |  69.30 |\n",
      "|                                                           |       MAP |   0.27 |   0.40 |   0.49 |   0.53 |   0.56 |   0.56 |\n",
      "|                                                           |           |        |        |        |        |        |        |\n",
      "|  cpp_model_burn_in_0_epochs_50_eps_1e-06_neg_20_threads_1 | mean_rank | 308.69 | 101.92 |  73.20 |  56.17 |  52.97 |  51.37 |\n",
      "|                                                           |       MAP |   0.27 |   0.43 |   0.53 |   0.61 |   0.64 |   0.65 |\n",
      "|                                                           |           |        |        |        |        |        |        |\n",
      "|  cpp_model_burn_in_5_epochs_50_eps_1e-06_neg_20_threads_8 | mean_rank | 227.69 | 175.64 | 171.60 | 144.47 | 146.84 | 139.28 |\n",
      "|                                                           |       MAP |   0.27 |   0.33 |   0.35 |   0.37 |   0.37 |   0.38 |\n",
      "|                                                           |           |        |        |        |        |        |        |\n",
      "|  cpp_model_burn_in_0_epochs_50_eps_1e-05_neg_20_threads_8 | mean_rank | 245.48 | 104.66 |  88.33 |  65.40 |  74.88 |  55.66 |\n",
      "|                                                           |       MAP |   0.28 |   0.42 |   0.50 |   0.56 |   0.56 |   0.57 |\n",
      "|                                                           |           |        |        |        |        |        |        |\n",
      "| cpp_model_burn_in_0_epochs_200_eps_1e-06_neg_20_threads_8 | mean_rank | 191.69 |  97.65 |  72.07 |  55.48 |  46.76 |  49.62 |\n",
      "|                                                           |       MAP |   0.34 |   0.43 |   0.51 |   0.57 |   0.59 |   0.59 |\n",
      "|                                                           |           |        |        |        |        |        |        |\n",
      "| cpp_model_burn_in_10_epochs_50_eps_1e-06_neg_20_threads_8 | mean_rank | 252.86 | 195.73 | 182.57 | 165.33 | 157.37 | 155.78 |\n",
      "|                                                           |       MAP |   0.26 |   0.32 |   0.34 |   0.36 |   0.36 |   0.36 |\n",
      "|                                                           |           |        |        |        |        |        |        |\n",
      "+-----------------------------------------------------------+-----------+--------+--------+--------+--------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "display_results('WordNet Reconstruction', reconstruction_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 WordNet link prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def train_test_split(data_file, test_ratio=0.1):\n",
    "    \"\"\"Creates train and test files from given data file, returns train/test file names\n",
    "    \n",
    "    Args:\n",
    "        data_file (str): path to data file for which train/test split is to be created\n",
    "        test_ratio (float): fraction of lines to be used for test data\n",
    "    \n",
    "    Returns\n",
    "        (train_file, test_file): tuple of strings with train file and test file paths\n",
    "    \"\"\"\n",
    "    root_nodes, leaf_nodes = get_root_and_leaf_nodes(data_file)\n",
    "    test_line_candidates = []\n",
    "    line_count = 0\n",
    "    all_nodes = set()\n",
    "    with open(data_file, 'rb') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            node_1, node_2 = line.split()\n",
    "            all_nodes.update([node_1, node_2])\n",
    "            if (\n",
    "                    node_1 not in leaf_nodes\n",
    "                    and node_2 not in leaf_nodes\n",
    "                    and node_1 not in root_nodes\n",
    "                    and node_2 not in root_nodes\n",
    "                    and node_1 != node_2\n",
    "                ):\n",
    "                test_line_candidates.append(i)\n",
    "            line_count += 1\n",
    "\n",
    "    num_test_lines = int(test_ratio * line_count)\n",
    "    if num_test_lines > len(test_line_candidates):\n",
    "        raise ValueError('Not enough candidate relations for test set')\n",
    "    print('Choosing %d test lines from %d candidates' % (num_test_lines, len(test_line_candidates)))\n",
    "    test_line_indices = set(random.sample(test_line_candidates, num_test_lines))\n",
    "    train_line_indices = set(l for l in range(line_count) if l not in test_line_indices)\n",
    "    \n",
    "    train_filename = data_file + '.train'\n",
    "    test_filename = data_file + '.test'\n",
    "    train_set_nodes = set()\n",
    "    with open(data_file, 'rb') as f:\n",
    "        train_file = open(train_filename, 'wb')\n",
    "        test_file = open(test_filename, 'wb')\n",
    "        for i, line in enumerate(f):\n",
    "            if i in train_line_indices:\n",
    "                train_set_nodes.update(line.split())\n",
    "                train_file.write(line)\n",
    "            elif i in test_line_indices:\n",
    "                test_file.write(line)\n",
    "            else:\n",
    "                raise AssertionError('Line %d not present in either train or test line indices' % i)\n",
    "        train_file.close()\n",
    "        test_file.close()\n",
    "    assert len(train_set_nodes) == len(all_nodes), 'Not all nodes from dataset present in train set relations'\n",
    "    return (train_filename, test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_root_and_leaf_nodes(data_file):\n",
    "    \"\"\"Return keys of root and leaf nodes from a file with transitive closure relations\n",
    "    \n",
    "    Args:\n",
    "        data_file(str): file path containing transitive closure relations\n",
    "    \n",
    "    Returns:\n",
    "        (root_nodes, leaf_nodes) - tuple containing keys of root and leaf nodes\n",
    "    \"\"\"\n",
    "    root_candidates = set()\n",
    "    leaf_candidates = set()\n",
    "    with open(data_file, 'rb') as f:\n",
    "        for line in f:\n",
    "            nodes = line.split()\n",
    "            root_candidates.update(nodes)\n",
    "            leaf_candidates.update(nodes)\n",
    "    \n",
    "    with open(data_file, 'rb') as f:\n",
    "        for line in f:\n",
    "            node_1, node_2 = line.split()\n",
    "            if node_1 == node_2:\n",
    "                continue\n",
    "            leaf_candidates.discard(node_1)\n",
    "            root_candidates.discard(node_2)\n",
    "    \n",
    "    return (leaf_candidates, root_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choosing 74324 test lines from 109577 candidates\n"
     ]
    }
   ],
   "source": [
    "wordnet_train_file, wordnet_test_file = train_test_split(wordnet_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 Training and loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training models for link prediction\n",
    "lp_model_files = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models with default params\n",
    "model_name, files = train_model_with_params(default_params, wordnet_train_file, model_sizes, 'cpp_lp_model')\n",
    "lp_model_files[model_name] = {}\n",
    "for dim, filepath in files.items():\n",
    "    lp_model_files[model_name][dim] = filepath\n",
    "# Train models with non-default params\n",
    "for param, values in non_default_params.items():\n",
    "    params = default_params.copy()\n",
    "    for value in values:\n",
    "        params[param] = value\n",
    "        model_name, files = train_model_with_params(params, wordnet_train_file, model_sizes, 'cpp_lp_model')\n",
    "        lp_model_files[model_name] = {}\n",
    "        for dim, filepath in files.items():\n",
    "            lp_model_files[model_name][dim] = filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_embeddings = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, models in lp_model_files.items():\n",
    "    lp_embeddings[model_name] = {}\n",
    "    for model_size, model_file in models.items():\n",
    "        lp_embeddings[model_name][model_size] = PoincareEmbedding.load_poincare_cpp(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3 Evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkPredictionEvaluation(object):\n",
    "    \"\"\"Evaluating reconstruction on given network for given embedding\"\"\"\n",
    "    def __init__(self, train_path, test_path, embedding):\n",
    "        \"\"\"Initialize evaluation instance with tsv file containing relation pairs and embedding to be evaluated\n",
    "        \n",
    "        Args:\n",
    "            train_path (str): path to tsv file containing relation pairs used for training\n",
    "            test_path (str): path to tsv file containing relation pairs to evaluate\n",
    "            embedding (PoincareEmbedding instance): embedding to be evaluated\n",
    "        \n",
    "        Returns\n",
    "            LinkPredictionEvaluation instance\n",
    "\n",
    "        \"\"\"\n",
    "        items = set()\n",
    "        embedding_vocab = embedding.kv.vocab\n",
    "        relations = {'known': defaultdict(set), 'unknown': defaultdict(set)}\n",
    "        data_files = {'known': train_path, 'unknown': test_path}\n",
    "        for relation_type, data_file in data_files.items():\n",
    "            with smart_open(data_file, 'r') as f:\n",
    "                reader = csv.reader(f, delimiter='\\t')\n",
    "                for row in reader:\n",
    "                    assert len(row) == 2, 'Hypernym pair has more than two items'\n",
    "                    item_1_index = embedding_vocab[row[0]].index\n",
    "                    item_2_index = embedding_vocab[row[1]].index\n",
    "                    relations[relation_type][item_1_index].add(item_2_index)\n",
    "                    items.update([item_1_index, item_2_index])\n",
    "        self.items = items\n",
    "        self.relations = relations\n",
    "        self.embedding = embedding\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def get_unknown_relation_ranks_and_avg_prec(all_distances, unknown_relations, known_relations):\n",
    "        \"\"\"\n",
    "        Given a numpy array of distances and indices of known and unknown positive relations,\n",
    "        compute ranks and Average Precision of unknown positive relations\n",
    "        \n",
    "        Args:\n",
    "            all_distances (numpy float array): np array of all distances for a specific item\n",
    "            unknown_relations (list): list of indices of unknown positive relations\n",
    "            known_relations (list): list of indices of known positive relations\n",
    "            \n",
    "        Returns:\n",
    "            tuple of (ranks, avg_precision)\n",
    "            `ranks` is a list of ranks (int) of unknown relations in the same order as `unknown_relations`\n",
    "            `avg_precision` is a float representing the Average Precision of the ranking\n",
    "        \"\"\"\n",
    "        unknown_relation_distances = all_distances[unknown_relations]\n",
    "        negative_relation_distances = np.ma.array(all_distances, mask=False)\n",
    "        negative_relation_distances.mask[unknown_relations] = True\n",
    "        negative_relation_distances.mask[known_relations] = True\n",
    "        # Compute how many negative relation distances are less than each unknown relation distance, plus 1 for rank\n",
    "        ranks = (negative_relation_distances < unknown_relation_distances[:, np.newaxis]).sum(axis=1) + 1\n",
    "        map_ranks = np.sort(ranks) + np.arange(len(ranks))\n",
    "        avg_precision = ((np.arange(1, len(map_ranks) + 1) / np.sort(map_ranks)).mean())\n",
    "        return list(ranks), avg_precision\n",
    "    \n",
    "    def evaluate(self, max_n=None):\n",
    "        \"\"\"Evaluate all defined metrics for the reconstruction task\n",
    "            \n",
    "        Args:\n",
    "            max_n (int or None): Maximum number of positive relations to evaluate, all if max_n is None\n",
    "        \n",
    "        Returns:\n",
    "            dict containing (metric_name, metric_value) pairs\n",
    "            e.g. {'mean_rank': 50.3, 'MAP': 0.31}\n",
    "\n",
    "        \"\"\"\n",
    "        mean_rank, map_ = self.evaluate_mean_rank_and_map(max_n)\n",
    "        return {'mean_rank': mean_rank, 'MAP': map_}\n",
    "\n",
    "    def evaluate_mean_rank_and_map(self, max_n=None):\n",
    "        \"\"\"Evaluate mean rank and MAP for reconstruction\n",
    "            \n",
    "        Args:\n",
    "            max_n (int or None): Maximum number of positive relations to evaluate, all if max_n is None\n",
    "        \n",
    "        Returns:\n",
    "            tuple of (mean_rank, MAP)\n",
    "\n",
    "        \"\"\"\n",
    "        ranks = []\n",
    "        avg_precision_scores = []\n",
    "        for i, item in enumerate(self.items, start=1):\n",
    "            if item not in self.relations['unknown']:  # No positive relations to predict for this node\n",
    "                continue\n",
    "            unknown_relations = list(self.relations['unknown'][item])\n",
    "            known_relations = list(self.relations['known'][item])\n",
    "            item_term = self.embedding.kv.index2word[item]\n",
    "            item_distances = self.embedding.get_all_distances(item_term)\n",
    "            unknown_relation_ranks, avg_precision = self.get_unknown_relation_ranks_and_avg_prec(item_distances, unknown_relations, known_relations)\n",
    "            ranks += unknown_relation_ranks\n",
    "            avg_precision_scores.append(avg_precision)\n",
    "            if max_n is not None and i > max_n:\n",
    "                break\n",
    "        return np.mean(ranks), np.mean(avg_precision_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_results = {}\n",
    "metrics = ['mean_rank', 'MAP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, models in lp_embeddings.items():\n",
    "    lp_results[model_name] = OrderedDict()\n",
    "    for metric in metrics:\n",
    "        lp_results[model_name][metric] = {}\n",
    "    for model_size, embedding in models.items():\n",
    "        print('Evaluating model %s of size %d' % (model_name, model_size))\n",
    "        eval_instance = LinkPredictionEvaluation(wordnet_train_file, wordnet_test_file, embedding)\n",
    "        eval_result = eval_instance.evaluate(max_n=1000)\n",
    "        for metric in metrics:\n",
    "            lp_results[model_name][metric][model_size] = eval_result[metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for WordNet Link Prediction task\n",
      "+--------------------------------------------------------------------------+-----------------------------------------------------+\n",
      "|                                                                          |                  Model Dimensions                   |\n",
      "+--------------------------------------------------------------+-----------+--------+--------+--------+--------+--------+--------+\n",
      "|                                            Model Description |    Metric |      5 |     10 |     20 |     50 |    100 |    200 |\n",
      "+--------------------------------------------------------------+-----------+--------+--------+--------+--------+--------+--------+\n",
      "|  cpp_lp_model_burn_in_0_epochs_50_eps_1e-05_neg_20_threads_8 | mean_rank | 182.03 | 107.04 |  63.29 |  72.67 |  73.64 |  60.35 |\n",
      "|                                                              |       MAP |   0.16 |   0.25 |   0.31 |   0.34 |   0.36 |   0.37 |\n",
      "|                                                              |           |        |        |        |        |        |        |\n",
      "| cpp_lp_model_burn_in_10_epochs_50_eps_1e-06_neg_20_threads_8 | mean_rank | 236.31 | 214.85 | 193.30 | 180.27 | 169.00 | 163.22 |\n",
      "|                                                              |       MAP |   0.10 |   0.13 |   0.14 |   0.15 |   0.16 |   0.16 |\n",
      "|                                                              |           |        |        |        |        |        |        |\n",
      "|  cpp_lp_model_burn_in_0_epochs_50_eps_1e-06_neg_20_threads_1 | mean_rank | 232.82 |  98.78 |  53.79 |  49.79 |  46.52 |  47.03 |\n",
      "|                                                              |       MAP |   0.15 |   0.25 |   0.33 |   0.39 |   0.40 |   0.41 |\n",
      "|                                                              |           |        |        |        |        |        |        |\n",
      "| cpp_lp_model_burn_in_0_epochs_100_eps_1e-06_neg_20_threads_8 | mean_rank | 190.93 | 116.63 |  68.68 |  43.67 |  55.01 |  66.02 |\n",
      "|                                                              |       MAP |   0.17 |   0.24 |   0.29 |   0.36 |   0.37 |   0.35 |\n",
      "|                                                              |           |        |        |        |        |        |        |\n",
      "|  cpp_lp_model_burn_in_0_epochs_50_eps_1e-06_neg_10_threads_8 | mean_rank | 230.34 | 123.24 |  75.62 |  65.97 |  55.33 |  56.89 |\n",
      "|                                                              |       MAP |   0.14 |   0.22 |   0.28 |   0.31 |   0.33 |   0.34 |\n",
      "|                                                              |           |        |        |        |        |        |        |\n",
      "|  cpp_lp_model_burn_in_5_epochs_50_eps_1e-06_neg_20_threads_8 | mean_rank | 224.50 | 199.29 | 184.29 | 178.89 | 155.52 | 157.39 |\n",
      "|                                                              |       MAP |   0.09 |   0.14 |   0.15 |   0.16 |   0.17 |   0.18 |\n",
      "|                                                              |           |        |        |        |        |        |        |\n",
      "|  cpp_lp_model_burn_in_0_epochs_50_eps_1e-06_neg_20_threads_8 | mean_rank | 687.48 | 281.88 |  72.95 |  57.37 |  52.56 |  61.42 |\n",
      "|                                                              |       MAP |   0.12 |   0.15 |   0.31 |   0.35 |   0.36 |   0.36 |\n",
      "|                                                              |           |        |        |        |        |        |        |\n",
      "| cpp_lp_model_burn_in_0_epochs_200_eps_1e-06_neg_20_threads_8 | mean_rank | 218.26 |  99.09 |  60.50 |  52.24 |  60.81 |  69.13 |\n",
      "|                                                              |       MAP |   0.15 |   0.24 |   0.31 |   0.35 |   0.36 |   0.36 |\n",
      "|                                                              |           |        |        |        |        |        |        |\n",
      "+--------------------------------------------------------------+-----------+--------+--------+--------+--------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "display_results('WordNet Link Prediction', lp_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 HyperLex Lexical Entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "class LexicalEntailmentEvaluation(object):\n",
    "    \"\"\"Evaluating reconstruction on given network for any embedding\"\"\"\n",
    "    def __init__(self, filepath):\n",
    "        \"\"\"Initialize evaluation instance with HyperLex text file containing relation pairs\n",
    "        \n",
    "        Args:\n",
    "            filepath (str): path to HyperLex text file\n",
    "        \n",
    "        Returns\n",
    "            LexicalEntailmentEvaluation instance\n",
    "\n",
    "        \"\"\"\n",
    "        expected_scores = {}\n",
    "        with smart_open(filepath, 'r') as f:\n",
    "            reader = csv.DictReader(f, delimiter=' ')\n",
    "            for row in reader:\n",
    "                word_1, word_2 = row['WORD1'], row['WORD2']\n",
    "                expected_scores[(word_1, word_2)] = float(row['AVG_SCORE'])\n",
    "        self.scores = expected_scores\n",
    "        self.alpha = 1000\n",
    "    \n",
    "    def score_function(self, embedding, word_1, word_2):\n",
    "        \"\"\"Given an embedding and two terms, return the predicted score for them (extent to which term_1 is a type of term_2)\"\"\"\n",
    "        try:\n",
    "            word_1_terms = embedding.find_matching_keys(word_1)\n",
    "            word_2_terms = embedding.find_matching_keys(word_2)\n",
    "        except KeyError:\n",
    "            raise ValueError(\"No matching terms found for either %s or %s\" % (word_1, word_2))\n",
    "        min_distance = np.inf\n",
    "        min_term_1, min_term_2 = None, None\n",
    "        for term_1 in word_1_terms:\n",
    "            for term_2 in word_2_terms:\n",
    "                distance = embedding.get_distance(term_1, term_2)\n",
    "                if distance < min_distance:\n",
    "                    min_term_1, min_term_2 = term_1, term_2\n",
    "                    min_distance = distance\n",
    "        assert min_term_1 is not None and min_term_2 is not None\n",
    "        vector_1, vector_2 = embedding.get_vector(min_term_1), embedding.get_vector(min_term_2)\n",
    "        norm_1, norm_2 = np.linalg.norm(vector_1), np.linalg.norm(vector_2)\n",
    "        return -1 * (1 + self.alpha * (norm_2 - norm_1)) * distance\n",
    "        \n",
    "    def evaluate_spearman(self, embedding):\n",
    "        \"\"\"Evaluate spearman scores for lexical entailment for given embedding\n",
    "            \n",
    "        Args:\n",
    "            embedding (PoincareEmbedding instance): embedding for which evaluation is to be done\n",
    "        \n",
    "        Returns:\n",
    "            spearman correlation score (float)\n",
    "\n",
    "        \"\"\"\n",
    "        predicted_scores = []\n",
    "        expected_scores = []\n",
    "        skipped = 0\n",
    "        count = 0\n",
    "        for (word_1, word_2), expected_score in self.scores.items():\n",
    "            try:\n",
    "                predicted_score = self.score_function(embedding, word_1, word_2)\n",
    "            except ValueError:\n",
    "                skipped += 1\n",
    "                continue\n",
    "            count += 1\n",
    "            predicted_scores.append(predicted_score)\n",
    "            expected_scores.append(expected_score)\n",
    "        print('Skipped pairs: %d out of %d' % (skipped, len(self.scores)))\n",
    "        spearman = spearmanr(expected_scores, predicted_scores)\n",
    "        return spearman.correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "entailment_results = {}\n",
    "eval_instance = LexicalEntailmentEvaluation(hyperlex_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, models in embeddings.items():\n",
    "    entailment_results[model_name] = {}\n",
    "    entailment_results[model_name]['spearman'] = {}\n",
    "    for model_size, embedding in models.items():\n",
    "        print('Evaluating model %s of size %d' % (model_name, model_size))\n",
    "        entailment_results[model_name]['spearman'][model_size] = eval_instance.evaluate_spearman(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Lexical Entailment (HyperLex) task\n",
      "+----------------------------------------------------------------------+-----------------------------------------+\n",
      "|                                                                      |            Model Dimensions             |\n",
      "+-----------------------------------------------------------+----------+------+------+------+------+------+------+\n",
      "|                     Model Description                     |  Metric  |  5   |  10  |  20  |  50  | 100  | 200  |\n",
      "+-----------------------------------------------------------+----------+------+------+------+------+------+------+\n",
      "|  cpp_model_burn_in_0_epochs_50_eps_1e-06_neg_10_threads_8 | spearman | 0.43 | 0.44 | 0.44 | 0.44 | 0.45 | 0.45 |\n",
      "|  cpp_model_burn_in_0_epochs_50_eps_1e-06_neg_20_threads_1 | spearman | 0.46 | 0.48 | 0.46 | 0.47 | 0.47 | 0.47 |\n",
      "| cpp_model_burn_in_0_epochs_200_eps_1e-06_neg_20_threads_8 | spearman | 0.46 | 0.47 | 0.46 | 0.46 | 0.46 | 0.47 |\n",
      "| cpp_model_burn_in_0_epochs_100_eps_1e-06_neg_20_threads_8 | spearman | 0.46 | 0.45 | 0.45 | 0.47 | 0.46 | 0.46 |\n",
      "|  cpp_model_burn_in_5_epochs_50_eps_1e-06_neg_20_threads_8 | spearman | 0.43 | 0.44 | 0.44 | 0.43 | 0.45 | 0.45 |\n",
      "| cpp_model_burn_in_10_epochs_50_eps_1e-06_neg_20_threads_8 | spearman | 0.43 | 0.43 | 0.44 | 0.45 | 0.45 | 0.45 |\n",
      "|  cpp_model_burn_in_0_epochs_50_eps_1e-06_neg_20_threads_8 | spearman | 0.46 | 0.44 | 0.48 | 0.45 | 0.47 | 0.46 |\n",
      "|  cpp_model_burn_in_0_epochs_50_eps_1e-05_neg_20_threads_8 | spearman | 0.45 | 0.46 | 0.46 | 0.47 | 0.47 | 0.46 |\n",
      "+-----------------------------------------------------------+----------+------+------+------+------+------+------+\n"
     ]
    }
   ],
   "source": [
    "display_results('Lexical Entailment (HyperLex)', entailment_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Link Prediction for collaboration networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - quite tricky, since the loss function used for training the model on this network is different\n",
    "# Will require changes to how gradients are calculated in C++ code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance improvement in Phrases module\n",
    "\n",
    "#### Author - Prakhar Pratyush (@prakhar2b)\n",
    "[Google summer of code '17 live blog](https://rare-technologies.com/google-summer-of-code-2017-live-blog-performance-improvement-in-gensim-and-fasttext/)\n",
    "\n",
    "| Optimization       | Python 2.7     | Python 3.6 | PR |\n",
    "| ------------- |:-------------:| :------------:|\n",
    "|    original  | ~ 36-38 sec | ~32-35 sec |\n",
    "| cython (static typing)      | ~30-32 sec    |\n",
    "| any2utf8 (without cython)| ~20-22 sec     | ~23-26 sec | #1413 |\n",
    "| cython (with any2utf8)| ~15-18 sec     |  ~19-21 sec |  #1385 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.1 :: Anaconda 4.4.0 (64-bit)\r\n"
     ]
    }
   ],
   "source": [
    "! python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-27 13:22:11,249 : INFO : 'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "import profile\n",
    "%load_ext autoreload\n",
    "\n",
    "import gensim\n",
    "from gensim.models.word2vec import Text8Corpus\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! git clone https://github.com/prakhar2b/gensim.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/prakhar\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! wget http://mattmahoney.net/dc/text8.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! unzip text8.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/prakhar/text8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "text8_file = os.path.abspath('text8')\n",
    "print(text8_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/prakhar/gensim\n"
     ]
    }
   ],
   "source": [
    "% cd gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already on 'develop'\r\n",
      "Your branch is up-to-date with 'origin/develop'.\r\n"
     ]
    }
   ],
   "source": [
    "!git checkout develop\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python setup.py install\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-27 13:12:26,162 : INFO : collecting all words and their counts\n",
      "2017-06-27 13:12:26,166 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2017-06-27 13:12:59,505 : INFO : collected 4400410 word types from a corpus of 17003506 words (unigram + bigrams) and 1701 sentences\n",
      "2017-06-27 13:12:59,506 : INFO : using 4400410 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n",
      "2017-06-27 13:12:59,510 : INFO : collecting all words and their counts\n",
      "2017-06-27 13:12:59,513 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2017-06-27 13:13:33,815 : INFO : collected 4400410 word types from a corpus of 17003506 words (unigram + bigrams) and 1701 sentences\n",
      "2017-06-27 13:13:33,816 : INFO : using 4400410 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n",
      "2017-06-27 13:13:33,909 : INFO : collecting all words and their counts\n",
      "2017-06-27 13:13:33,911 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2017-06-27 13:14:09,567 : INFO : collected 4400410 word types from a corpus of 17003506 words (unigram + bigrams) and 1701 sentences\n",
      "2017-06-27 13:14:09,569 : INFO : using 4400410 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n",
      "2017-06-27 13:14:09,673 : INFO : collecting all words and their counts\n",
      "2017-06-27 13:14:09,676 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2017-06-27 13:14:44,182 : INFO : collected 4400410 word types from a corpus of 17003506 words (unigram + bigrams) and 1701 sentences\n",
      "2017-06-27 13:14:44,183 : INFO : using 4400410 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n",
      "2017-06-27 13:14:44,275 : INFO : collecting all words and their counts\n",
      "2017-06-27 13:14:44,278 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2017-06-27 13:15:20,203 : INFO : collected 4400410 word types from a corpus of 17003506 words (unigram + bigrams) and 1701 sentences\n",
      "2017-06-27 13:15:20,205 : INFO : using 4400410 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 34.5 s per loop\n"
     ]
    }
   ],
   "source": [
    "# currently on develop --- original code\n",
    "from gensim.models import Phrases\n",
    "bigram = Phrases(Text8Corpus(text8_file))\n",
    "%timeit bigram = Phrases(Text8Corpus(text8_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to branch 'any2utf8'\r\n",
      "Your branch is up-to-date with 'origin/any2utf8'.\r\n"
     ]
    }
   ],
   "source": [
    "! git checkout any2utf8\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python setup.py install\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-27 13:15:25,852 : INFO : collecting all words and their counts\n",
      "2017-06-27 13:15:25,857 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2017-06-27 13:15:56,700 : INFO : collected 4400410 word types from a corpus of 17003506 words (unigram + bigrams) and 1701 sentences\n",
      "2017-06-27 13:15:56,702 : INFO : using 4400410 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n",
      "2017-06-27 13:15:56,868 : INFO : collecting all words and their counts\n",
      "2017-06-27 13:15:56,877 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2017-06-27 13:16:28,853 : INFO : collected 4400410 word types from a corpus of 17003506 words (unigram + bigrams) and 1701 sentences\n",
      "2017-06-27 13:16:28,855 : INFO : using 4400410 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n",
      "2017-06-27 13:16:28,948 : INFO : collecting all words and their counts\n",
      "2017-06-27 13:16:28,952 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2017-06-27 13:16:54,980 : INFO : collected 4400410 word types from a corpus of 17003506 words (unigram + bigrams) and 1701 sentences\n",
      "2017-06-27 13:16:54,982 : INFO : using 4400410 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n",
      "2017-06-27 13:16:55,064 : INFO : collecting all words and their counts\n",
      "2017-06-27 13:16:55,068 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2017-06-27 13:17:25,104 : INFO : collected 4400410 word types from a corpus of 17003506 words (unigram + bigrams) and 1701 sentences\n",
      "2017-06-27 13:17:25,105 : INFO : using 4400410 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n",
      "2017-06-27 13:17:25,189 : INFO : collecting all words and their counts\n",
      "2017-06-27 13:17:25,193 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2017-06-27 13:17:57,680 : INFO : collected 4400410 word types from a corpus of 17003506 words (unigram + bigrams) and 1701 sentences\n",
      "2017-06-27 13:17:57,681 : INFO : using 4400410 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 26 s per loop\n"
     ]
    }
   ],
   "source": [
    "# currently on any2utf8 \n",
    "from gensim.models import Phrases\n",
    "bigram = Phrases(Text8Corpus(text8_file))\n",
    "%timeit bigram = Phrases(Text8Corpus(text8_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to branch 'gsoc17_phrases'\r\n",
      "Your branch is up-to-date with 'origin/gsoc17_phrases'.\r\n"
     ]
    }
   ],
   "source": [
    "! git checkout gsoc17_phrases\n",
    "%autoreload \n",
    "# cython + any2utf8 optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python setup.py build_ext --inplace\n",
    "%autoreload \n",
    "!python setup.py install\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-27 13:22:19,394 : INFO : collecting all words and their counts\n",
      "2017-06-27 13:22:19,401 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2017-06-27 13:22:39,148 : INFO : collected 4400410 word types from a corpus of 17003506 words (unigram + bigrams) and 1701 sentences\n",
      "2017-06-27 13:22:39,149 : INFO : using 4400410 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n",
      "2017-06-27 13:22:39,244 : INFO : collecting all words and their counts\n",
      "2017-06-27 13:22:39,247 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2017-06-27 13:22:59,694 : INFO : collected 4400410 word types from a corpus of 17003506 words (unigram + bigrams) and 1701 sentences\n",
      "2017-06-27 13:22:59,695 : INFO : using 4400410 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n",
      "2017-06-27 13:22:59,778 : INFO : collecting all words and their counts\n",
      "2017-06-27 13:22:59,781 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2017-06-27 13:23:21,577 : INFO : collected 4400410 word types from a corpus of 17003506 words (unigram + bigrams) and 1701 sentences\n",
      "2017-06-27 13:23:21,579 : INFO : using 4400410 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n",
      "2017-06-27 13:23:21,686 : INFO : collecting all words and their counts\n",
      "2017-06-27 13:23:21,690 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2017-06-27 13:23:42,943 : INFO : collected 4400410 word types from a corpus of 17003506 words (unigram + bigrams) and 1701 sentences\n",
      "2017-06-27 13:23:42,945 : INFO : using 4400410 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n",
      "2017-06-27 13:23:43,040 : INFO : collecting all words and their counts\n",
      "2017-06-27 13:23:43,043 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2017-06-27 13:24:03,109 : INFO : collected 4400410 word types from a corpus of 17003506 words (unigram + bigrams) and 1701 sentences\n",
      "2017-06-27 13:24:03,111 : INFO : using 4400410 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 20.1 s per loop\n"
     ]
    }
   ],
   "source": [
    "# currently on gsoc17_phrases (cython) \n",
    "from gensim.models import Phrases\n",
    "bigram = Phrases(Text8Corpus(text8_file))\n",
    "%timeit bigram = Phrases(Text8Corpus(text8_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

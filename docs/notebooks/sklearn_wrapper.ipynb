{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using wrappers for Scikit learn API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial is about using gensim models as a part of your scikit learn workflow with the help of wrappers found at ```gensim.sklearn_integration```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wrappers available (as of now) are :\n",
    "* LdaModel (```gensim.sklearn_integration.sklearn_wrapper_gensim_ldaModel.SklLdaModel```),which implements gensim's ```LDA Model``` in a scikit-learn interface\n",
    "\n",
    "* LsiModel (```gensim.sklearn_integration.sklearn_wrapper_gensim_lsiModel.SklLsiModel```),which implements gensim's ```LSI Model``` in a scikit-learn interface\n",
    "\n",
    "* RpModel (```gensim.sklearn_integration.sklearn_wrapper_gensim_rpmodel.SklRpModel```),which implements gensim's ```Random Projections Model``` in a scikit-learn interface\n",
    "\n",
    "* LDASeq Model (```gensim.sklearn_integration.sklearn_wrapper_gensim_lsiModel.SklLdaSeqModel```),which implements gensim's ```LdaSeqModel``` in a scikit-learn interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use LdaModel begin with importing LdaModel wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from gensim.sklearn_integration import SklLdaModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will create a dummy set of texts and convert it into a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "texts = [\n",
    "    ['complier', 'system', 'computer'],\n",
    "    ['eulerian', 'node', 'cycle', 'graph', 'tree', 'path'],\n",
    "    ['graph', 'flow', 'network', 'graph'],\n",
    "    ['loading', 'computer', 'system'],\n",
    "    ['user', 'server', 'system'],\n",
    "    ['tree', 'hamiltonian'],\n",
    "    ['graph', 'trees'],\n",
    "    ['computer', 'kernel', 'malfunction', 'computer'],\n",
    "    ['server', 'system', 'computer']\n",
    "]\n",
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then to run the LdaModel on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.85275314,  0.14724686],\n",
       "       [ 0.12390183,  0.87609817],\n",
       "       [ 0.4612995 ,  0.5387005 ],\n",
       "       [ 0.84924177,  0.15075823],\n",
       "       [ 0.49180096,  0.50819904],\n",
       "       [ 0.40086923,  0.59913077],\n",
       "       [ 0.28454427,  0.71545573],\n",
       "       [ 0.88776198,  0.11223802],\n",
       "       [ 0.84210373,  0.15789627]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SklLdaModel(num_topics=2, id2word=dictionary, iterations=20, random_state=1)\n",
    "model.fit(corpus)\n",
    "model.transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Integration with Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To provide a better example of how it can be used with Sklearn, Let's use CountVectorizer method of sklearn. For this example we will use [20 Newsgroups data set](http://qwone.com/~jason/20Newsgroups/). We will only use the categories rec.sport.baseball and sci.crypt and use it to generate topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim import matutils\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from gensim.sklearn_integration.sklearn_wrapper_gensim_ldamodel import SklLdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rand = np.random.mtrand.RandomState(1) # set seed for getting same result\n",
    "cats = ['alt.atheism',\n",
    "        'comp.graphics',\n",
    "        'rec.autos'\n",
    "       ]\n",
    "data = fetch_20newsgroups(subset='train', categories=cats, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use use the loaded data to create our dictionary and corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_texts = [_.split() for _ in data.data]\n",
    "id2word = Dictionary(data_texts)\n",
    "corpus = [id2word.doc2bow(i.split()) for i in data.data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we just need to fit corpus and id2word to our Lda wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obj = SklLdaModel(id2word=id2word, num_topics=5, iterations=20)\n",
    "lda = obj.fit(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Example for Using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inbuilt `score` function of Lda wrapper class provides two modes : `perplexity` and `u_mass` for computing the scores of the candidate models. The preferred mode for the scoring function is specified using `scorer` parameter of the wrapper as follows : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iterations': 20, 'num_topics': 2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = SklLdaModel(id2word=id2word, num_topics=2, iterations=5, scorer='u_mass') # here 'scorer' can be 'perplexity' or 'u_mass'\n",
    "parameters = {'num_topics': (2, 3, 5, 10), 'iterations': (1, 20, 50)}\n",
    "\n",
    "# set `scoring` as `None` to use the inbuilt score function of `SklLdaModel` class\n",
    "model = GridSearchCV(obj, parameters, cv=3, scoring=None)\n",
    "model.fit(corpus)\n",
    "\n",
    "model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also supply a custom scoring function of your choice using the `scoring` parameter of `GridSearchCV` function. The example shown below uses `c_v` mode of `CoherenceModel` class for computing the scores of the candidate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iterations': 50, 'num_topics': 2}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# supplying a custom scoring function\n",
    "def scoring_function(estimator, X, y=None):\n",
    "    goodcm = CoherenceModel(model=estimator.gensim_model, texts=data_texts, dictionary=estimator.gensim_model.id2word, coherence='c_v')\n",
    "    return goodcm.get_coherence()\n",
    "\n",
    "obj = SklLdaModel(id2word=id2word, num_topics=5, iterations=5)\n",
    "parameters = {'num_topics': (2, 3, 5, 10), 'iterations': (1, 20, 50)}\n",
    "\n",
    "# set `scoring` as your custom scoring function\n",
    "model = GridSearchCV(obj, parameters, cv=2, scoring=scoring_function)\n",
    "model.fit(corpus)\n",
    "\n",
    "model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of Using Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model\n",
    "\n",
    "def print_features_pipe(clf, vocab, n=10):\n",
    "    ''' Better printing for sorted list '''\n",
    "    coef = clf.named_steps['classifier'].coef_[0]\n",
    "    print coef\n",
    "    print 'Positive features: %s' % (' '.join(['%s:%.2f' % (vocab[j], coef[j]) for j in np.argsort(coef)[::-1][:n] if coef[j] > 0]))\n",
    "    print 'Negative features: %s' % (' '.join(['%s:%.2f' % (vocab[j], coef[j]) for j in np.argsort(coef)[:n] if coef[j] < 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.70383516 -1.02111207 -0.70109648 -0.4570351   0.02175549 -0.20545727\n",
      " -0.01517654  0.0717219   0.51160112  0.49580676  0.33125423  0.31986992\n",
      "  0.48162159  0.26829541  0.11292571]\n",
      "Positive features: hanging:0.51 localized:0.50 course...:0.48 LAST:0.33 wax):0.32 Stoakley):0.27 Signature!:0.11 circuitry:0.07 technique),:0.02\n",
      "Negative features: considered.:-1.02 al-Qanawi,:-0.70 alt.autos.karting:-0.70 considered,:-0.46 360.0;:-0.21 talk.origins:-0.02\n",
      "0.437876960193\n"
     ]
    }
   ],
   "source": [
    "model = SklLdaModel(num_topics=15, id2word=id2word, iterations=10, random_state=37)\n",
    "clf = linear_model.LogisticRegression(penalty='l2', C=0.1)  # l2 penalty used\n",
    "pipe = Pipeline((('features', model,), ('classifier', clf)))\n",
    "pipe.fit(corpus, data.target)\n",
    "print_features_pipe(pipe, id2word.values())\n",
    "print(pipe.score(corpus, data.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSI Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use LsiModel begin with importing LsiModel wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.sklearn_integration import SklLsiModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of Using Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00929522 -0.68199243  0.00292464 -0.22145158  0.58612298  0.16492053\n",
      "  0.00354379  0.37629786 -0.17202791 -0.03847397 -0.05041424 -0.08953721\n",
      "  0.21241931 -0.04824542  0.2287388 ]\n",
      "Positive features: technique),:0.59 circuitry:0.38 Signature!:0.23 course...:0.21 360.0;:0.16 al-Qanawi,:0.01 talk.origins:0.00 alt.autos.karting:0.00\n",
      "Negative features: considered.:-0.68 considered,:-0.22 hanging:-0.17 wax):-0.09 LAST:-0.05 Stoakley):-0.05 localized:-0.04\n",
      "0.683353437877\n"
     ]
    }
   ],
   "source": [
    "model = SklLsiModel(num_topics=15, id2word=id2word)\n",
    "clf = linear_model.LogisticRegression(penalty='l2', C=0.1)  # l2 penalty used\n",
    "pipe = Pipeline((('features', model,), ('classifier', clf)))\n",
    "pipe.fit(corpus, data.target)\n",
    "print_features_pipe(pipe, id2word.values())\n",
    "print(pipe.score(corpus, data.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Projections Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use RpModel begin with importing RpModel wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.sklearn_integration import SklRpModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of Using Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00474168  0.01863391]\n",
      "Positive features: considered.:0.02\n",
      "Negative features: al-Qanawi,:-0.00\n",
      "0.434861278649\n"
     ]
    }
   ],
   "source": [
    "model = SklRpModel(num_topics=2)\n",
    "np.random.mtrand.RandomState(1)  # set seed for getting same result\n",
    "clf = linear_model.LogisticRegression(penalty='l2', C=0.1)  # l2 penalty used\n",
    "pipe = Pipeline((('features', model,), ('classifier', clf)))\n",
    "pipe.fit(corpus, data.target)\n",
    "print_features_pipe(pipe, id2word.values())\n",
    "print(pipe.score(corpus, data.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDASeq Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use LdaSeqModel begin with importing LdaSeqModel wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.sklearn_integration import SklLdaSeqModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of Using Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chinmaya/GSOC/Gensim/gensim/gensim/models/ldaseqmodel.py:217: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  convergence = np.fabs((bound - old_bound) / old_bound)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04877123 -0.04877123]\n",
      "Positive features: In-Reply-To::0.05\n",
      "Negative features: nicknames:-0.05\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "test_data = data.data[0:2]\n",
    "test_target = data.target[0:2]\n",
    "id2word = Dictionary(map(lambda x: x.split(), test_data))\n",
    "corpus = [id2word.doc2bow(i.split()) for i in test_data]\n",
    "\n",
    "model = SklLdaSeqModel(id2word=id2word, num_topics=2, time_slice=[1, 1, 1], initialize='gensim')\n",
    "clf = linear_model.LogisticRegression(penalty='l2', C=0.1)  # l2 penalty used\n",
    "pipe = Pipeline((('features', model,), ('classifier', clf)))\n",
    "pipe.fit(corpus, test_target)\n",
    "print_features_pipe(pipe, id2word.values())\n",
    "print(pipe.score(corpus, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}


.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/tutorials/run_lda.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_tutorials_run_lda.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_tutorials_run_lda.py:


LDA Model
=========

Introduces Gensim's LDA model and demonstrates its use on the NIPS corpus.

.. GENERATED FROM PYTHON SOURCE LINES 8-12

.. code-block:: default


    import logging
    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)








.. GENERATED FROM PYTHON SOURCE LINES 13-60

The purpose of this tutorial is to demonstrate how to train and tune an LDA model.

In this tutorial we will:

* Load input data.
* Pre-process that data.
* Transform documents into bag-of-words vectors.
* Train an LDA model.

This tutorial will **not**:

* Explain how Latent Dirichlet Allocation works
* Explain how the LDA model performs inference
* Teach you all the parameters and options for Gensim's LDA implementation

If you are not familiar with the LDA model or how to use it in Gensim, I (Olavur Mortensen)
suggest you read up on that before continuing with this tutorial. Basic
understanding of the LDA model should suffice. Examples:

* `Introduction to Latent Dirichlet Allocation <http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation>`_
* Gensim tutorial: :ref:`sphx_glr_auto_examples_core_run_topics_and_transformations.py`
* Gensim's LDA model API docs: :py:class:`gensim.models.LdaModel`

I would also encourage you to consider each step when applying the model to
your data, instead of just blindly applying my solution. The different steps
will depend on your data and possibly your goal with the model.

Data
----

I have used a corpus of NIPS papers in this tutorial, but if you're following
this tutorial just to learn about LDA I encourage you to consider picking a
corpus on a subject that you are familiar with. Qualitatively evaluating the
output of an LDA model is challenging and can require you to understand the
subject matter of your corpus (depending on your goal with the model).

NIPS (Neural Information Processing Systems) is a machine learning conference
so the subject matter should be well suited for most of the target audience
of this tutorial.  You can download the original data from Sam Roweis'
`website <http://www.cs.nyu.edu/~roweis/data.html>`_.  The code below will
also do that for you.

.. Important::
    The corpus contains 1740 documents, and not particularly long ones.
    So keep in mind that this tutorial is not geared towards efficiency, and be
    careful before applying the code to a large dataset.


.. GENERATED FROM PYTHON SOURCE LINES 60-78

.. code-block:: default


    import io
    import os.path
    import re
    import tarfile

    import smart_open

    def extract_documents(url='https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz'):
        with smart_open.open(url, "rb") as file:
            with tarfile.open(fileobj=file) as tar:
                for member in tar.getmembers():
                    if member.isfile() and re.search(r'nipstxt/nips\d+/\d+\.txt', member.name):
                        member_bytes = tar.extractfile(member).read()
                        yield member_bytes.decode('utf-8', errors='replace')

    docs = list(extract_documents())








.. GENERATED FROM PYTHON SOURCE LINES 79-84

So we have a list of 1740 documents, where each document is a Unicode string.
If you're thinking about using your own corpus, then you need to make sure
that it's in the same format (list of Unicode strings) before proceeding
with the rest of this tutorial.


.. GENERATED FROM PYTHON SOURCE LINES 84-87

.. code-block:: default

    print(len(docs))
    print(docs[0][:500])





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    1740
    387 
    Neural Net and Traditional Classifiers  
    William Y. Huang and Richard P. Lippmann 
    MIT Lincoln Laboratory 
    Lexington, MA 02173, USA 
    Abstract
    Previous work on nets with continuous-valued inputs led to generative 
    procedures to construct convex decision regions with two-layer percepttons (one hidden 
    layer) and arbitrary decision regions with three-layer percepttons (two hidden layers). 
    Here we demonstrate that two-layer perceptton classifiers trained with back propagation 
    can form both c




.. GENERATED FROM PYTHON SOURCE LINES 88-107

Pre-process and vectorize the documents
---------------------------------------

As part of preprocessing, we will:

* Tokenize (split the documents into tokens).
* Lemmatize the tokens.
* Compute bigrams.
* Compute a bag-of-words representation of the data.

First we tokenize the text using a regular expression tokenizer from NLTK. We
remove numeric tokens and tokens that are only a single character, as they
don't tend to be useful, and the dataset contains a lot of them.

.. Important::

   This tutorial uses the nltk library for preprocessing, although you can
   replace it with something else if you want.


.. GENERATED FROM PYTHON SOURCE LINES 107-123

.. code-block:: default


    # Tokenize the documents.
    from nltk.tokenize import RegexpTokenizer

    # Split the documents into tokens.
    tokenizer = RegexpTokenizer(r'\w+')
    for idx in range(len(docs)):
        docs[idx] = docs[idx].lower()  # Convert to lowercase.
        docs[idx] = tokenizer.tokenize(docs[idx])  # Split into words.

    # Remove numbers, but not words that contain numbers.
    docs = [[token for token in doc if not token.isnumeric()] for doc in docs]

    # Remove words that are only one character.
    docs = [[token for token in doc if len(token) > 1] for doc in docs]





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /home/jonaschn/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/feature_extraction/image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
    Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
      dtype=np.int):
    /home/jonaschn/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
    Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
      eps=np.finfo(np.float).eps,
    /home/jonaschn/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:597: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
    Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
      eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,
    /home/jonaschn/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:836: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
    Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
      eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,
    /home/jonaschn/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
    Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
      eps=np.finfo(np.float).eps, positive=False):
    /home/jonaschn/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1074: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
    Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
      max_n_alphas=1000, n_jobs=1, eps=np.finfo(np.float).eps,
    /home/jonaschn/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1306: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
    Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
      max_n_alphas=1000, n_jobs=1, eps=np.finfo(np.float).eps,
    /home/jonaschn/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1442: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
    Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
      eps=np.finfo(np.float).eps, copy_X=True, positive=False):
    /home/jonaschn/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:152: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
    Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
      precompute=False, eps=np.finfo(np.float).eps,
    /home/jonaschn/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:318: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
    Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
      eps=np.finfo(np.float).eps, random_state=None,
    /home/jonaschn/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:575: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
    Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
      eps=4 * np.finfo(np.float).eps, n_jobs=1,




.. GENERATED FROM PYTHON SOURCE LINES 124-128

We use the WordNet lemmatizer from NLTK. A lemmatizer is preferred over a
stemmer in this case because it produces more readable words. Output that is
easy to read is very desirable in topic modelling.


.. GENERATED FROM PYTHON SOURCE LINES 128-135

.. code-block:: default


    # Lemmatize the documents.
    from nltk.stem.wordnet import WordNetLemmatizer

    lemmatizer = WordNetLemmatizer()
    docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]








.. GENERATED FROM PYTHON SOURCE LINES 136-149

We find bigrams in the documents. Bigrams are sets of two adjacent words.
Using bigrams we can get phrases like "machine_learning" in our output
(spaces are replaced with underscores); without bigrams we would only get
"machine" and "learning".

Note that in the code below, we find bigrams and then add them to the
original data, because we would like to keep the words "machine" and
"learning" as well as the bigram "machine_learning".

.. Important::
    Computing n-grams of large dataset can be very computationally
    and memory intensive.


.. GENERATED FROM PYTHON SOURCE LINES 149-162

.. code-block:: default



    # Compute bigrams.
    from gensim.models import Phrases

    # Add bigrams and trigrams to docs (only ones that appear 20 times or more).
    bigram = Phrases(docs, min_count=20)
    for idx in range(len(docs)):
        for token in bigram[docs[idx]]:
            if '_' in token:
                # Token is a bigram, add to document.
                docs[idx].append(token)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /home/jonaschn/Projects/gensim/gensim/similarities/__init__.py:11: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.
      "The gensim.similarities.levenshtein submodule is disabled, because the optional "
    2021-03-19 14:09:53,817 : INFO : collecting all words and their counts
    2021-03-19 14:09:53,817 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types
    2021-03-19 14:09:59,172 : INFO : collected 1120198 token types (unigram + bigrams) from a corpus of 4629808 words and 1740 sentences
    2021-03-19 14:09:59,172 : INFO : merged Phrases<1120198 vocab, min_count=20, threshold=10.0, max_vocab_size=40000000>
    2021-03-19 14:09:59,190 : INFO : Phrases lifecycle event {'msg': 'built Phrases<1120198 vocab, min_count=20, threshold=10.0, max_vocab_size=40000000> in 5.36s', 'datetime': '2021-03-19T14:09:59.189253', 'gensim': '4.0.0.rc1', 'python': '3.7.0 (default, Jun 28 2018, 13:15:42) \n[GCC 7.2.0]', 'platform': 'Linux-4.15.0-136-generic-x86_64-with-debian-buster-sid', 'event': 'created'}




.. GENERATED FROM PYTHON SOURCE LINES 163-168

We remove rare words and common words based on their *document frequency*.
Below we remove words that appear in less than 20 documents or in more than
50% of the documents. Consider trying to remove words only based on their
frequency, or maybe combining that with this approach.


.. GENERATED FROM PYTHON SOURCE LINES 168-178

.. code-block:: default


    # Remove rare and common tokens.
    from gensim.corpora import Dictionary

    # Create a dictionary representation of the documents.
    dictionary = Dictionary(docs)

    # Filter out words that occur less than 20 documents, or more than 50% of the documents.
    dictionary.filter_extremes(no_below=20, no_above=0.5)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    2021-03-19 14:10:07,280 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
    2021-03-19 14:10:09,906 : INFO : built Dictionary(79429 unique tokens: ['1ooooo', '1st', '25oo', '2o00', '4ooo']...) from 1740 documents (total 4953968 corpus positions)
    2021-03-19 14:10:09,906 : INFO : Dictionary lifecycle event {'msg': "built Dictionary(79429 unique tokens: ['1ooooo', '1st', '25oo', '2o00', '4ooo']...) from 1740 documents (total 4953968 corpus positions)", 'datetime': '2021-03-19T14:10:09.906597', 'gensim': '4.0.0.rc1', 'python': '3.7.0 (default, Jun 28 2018, 13:15:42) \n[GCC 7.2.0]', 'platform': 'Linux-4.15.0-136-generic-x86_64-with-debian-buster-sid', 'event': 'created'}
    2021-03-19 14:10:10,101 : INFO : discarding 70785 tokens: [('1ooooo', 1), ('25oo', 2), ('2o00', 6), ('4ooo', 2), ('64k', 6), ('a', 1740), ('aaditional', 1), ('above', 1114), ('abstract', 1740), ('acase', 1)]...
    2021-03-19 14:10:10,102 : INFO : keeping 8644 tokens which were in no less than 20 and no more than 870 (=50.0%) documents
    2021-03-19 14:10:10,128 : INFO : resulting dictionary: Dictionary(8644 unique tokens: ['1st', '5oo', '7th', 'a2', 'a_well']...)




.. GENERATED FROM PYTHON SOURCE LINES 179-182

Finally, we transform the documents to a vectorized form. We simply compute
the frequency of each word, including the bigrams.


.. GENERATED FROM PYTHON SOURCE LINES 182-186

.. code-block:: default


    # Bag-of-words representation of the documents.
    corpus = [dictionary.doc2bow(doc) for doc in docs]








.. GENERATED FROM PYTHON SOURCE LINES 187-189

Let's see how many tokens and documents we have to train on.


.. GENERATED FROM PYTHON SOURCE LINES 189-193

.. code-block:: default


    print('Number of unique tokens: %d' % len(dictionary))
    print('Number of documents: %d' % len(corpus))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Number of unique tokens: 8644
    Number of documents: 1740




.. GENERATED FROM PYTHON SOURCE LINES 194-236

Training
--------

We are ready to train the LDA model. We will first discuss how to set some of
the training parameters.

First of all, the elephant in the room: how many topics do I need? There is
really no easy answer for this, it will depend on both your data and your
application. I have used 10 topics here because I wanted to have a few topics
that I could interpret and "label", and because that turned out to give me
reasonably good results. You might not need to interpret all your topics, so
you could use a large number of topics, for example 100.

``chunksize`` controls how many documents are processed at a time in the
training algorithm. Increasing chunksize will speed up training, at least as
long as the chunk of documents easily fit into memory. I've set ``chunksize =
2000``, which is more than the amount of documents, so I process all the
data in one go. Chunksize can however influence the quality of the model, as
discussed in Hoffman and co-authors [2], but the difference was not
substantial in this case.

``passes`` controls how often we train the model on the entire corpus.
Another word for passes might be "epochs". ``iterations`` is somewhat
technical, but essentially it controls how often we repeat a particular loop
over each document. It is important to set the number of "passes" and
"iterations" high enough.

I suggest the following way to choose iterations and passes. First, enable
logging (as described in many Gensim tutorials), and set ``eval_every = 1``
in ``LdaModel``. When training the model look for a line in the log that
looks something like this::

   2016-06-21 15:40:06,753 - gensim.models.ldamodel - DEBUG - 68/1566 documents converged within 400 iterations

If you set ``passes = 20`` you will see this line 20 times. Make sure that by
the final passes, most of the documents have converged. So you want to choose
both passes and iterations to be high enough for this to happen.

We set ``alpha = 'auto'`` and ``eta = 'auto'``. Again this is somewhat
technical, but essentially we are automatically learning two parameters in
the model that we usually would have to specify explicitly.


.. GENERATED FROM PYTHON SOURCE LINES 236-264

.. code-block:: default



    # Train LDA model.
    from gensim.models import LdaModel

    # Set training parameters.
    num_topics = 10
    chunksize = 2000
    passes = 20
    iterations = 400
    eval_every = None  # Don't evaluate model perplexity, takes too much time.

    # Make a index to word dictionary.
    temp = dictionary[0]  # This is only to "load" the dictionary.
    id2word = dictionary.id2token

    model = LdaModel(
        corpus=corpus,
        id2word=id2word,
        chunksize=chunksize,
        alpha='auto',
        eta='auto',
        iterations=iterations,
        num_topics=num_topics,
        passes=passes,
        eval_every=eval_every
    )





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    2021-03-19 14:10:12,273 : INFO : using autotuned alpha, starting with [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
    2021-03-19 14:10:12,278 : INFO : using serial LDA version on this node
    2021-03-19 14:10:12,478 : INFO : running online (multi-pass) LDA training, 10 topics, 20 passes over the supplied corpus of 1740 documents, updating model once every 1740 documents, evaluating perplexity every 0 documents, iterating 400x with a convergence threshold of 0.001000
    2021-03-19 14:10:12,482 : INFO : PROGRESS: pass 0, at document #1740/1740
    2021-03-19 14:10:27,000 : INFO : optimized alpha [0.06386429, 0.07352975, 0.10417274, 0.09618805, 0.09326739, 0.07658379, 0.05232423, 0.09257348, 0.05156824, 0.064680815]
    2021-03-19 14:10:27,050 : INFO : topic #8 (0.052): 0.004*"layer" + 0.004*"action" + 0.003*"generalization" + 0.003*"image" + 0.002*"dynamic" + 0.002*"sample" + 0.002*"optimal" + 0.002*"matrix" + 0.002*"net" + 0.002*"classifier"
    2021-03-19 14:10:27,051 : INFO : topic #6 (0.052): 0.006*"image" + 0.005*"hidden" + 0.004*"recognition" + 0.003*"component" + 0.003*"field" + 0.003*"dynamic" + 0.002*"map" + 0.002*"solution" + 0.002*"net" + 0.002*"generalization"
    2021-03-19 14:10:27,051 : INFO : topic #4 (0.093): 0.004*"class" + 0.003*"rule" + 0.003*"hidden" + 0.003*"neuron" + 0.003*"layer" + 0.003*"field" + 0.002*"noise" + 0.002*"net" + 0.002*"image" + 0.002*"node"
    2021-03-19 14:10:27,051 : INFO : topic #3 (0.096): 0.006*"image" + 0.003*"gaussian" + 0.003*"layer" + 0.003*"neuron" + 0.003*"field" + 0.003*"matrix" + 0.003*"circuit" + 0.003*"class" + 0.002*"threshold" + 0.002*"recognition"
    2021-03-19 14:10:27,051 : INFO : topic #2 (0.104): 0.005*"neuron" + 0.004*"image" + 0.004*"control" + 0.004*"layer" + 0.004*"hidden" + 0.003*"recognition" + 0.003*"object" + 0.003*"signal" + 0.003*"response" + 0.003*"class"
    2021-03-19 14:10:27,051 : INFO : topic diff=1.190941, rho=1.000000
    2021-03-19 14:10:27,063 : INFO : PROGRESS: pass 1, at document #1740/1740
    2021-03-19 14:10:36,200 : INFO : optimized alpha [0.05691391, 0.05848132, 0.0764488, 0.07592632, 0.07411411, 0.06465285, 0.046124753, 0.06826302, 0.043833494, 0.05291034]
    2021-03-19 14:10:36,207 : INFO : topic #8 (0.044): 0.007*"action" + 0.004*"robot" + 0.004*"control" + 0.003*"optimal" + 0.003*"policy" + 0.003*"reinforcement" + 0.003*"generalization" + 0.003*"dynamic" + 0.003*"layer" + 0.003*"trajectory"
    2021-03-19 14:10:36,207 : INFO : topic #6 (0.046): 0.007*"image" + 0.007*"hidden" + 0.005*"recognition" + 0.003*"hidden_unit" + 0.003*"energy" + 0.003*"component" + 0.003*"map" + 0.003*"generalization" + 0.003*"net" + 0.003*"layer"
    2021-03-19 14:10:36,207 : INFO : topic #4 (0.074): 0.005*"class" + 0.004*"rule" + 0.003*"hidden" + 0.003*"layer" + 0.003*"net" + 0.003*"classifier" + 0.002*"node" + 0.002*"word" + 0.002*"context" + 0.002*"architecture"
    2021-03-19 14:10:36,207 : INFO : topic #3 (0.076): 0.007*"image" + 0.004*"circuit" + 0.003*"layer" + 0.003*"field" + 0.003*"analog" + 0.003*"chip" + 0.003*"threshold" + 0.003*"gaussian" + 0.003*"class" + 0.003*"matrix"
    2021-03-19 14:10:36,208 : INFO : topic #2 (0.076): 0.005*"control" + 0.005*"recognition" + 0.005*"image" + 0.005*"object" + 0.004*"speech" + 0.004*"layer" + 0.004*"signal" + 0.004*"neuron" + 0.004*"hidden" + 0.003*"word"
    2021-03-19 14:10:36,208 : INFO : topic diff=0.297702, rho=0.577350
    2021-03-19 14:10:36,218 : INFO : PROGRESS: pass 2, at document #1740/1740
    2021-03-19 14:10:43,026 : INFO : optimized alpha [0.05407287, 0.051192053, 0.06480061, 0.06461501, 0.06359977, 0.05890888, 0.042885136, 0.056735355, 0.039943077, 0.04743726]
    2021-03-19 14:10:43,033 : INFO : topic #8 (0.040): 0.008*"action" + 0.006*"control" + 0.005*"robot" + 0.005*"reinforcement" + 0.005*"policy" + 0.004*"optimal" + 0.004*"dynamic" + 0.003*"trajectory" + 0.003*"reinforcement_learning" + 0.003*"controller"
    2021-03-19 14:10:43,033 : INFO : topic #6 (0.043): 0.008*"image" + 0.008*"hidden" + 0.005*"recognition" + 0.004*"hidden_unit" + 0.003*"energy" + 0.003*"layer" + 0.003*"net" + 0.003*"generalization" + 0.003*"map" + 0.003*"solution"
    2021-03-19 14:10:43,034 : INFO : topic #4 (0.064): 0.005*"class" + 0.004*"rule" + 0.004*"hidden" + 0.004*"layer" + 0.003*"net" + 0.003*"classifier" + 0.003*"node" + 0.003*"word" + 0.003*"context" + 0.002*"architecture"
    2021-03-19 14:10:43,034 : INFO : topic #3 (0.065): 0.008*"image" + 0.004*"circuit" + 0.004*"chip" + 0.004*"analog" + 0.004*"threshold" + 0.004*"layer" + 0.003*"field" + 0.003*"node" + 0.003*"class" + 0.003*"net"
    2021-03-19 14:10:43,034 : INFO : topic #2 (0.065): 0.006*"recognition" + 0.006*"speech" + 0.005*"control" + 0.005*"object" + 0.005*"image" + 0.005*"layer" + 0.005*"signal" + 0.004*"word" + 0.004*"hidden" + 0.003*"classification"
    2021-03-19 14:10:43,034 : INFO : topic diff=0.256329, rho=0.500000
    2021-03-19 14:10:43,044 : INFO : PROGRESS: pass 3, at document #1740/1740
    2021-03-19 14:10:48,846 : INFO : optimized alpha [0.053115886, 0.046841364, 0.05838778, 0.05814584, 0.05758646, 0.05547897, 0.040862918, 0.05055692, 0.037515096, 0.044183854]
    2021-03-19 14:10:48,853 : INFO : topic #8 (0.038): 0.010*"action" + 0.008*"control" + 0.006*"reinforcement" + 0.006*"robot" + 0.005*"policy" + 0.005*"optimal" + 0.004*"controller" + 0.004*"dynamic" + 0.004*"reinforcement_learning" + 0.004*"trajectory"
    2021-03-19 14:10:48,853 : INFO : topic #6 (0.041): 0.009*"hidden" + 0.008*"image" + 0.006*"recognition" + 0.004*"hidden_unit" + 0.004*"layer" + 0.004*"energy" + 0.003*"net" + 0.003*"generalization" + 0.003*"field" + 0.003*"map"
    2021-03-19 14:10:48,853 : INFO : topic #4 (0.058): 0.005*"class" + 0.005*"hidden" + 0.004*"rule" + 0.004*"layer" + 0.004*"net" + 0.004*"classifier" + 0.003*"node" + 0.003*"propagation" + 0.003*"architecture" + 0.003*"context"
    2021-03-19 14:10:48,854 : INFO : topic #3 (0.058): 0.009*"image" + 0.005*"chip" + 0.005*"circuit" + 0.005*"analog" + 0.004*"threshold" + 0.004*"layer" + 0.003*"field" + 0.003*"bit" + 0.003*"node" + 0.003*"net"
    2021-03-19 14:10:48,854 : INFO : topic #2 (0.058): 0.007*"recognition" + 0.007*"speech" + 0.006*"object" + 0.006*"image" + 0.005*"word" + 0.005*"layer" + 0.005*"control" + 0.005*"signal" + 0.004*"hidden" + 0.003*"face"
    2021-03-19 14:10:48,854 : INFO : topic diff=0.230126, rho=0.447214
    2021-03-19 14:10:48,864 : INFO : PROGRESS: pass 4, at document #1740/1740
    2021-03-19 14:10:54,097 : INFO : optimized alpha [0.052869715, 0.044183813, 0.0546517, 0.054109406, 0.053801704, 0.053375203, 0.0394719, 0.04672288, 0.035995413, 0.04192354]
    2021-03-19 14:10:54,105 : INFO : topic #8 (0.036): 0.010*"action" + 0.010*"control" + 0.007*"reinforcement" + 0.006*"robot" + 0.006*"policy" + 0.005*"optimal" + 0.005*"controller" + 0.005*"dynamic" + 0.004*"reinforcement_learning" + 0.004*"trajectory"
    2021-03-19 14:10:54,105 : INFO : topic #6 (0.039): 0.009*"hidden" + 0.008*"image" + 0.006*"recognition" + 0.005*"hidden_unit" + 0.004*"layer" + 0.004*"energy" + 0.003*"net" + 0.003*"digit" + 0.003*"field" + 0.003*"generalization"
    2021-03-19 14:10:54,105 : INFO : topic #4 (0.054): 0.005*"class" + 0.005*"hidden" + 0.005*"rule" + 0.005*"net" + 0.005*"layer" + 0.004*"classifier" + 0.004*"node" + 0.003*"propagation" + 0.003*"architecture" + 0.003*"sequence"
    2021-03-19 14:10:54,106 : INFO : topic #3 (0.054): 0.009*"image" + 0.006*"chip" + 0.006*"circuit" + 0.006*"analog" + 0.004*"threshold" + 0.004*"layer" + 0.003*"field" + 0.003*"bit" + 0.003*"node" + 0.003*"net"
    2021-03-19 14:10:54,106 : INFO : topic #2 (0.055): 0.008*"recognition" + 0.008*"speech" + 0.007*"object" + 0.006*"word" + 0.006*"image" + 0.005*"layer" + 0.005*"signal" + 0.005*"control" + 0.004*"hidden" + 0.004*"face"
    2021-03-19 14:10:54,106 : INFO : topic diff=0.214075, rho=0.408248
    2021-03-19 14:10:54,116 : INFO : PROGRESS: pass 5, at document #1740/1740
    2021-03-19 14:10:59,195 : INFO : optimized alpha [0.05290075, 0.042460088, 0.052235015, 0.051339325, 0.05138389, 0.05190376, 0.038578223, 0.044312876, 0.035001513, 0.040355477]
    2021-03-19 14:10:59,202 : INFO : topic #8 (0.035): 0.011*"control" + 0.011*"action" + 0.007*"reinforcement" + 0.006*"policy" + 0.006*"robot" + 0.005*"controller" + 0.005*"optimal" + 0.005*"dynamic" + 0.005*"reinforcement_learning" + 0.005*"trajectory"
    2021-03-19 14:10:59,202 : INFO : topic #6 (0.039): 0.010*"hidden" + 0.008*"image" + 0.006*"recognition" + 0.005*"hidden_unit" + 0.005*"layer" + 0.004*"energy" + 0.004*"digit" + 0.004*"character" + 0.004*"net" + 0.003*"field"
    2021-03-19 14:10:59,203 : INFO : topic #5 (0.052): 0.021*"neuron" + 0.012*"cell" + 0.007*"response" + 0.007*"spike" + 0.006*"synaptic" + 0.006*"stimulus" + 0.005*"activity" + 0.005*"firing" + 0.005*"signal" + 0.004*"memory"
    2021-03-19 14:10:59,203 : INFO : topic #2 (0.052): 0.009*"recognition" + 0.008*"speech" + 0.007*"object" + 0.007*"word" + 0.006*"image" + 0.006*"signal" + 0.005*"layer" + 0.004*"hidden" + 0.004*"control" + 0.004*"face"
    2021-03-19 14:10:59,203 : INFO : topic #0 (0.053): 0.005*"gaussian" + 0.005*"noise" + 0.005*"matrix" + 0.005*"hidden" + 0.004*"approximation" + 0.004*"sample" + 0.004*"estimate" + 0.004*"variance" + 0.004*"bayesian" + 0.003*"prior"
    2021-03-19 14:10:59,203 : INFO : topic diff=0.202368, rho=0.377964
    2021-03-19 14:10:59,214 : INFO : PROGRESS: pass 6, at document #1740/1740
    2021-03-19 14:11:04,013 : INFO : optimized alpha [0.053310633, 0.041254587, 0.050613035, 0.04936813, 0.049790192, 0.05083673, 0.038025398, 0.042830754, 0.034370847, 0.039269455]
    2021-03-19 14:11:04,020 : INFO : topic #8 (0.034): 0.012*"control" + 0.011*"action" + 0.008*"reinforcement" + 0.007*"policy" + 0.006*"robot" + 0.006*"controller" + 0.005*"optimal" + 0.005*"dynamic" + 0.005*"trajectory" + 0.005*"reinforcement_learning"
    2021-03-19 14:11:04,020 : INFO : topic #6 (0.038): 0.010*"hidden" + 0.009*"image" + 0.006*"recognition" + 0.005*"hidden_unit" + 0.005*"layer" + 0.004*"energy" + 0.004*"character" + 0.004*"digit" + 0.004*"net" + 0.004*"field"
    2021-03-19 14:11:04,021 : INFO : topic #2 (0.051): 0.010*"recognition" + 0.009*"speech" + 0.007*"word" + 0.007*"object" + 0.007*"image" + 0.006*"signal" + 0.006*"layer" + 0.004*"hidden" + 0.004*"face" + 0.004*"classification"
    2021-03-19 14:11:04,021 : INFO : topic #5 (0.051): 0.021*"neuron" + 0.012*"cell" + 0.007*"response" + 0.007*"spike" + 0.006*"synaptic" + 0.006*"stimulus" + 0.006*"activity" + 0.005*"firing" + 0.005*"signal" + 0.004*"frequency"
    2021-03-19 14:11:04,021 : INFO : topic #0 (0.053): 0.006*"gaussian" + 0.005*"noise" + 0.005*"matrix" + 0.005*"hidden" + 0.004*"approximation" + 0.004*"estimate" + 0.004*"sample" + 0.004*"bayesian" + 0.004*"variance" + 0.004*"prior"
    2021-03-19 14:11:04,021 : INFO : topic diff=0.192693, rho=0.353553
    2021-03-19 14:11:04,032 : INFO : PROGRESS: pass 7, at document #1740/1740
    2021-03-19 14:11:08,718 : INFO : optimized alpha [0.053891532, 0.040544394, 0.049499568, 0.047873296, 0.04881682, 0.0500006, 0.037689965, 0.04181969, 0.03393164, 0.038607482]
    2021-03-19 14:11:08,725 : INFO : topic #8 (0.034): 0.013*"control" + 0.012*"action" + 0.008*"reinforcement" + 0.007*"policy" + 0.006*"robot" + 0.006*"controller" + 0.005*"dynamic" + 0.005*"optimal" + 0.005*"trajectory" + 0.005*"reinforcement_learning"
    2021-03-19 14:11:08,725 : INFO : topic #6 (0.038): 0.010*"hidden" + 0.009*"image" + 0.006*"recognition" + 0.005*"layer" + 0.005*"hidden_unit" + 0.005*"character" + 0.004*"energy" + 0.004*"digit" + 0.004*"net" + 0.004*"field"
    2021-03-19 14:11:08,726 : INFO : topic #2 (0.049): 0.011*"recognition" + 0.009*"speech" + 0.008*"word" + 0.007*"object" + 0.007*"image" + 0.006*"signal" + 0.006*"layer" + 0.004*"face" + 0.004*"hidden" + 0.004*"classification"
    2021-03-19 14:11:08,726 : INFO : topic #5 (0.050): 0.022*"neuron" + 0.012*"cell" + 0.007*"response" + 0.007*"spike" + 0.007*"synaptic" + 0.006*"stimulus" + 0.006*"activity" + 0.005*"firing" + 0.005*"signal" + 0.005*"frequency"
    2021-03-19 14:11:08,726 : INFO : topic #0 (0.054): 0.006*"gaussian" + 0.005*"noise" + 0.005*"matrix" + 0.004*"approximation" + 0.004*"hidden" + 0.004*"estimate" + 0.004*"sample" + 0.004*"bayesian" + 0.004*"variance" + 0.004*"prior"
    2021-03-19 14:11:08,726 : INFO : topic diff=0.183651, rho=0.333333
    2021-03-19 14:11:08,737 : INFO : PROGRESS: pass 8, at document #1740/1740
    2021-03-19 14:11:13,510 : INFO : optimized alpha [0.0545965, 0.040113404, 0.048812777, 0.0467447, 0.048271947, 0.049433745, 0.03755086, 0.04124074, 0.033623673, 0.038269136]
    2021-03-19 14:11:13,518 : INFO : topic #8 (0.034): 0.014*"control" + 0.012*"action" + 0.008*"reinforcement" + 0.007*"policy" + 0.006*"controller" + 0.006*"robot" + 0.006*"dynamic" + 0.006*"optimal" + 0.005*"trajectory" + 0.005*"reinforcement_learning"
    2021-03-19 14:11:13,518 : INFO : topic #6 (0.038): 0.010*"hidden" + 0.009*"image" + 0.006*"recognition" + 0.005*"layer" + 0.005*"hidden_unit" + 0.005*"character" + 0.004*"energy" + 0.004*"digit" + 0.004*"net" + 0.004*"field"
    2021-03-19 14:11:13,518 : INFO : topic #2 (0.049): 0.011*"recognition" + 0.009*"speech" + 0.008*"word" + 0.008*"object" + 0.007*"image" + 0.006*"signal" + 0.006*"layer" + 0.004*"face" + 0.004*"classification" + 0.004*"hidden"
    2021-03-19 14:11:13,518 : INFO : topic #5 (0.049): 0.022*"neuron" + 0.013*"cell" + 0.008*"response" + 0.007*"spike" + 0.007*"synaptic" + 0.006*"stimulus" + 0.006*"activity" + 0.006*"firing" + 0.005*"signal" + 0.005*"frequency"
    2021-03-19 14:11:13,519 : INFO : topic #0 (0.055): 0.006*"gaussian" + 0.005*"noise" + 0.005*"matrix" + 0.004*"approximation" + 0.004*"estimate" + 0.004*"hidden" + 0.004*"sample" + 0.004*"bayesian" + 0.004*"likelihood" + 0.004*"variance"
    2021-03-19 14:11:13,519 : INFO : topic diff=0.175043, rho=0.316228
    2021-03-19 14:11:13,530 : INFO : PROGRESS: pass 9, at document #1740/1740
    2021-03-19 14:11:18,487 : INFO : optimized alpha [0.055368014, 0.039957594, 0.048399936, 0.045934383, 0.04802085, 0.049097233, 0.037513737, 0.040929828, 0.0334422, 0.038141657]
    2021-03-19 14:11:18,495 : INFO : topic #8 (0.033): 0.014*"control" + 0.012*"action" + 0.008*"reinforcement" + 0.007*"policy" + 0.006*"controller" + 0.006*"robot" + 0.006*"dynamic" + 0.006*"optimal" + 0.005*"trajectory" + 0.005*"reinforcement_learning"
    2021-03-19 14:11:18,495 : INFO : topic #6 (0.038): 0.010*"hidden" + 0.009*"image" + 0.006*"layer" + 0.006*"recognition" + 0.005*"character" + 0.005*"hidden_unit" + 0.004*"digit" + 0.004*"energy" + 0.004*"field" + 0.004*"net"
    2021-03-19 14:11:18,496 : INFO : topic #2 (0.048): 0.012*"recognition" + 0.010*"speech" + 0.009*"word" + 0.008*"image" + 0.008*"object" + 0.006*"signal" + 0.006*"layer" + 0.004*"face" + 0.004*"classification" + 0.004*"trained"
    2021-03-19 14:11:18,496 : INFO : topic #5 (0.049): 0.022*"neuron" + 0.013*"cell" + 0.008*"spike" + 0.008*"response" + 0.007*"synaptic" + 0.006*"stimulus" + 0.006*"activity" + 0.006*"firing" + 0.005*"signal" + 0.005*"frequency"
    2021-03-19 14:11:18,496 : INFO : topic #0 (0.055): 0.006*"gaussian" + 0.005*"noise" + 0.005*"matrix" + 0.005*"estimate" + 0.005*"approximation" + 0.004*"hidden" + 0.004*"sample" + 0.004*"bayesian" + 0.004*"likelihood" + 0.004*"prior"
    2021-03-19 14:11:18,496 : INFO : topic diff=0.166410, rho=0.301511
    2021-03-19 14:11:18,507 : INFO : PROGRESS: pass 10, at document #1740/1740
    2021-03-19 14:11:23,641 : INFO : optimized alpha [0.056234606, 0.039904997, 0.04814231, 0.045396697, 0.048054837, 0.048870783, 0.037563145, 0.04080154, 0.03336996, 0.03815883]
    2021-03-19 14:11:23,650 : INFO : topic #8 (0.033): 0.015*"control" + 0.012*"action" + 0.008*"reinforcement" + 0.008*"policy" + 0.007*"controller" + 0.006*"robot" + 0.006*"dynamic" + 0.006*"optimal" + 0.005*"trajectory" + 0.005*"reinforcement_learning"
    2021-03-19 14:11:23,651 : INFO : topic #6 (0.038): 0.010*"hidden" + 0.009*"image" + 0.006*"layer" + 0.006*"character" + 0.005*"recognition" + 0.005*"hidden_unit" + 0.004*"digit" + 0.004*"energy" + 0.004*"field" + 0.004*"net"
    2021-03-19 14:11:23,651 : INFO : topic #2 (0.048): 0.012*"recognition" + 0.010*"speech" + 0.009*"word" + 0.008*"image" + 0.008*"object" + 0.006*"signal" + 0.006*"layer" + 0.005*"face" + 0.004*"classification" + 0.004*"trained"
    2021-03-19 14:11:23,651 : INFO : topic #5 (0.049): 0.023*"neuron" + 0.013*"cell" + 0.008*"spike" + 0.008*"response" + 0.007*"synaptic" + 0.006*"activity" + 0.006*"stimulus" + 0.006*"firing" + 0.005*"signal" + 0.005*"frequency"
    2021-03-19 14:11:23,651 : INFO : topic #0 (0.056): 0.006*"gaussian" + 0.005*"noise" + 0.005*"estimate" + 0.005*"matrix" + 0.005*"approximation" + 0.004*"bayesian" + 0.004*"likelihood" + 0.004*"sample" + 0.004*"hidden" + 0.004*"prior"
    2021-03-19 14:11:23,651 : INFO : topic diff=0.157726, rho=0.288675
    2021-03-19 14:11:23,663 : INFO : PROGRESS: pass 11, at document #1740/1740
    2021-03-19 14:11:28,247 : INFO : optimized alpha [0.05706192, 0.039978355, 0.04797657, 0.044978894, 0.048209604, 0.048704833, 0.03767563, 0.04074631, 0.033347335, 0.038310345]
    2021-03-19 14:11:28,255 : INFO : topic #8 (0.033): 0.015*"control" + 0.012*"action" + 0.008*"reinforcement" + 0.008*"policy" + 0.007*"controller" + 0.006*"robot" + 0.006*"dynamic" + 0.006*"optimal" + 0.006*"trajectory" + 0.005*"reinforcement_learning"
    2021-03-19 14:11:28,256 : INFO : topic #6 (0.038): 0.010*"hidden" + 0.009*"image" + 0.006*"layer" + 0.006*"character" + 0.005*"recognition" + 0.005*"hidden_unit" + 0.004*"digit" + 0.004*"energy" + 0.004*"field" + 0.004*"net"
    2021-03-19 14:11:28,256 : INFO : topic #4 (0.048): 0.008*"hidden" + 0.007*"net" + 0.006*"layer" + 0.006*"rule" + 0.005*"node" + 0.004*"classifier" + 0.004*"hidden_unit" + 0.004*"class" + 0.004*"propagation" + 0.004*"sequence"
    2021-03-19 14:11:28,256 : INFO : topic #5 (0.049): 0.023*"neuron" + 0.013*"cell" + 0.008*"spike" + 0.008*"response" + 0.007*"synaptic" + 0.006*"activity" + 0.006*"firing" + 0.006*"stimulus" + 0.005*"signal" + 0.005*"frequency"
    2021-03-19 14:11:28,256 : INFO : topic #0 (0.057): 0.006*"gaussian" + 0.006*"noise" + 0.005*"estimate" + 0.005*"matrix" + 0.005*"approximation" + 0.004*"likelihood" + 0.004*"bayesian" + 0.004*"prior" + 0.004*"sample" + 0.004*"hidden"
    2021-03-19 14:11:28,256 : INFO : topic diff=0.149091, rho=0.277350
    2021-03-19 14:11:28,268 : INFO : PROGRESS: pass 12, at document #1740/1740
    2021-03-19 14:11:32,844 : INFO : optimized alpha [0.057841934, 0.040147286, 0.047984846, 0.04466845, 0.048510514, 0.048608452, 0.037831437, 0.04078982, 0.03338453, 0.038538743]
    2021-03-19 14:11:32,852 : INFO : topic #8 (0.033): 0.015*"control" + 0.012*"action" + 0.008*"reinforcement" + 0.008*"policy" + 0.007*"controller" + 0.006*"dynamic" + 0.006*"robot" + 0.006*"optimal" + 0.006*"trajectory" + 0.005*"reinforcement_learning"
    2021-03-19 14:11:32,852 : INFO : topic #6 (0.038): 0.010*"hidden" + 0.009*"image" + 0.006*"layer" + 0.006*"character" + 0.005*"recognition" + 0.005*"hidden_unit" + 0.005*"digit" + 0.004*"energy" + 0.004*"attractor" + 0.004*"field"
    2021-03-19 14:11:32,853 : INFO : topic #4 (0.049): 0.008*"hidden" + 0.007*"net" + 0.006*"layer" + 0.006*"rule" + 0.005*"node" + 0.004*"hidden_unit" + 0.004*"classifier" + 0.004*"class" + 0.004*"propagation" + 0.004*"sequence"
    2021-03-19 14:11:32,853 : INFO : topic #5 (0.049): 0.023*"neuron" + 0.013*"cell" + 0.008*"spike" + 0.008*"response" + 0.007*"synaptic" + 0.006*"firing" + 0.006*"activity" + 0.006*"stimulus" + 0.005*"signal" + 0.005*"frequency"
    2021-03-19 14:11:32,853 : INFO : topic #0 (0.058): 0.006*"gaussian" + 0.006*"noise" + 0.005*"estimate" + 0.005*"approximation" + 0.005*"matrix" + 0.004*"likelihood" + 0.004*"bayesian" + 0.004*"prior" + 0.004*"variance" + 0.004*"sample"
    2021-03-19 14:11:32,853 : INFO : topic diff=0.140596, rho=0.267261
    2021-03-19 14:11:32,865 : INFO : PROGRESS: pass 13, at document #1740/1740
    2021-03-19 14:11:37,447 : INFO : optimized alpha [0.058551796, 0.040399875, 0.048106886, 0.044424307, 0.04896659, 0.04858641, 0.03804483, 0.040931225, 0.03344661, 0.038809597]
    2021-03-19 14:11:37,455 : INFO : topic #8 (0.033): 0.016*"control" + 0.013*"action" + 0.008*"policy" + 0.008*"reinforcement" + 0.007*"controller" + 0.006*"dynamic" + 0.006*"robot" + 0.006*"optimal" + 0.006*"trajectory" + 0.005*"reinforcement_learning"
    2021-03-19 14:11:37,455 : INFO : topic #6 (0.038): 0.010*"hidden" + 0.009*"image" + 0.006*"layer" + 0.006*"character" + 0.005*"hidden_unit" + 0.005*"recognition" + 0.005*"digit" + 0.004*"energy" + 0.004*"attractor" + 0.004*"field"
    2021-03-19 14:11:37,456 : INFO : topic #5 (0.049): 0.023*"neuron" + 0.013*"cell" + 0.008*"spike" + 0.008*"response" + 0.007*"synaptic" + 0.006*"firing" + 0.006*"activity" + 0.006*"stimulus" + 0.005*"signal" + 0.005*"frequency"
    2021-03-19 14:11:37,456 : INFO : topic #4 (0.049): 0.008*"hidden" + 0.007*"net" + 0.006*"layer" + 0.006*"rule" + 0.006*"node" + 0.005*"hidden_unit" + 0.004*"classifier" + 0.004*"class" + 0.004*"sequence" + 0.004*"propagation"
    2021-03-19 14:11:37,456 : INFO : topic #0 (0.059): 0.007*"gaussian" + 0.006*"noise" + 0.005*"estimate" + 0.005*"approximation" + 0.005*"matrix" + 0.005*"likelihood" + 0.004*"bayesian" + 0.004*"prior" + 0.004*"variance" + 0.004*"sample"
    2021-03-19 14:11:37,456 : INFO : topic diff=0.132327, rho=0.258199
    2021-03-19 14:11:37,467 : INFO : PROGRESS: pass 14, at document #1740/1740
    2021-03-19 14:11:41,536 : INFO : optimized alpha [0.05925279, 0.040705983, 0.04832607, 0.04427085, 0.049501013, 0.048644915, 0.038285527, 0.04113948, 0.03352695, 0.039150245]
    2021-03-19 14:11:41,544 : INFO : topic #8 (0.034): 0.016*"control" + 0.013*"action" + 0.009*"policy" + 0.008*"reinforcement" + 0.007*"controller" + 0.006*"dynamic" + 0.006*"robot" + 0.006*"optimal" + 0.006*"trajectory" + 0.005*"reinforcement_learning"
    2021-03-19 14:11:41,544 : INFO : topic #6 (0.038): 0.010*"hidden" + 0.009*"image" + 0.006*"character" + 0.006*"layer" + 0.005*"hidden_unit" + 0.005*"recognition" + 0.005*"digit" + 0.004*"energy" + 0.004*"attractor" + 0.004*"net"
    2021-03-19 14:11:41,544 : INFO : topic #5 (0.049): 0.023*"neuron" + 0.013*"cell" + 0.008*"spike" + 0.008*"response" + 0.007*"synaptic" + 0.006*"firing" + 0.006*"activity" + 0.006*"stimulus" + 0.005*"signal" + 0.005*"frequency"
    2021-03-19 14:11:41,545 : INFO : topic #4 (0.050): 0.008*"hidden" + 0.008*"net" + 0.006*"layer" + 0.006*"rule" + 0.006*"node" + 0.005*"hidden_unit" + 0.004*"sequence" + 0.004*"propagation" + 0.004*"architecture" + 0.004*"activation"
    2021-03-19 14:11:41,545 : INFO : topic #0 (0.059): 0.007*"gaussian" + 0.006*"noise" + 0.005*"estimate" + 0.005*"approximation" + 0.005*"likelihood" + 0.005*"matrix" + 0.004*"prior" + 0.004*"bayesian" + 0.004*"variance" + 0.004*"density"
    2021-03-19 14:11:41,545 : INFO : topic diff=0.124371, rho=0.250000
    2021-03-19 14:11:41,556 : INFO : PROGRESS: pass 15, at document #1740/1740
    2021-03-19 14:11:45,592 : INFO : optimized alpha [0.05994643, 0.041028578, 0.048593685, 0.04419364, 0.05009154, 0.048734292, 0.03856185, 0.041424613, 0.033627965, 0.039535556]
    2021-03-19 14:11:45,600 : INFO : topic #8 (0.034): 0.016*"control" + 0.013*"action" + 0.009*"policy" + 0.008*"reinforcement" + 0.007*"controller" + 0.007*"dynamic" + 0.006*"robot" + 0.006*"optimal" + 0.006*"trajectory" + 0.005*"reinforcement_learning"
    2021-03-19 14:11:45,600 : INFO : topic #6 (0.039): 0.010*"hidden" + 0.009*"image" + 0.006*"character" + 0.006*"layer" + 0.005*"hidden_unit" + 0.005*"recognition" + 0.005*"digit" + 0.004*"energy" + 0.004*"attractor" + 0.004*"dynamic"
    2021-03-19 14:11:45,600 : INFO : topic #5 (0.049): 0.023*"neuron" + 0.014*"cell" + 0.008*"spike" + 0.008*"response" + 0.008*"synaptic" + 0.006*"firing" + 0.006*"activity" + 0.006*"stimulus" + 0.005*"signal" + 0.005*"frequency"
    2021-03-19 14:11:45,600 : INFO : topic #4 (0.050): 0.008*"hidden" + 0.008*"net" + 0.007*"layer" + 0.006*"rule" + 0.006*"node" + 0.005*"hidden_unit" + 0.004*"sequence" + 0.004*"architecture" + 0.004*"propagation" + 0.004*"activation"
    2021-03-19 14:11:45,601 : INFO : topic #0 (0.060): 0.007*"gaussian" + 0.006*"noise" + 0.005*"estimate" + 0.005*"likelihood" + 0.005*"approximation" + 0.005*"matrix" + 0.004*"prior" + 0.004*"bayesian" + 0.004*"variance" + 0.004*"density"
    2021-03-19 14:11:45,601 : INFO : topic diff=0.116794, rho=0.242536
    2021-03-19 14:11:45,611 : INFO : PROGRESS: pass 16, at document #1740/1740
    2021-03-19 14:11:49,737 : INFO : optimized alpha [0.06068379, 0.041378528, 0.048856508, 0.0441432, 0.05072476, 0.0488511, 0.038870405, 0.041741073, 0.03375229, 0.039979585]
    2021-03-19 14:11:49,745 : INFO : topic #8 (0.034): 0.016*"control" + 0.013*"action" + 0.009*"policy" + 0.008*"reinforcement" + 0.007*"controller" + 0.007*"dynamic" + 0.006*"robot" + 0.006*"optimal" + 0.006*"trajectory" + 0.006*"reinforcement_learning"
    2021-03-19 14:11:49,745 : INFO : topic #6 (0.039): 0.010*"hidden" + 0.009*"image" + 0.006*"character" + 0.006*"layer" + 0.005*"hidden_unit" + 0.005*"recognition" + 0.005*"digit" + 0.004*"energy" + 0.004*"attractor" + 0.004*"dynamic"
    2021-03-19 14:11:49,745 : INFO : topic #5 (0.049): 0.023*"neuron" + 0.014*"cell" + 0.008*"spike" + 0.008*"response" + 0.008*"synaptic" + 0.006*"firing" + 0.006*"activity" + 0.006*"stimulus" + 0.006*"signal" + 0.005*"frequency"
    2021-03-19 14:11:49,746 : INFO : topic #4 (0.051): 0.008*"hidden" + 0.008*"net" + 0.007*"layer" + 0.006*"rule" + 0.006*"node" + 0.005*"hidden_unit" + 0.004*"sequence" + 0.004*"architecture" + 0.004*"activation" + 0.004*"propagation"
    2021-03-19 14:11:49,746 : INFO : topic #0 (0.061): 0.007*"gaussian" + 0.006*"noise" + 0.005*"estimate" + 0.005*"likelihood" + 0.005*"approximation" + 0.005*"prior" + 0.004*"bayesian" + 0.004*"matrix" + 0.004*"variance" + 0.004*"density"
    2021-03-19 14:11:49,746 : INFO : topic diff=0.109661, rho=0.235702
    2021-03-19 14:11:49,756 : INFO : PROGRESS: pass 17, at document #1740/1740
    2021-03-19 14:11:53,841 : INFO : optimized alpha [0.061406724, 0.04174132, 0.0491224, 0.044116188, 0.05141323, 0.049025778, 0.03920408, 0.04207979, 0.033907466, 0.04045379]
    2021-03-19 14:11:53,850 : INFO : topic #8 (0.034): 0.016*"control" + 0.013*"action" + 0.009*"policy" + 0.008*"reinforcement" + 0.007*"controller" + 0.007*"dynamic" + 0.006*"robot" + 0.006*"optimal" + 0.006*"trajectory" + 0.006*"reinforcement_learning"
    2021-03-19 14:11:53,850 : INFO : topic #6 (0.039): 0.010*"hidden" + 0.009*"image" + 0.007*"character" + 0.006*"layer" + 0.005*"hidden_unit" + 0.005*"recognition" + 0.005*"digit" + 0.004*"energy" + 0.004*"attractor" + 0.004*"dynamic"
    2021-03-19 14:11:53,850 : INFO : topic #2 (0.049): 0.014*"recognition" + 0.011*"speech" + 0.010*"word" + 0.010*"image" + 0.008*"object" + 0.006*"signal" + 0.005*"layer" + 0.005*"face" + 0.005*"classification" + 0.005*"trained"
    2021-03-19 14:11:53,851 : INFO : topic #4 (0.051): 0.009*"hidden" + 0.008*"net" + 0.007*"layer" + 0.006*"rule" + 0.006*"node" + 0.005*"hidden_unit" + 0.004*"architecture" + 0.004*"sequence" + 0.004*"activation" + 0.004*"propagation"
    2021-03-19 14:11:53,851 : INFO : topic #0 (0.061): 0.007*"gaussian" + 0.006*"noise" + 0.005*"estimate" + 0.005*"likelihood" + 0.005*"approximation" + 0.005*"prior" + 0.005*"bayesian" + 0.004*"matrix" + 0.004*"variance" + 0.004*"density"
    2021-03-19 14:11:53,851 : INFO : topic diff=0.102938, rho=0.229416
    2021-03-19 14:11:53,862 : INFO : PROGRESS: pass 18, at document #1740/1740
    2021-03-19 14:11:57,816 : INFO : optimized alpha [0.062154472, 0.042110436, 0.04939213, 0.044109803, 0.05212181, 0.049227104, 0.039544087, 0.04246847, 0.03410476, 0.040957462]
    2021-03-19 14:11:57,823 : INFO : topic #8 (0.034): 0.016*"control" + 0.013*"action" + 0.009*"policy" + 0.008*"reinforcement" + 0.007*"controller" + 0.007*"dynamic" + 0.006*"robot" + 0.006*"optimal" + 0.006*"trajectory" + 0.006*"reinforcement_learning"
    2021-03-19 14:11:57,824 : INFO : topic #6 (0.040): 0.010*"hidden" + 0.008*"image" + 0.007*"character" + 0.006*"layer" + 0.005*"hidden_unit" + 0.005*"recognition" + 0.005*"digit" + 0.004*"energy" + 0.004*"attractor" + 0.004*"dynamic"
    2021-03-19 14:11:57,824 : INFO : topic #2 (0.049): 0.014*"recognition" + 0.011*"speech" + 0.010*"word" + 0.010*"image" + 0.008*"object" + 0.006*"signal" + 0.005*"layer" + 0.005*"face" + 0.005*"classification" + 0.005*"trained"
    2021-03-19 14:11:57,824 : INFO : topic #4 (0.052): 0.009*"hidden" + 0.008*"net" + 0.007*"layer" + 0.006*"rule" + 0.006*"node" + 0.005*"hidden_unit" + 0.004*"architecture" + 0.004*"sequence" + 0.004*"activation" + 0.004*"propagation"
    2021-03-19 14:11:57,824 : INFO : topic #0 (0.062): 0.007*"gaussian" + 0.006*"noise" + 0.005*"estimate" + 0.005*"likelihood" + 0.005*"approximation" + 0.005*"prior" + 0.005*"bayesian" + 0.004*"matrix" + 0.004*"density" + 0.004*"variance"
    2021-03-19 14:11:57,825 : INFO : topic diff=0.096678, rho=0.223607
    2021-03-19 14:11:57,835 : INFO : PROGRESS: pass 19, at document #1740/1740
    2021-03-19 14:12:01,856 : INFO : optimized alpha [0.06292996, 0.04251684, 0.049703237, 0.044167582, 0.052860808, 0.049467582, 0.039925203, 0.042864826, 0.03433462, 0.0415304]
    2021-03-19 14:12:01,864 : INFO : topic #8 (0.034): 0.016*"control" + 0.013*"action" + 0.009*"policy" + 0.008*"reinforcement" + 0.007*"controller" + 0.007*"dynamic" + 0.006*"robot" + 0.006*"optimal" + 0.006*"trajectory" + 0.006*"reinforcement_learning"
    2021-03-19 14:12:01,864 : INFO : topic #6 (0.040): 0.010*"hidden" + 0.008*"image" + 0.007*"character" + 0.006*"layer" + 0.005*"hidden_unit" + 0.005*"recognition" + 0.005*"digit" + 0.004*"attractor" + 0.004*"energy" + 0.004*"dynamic"
    2021-03-19 14:12:01,864 : INFO : topic #2 (0.050): 0.014*"recognition" + 0.011*"speech" + 0.010*"word" + 0.010*"image" + 0.008*"object" + 0.006*"signal" + 0.005*"layer" + 0.005*"classification" + 0.005*"face" + 0.005*"trained"
    2021-03-19 14:12:01,865 : INFO : topic #4 (0.053): 0.009*"hidden" + 0.008*"net" + 0.007*"layer" + 0.006*"rule" + 0.006*"node" + 0.005*"hidden_unit" + 0.004*"architecture" + 0.004*"activation" + 0.004*"sequence" + 0.004*"propagation"
    2021-03-19 14:12:01,865 : INFO : topic #0 (0.063): 0.007*"gaussian" + 0.006*"noise" + 0.005*"estimate" + 0.005*"likelihood" + 0.005*"approximation" + 0.005*"prior" + 0.005*"bayesian" + 0.004*"density" + 0.004*"mixture" + 0.004*"variance"
    2021-03-19 14:12:01,865 : INFO : topic diff=0.090853, rho=0.218218
    2021-03-19 14:12:01,877 : INFO : LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=8644, num_topics=10, decay=0.5, chunksize=2000) in 109.40s', 'datetime': '2021-03-19T14:12:01.877604', 'gensim': '4.0.0.rc1', 'python': '3.7.0 (default, Jun 28 2018, 13:15:42) \n[GCC 7.2.0]', 'platform': 'Linux-4.15.0-136-generic-x86_64-with-debian-buster-sid', 'event': 'created'}




.. GENERATED FROM PYTHON SOURCE LINES 265-280

We can compute the topic coherence of each topic. Below we display the
average topic coherence and print the topics in order of topic coherence.

Note that we use the "Umass" topic coherence measure here (see
:py:func:`gensim.models.ldamodel.LdaModel.top_topics`), Gensim has recently
obtained an implementation of the "AKSW" topic coherence measure (see
accompanying blog post, http://rare-technologies.com/what-is-topic-coherence/).

If you are familiar with the subject of the articles in this dataset, you can
see that the topics below make a lot of sense. However, they are not without
flaws. We can see that there is substantial overlap between some topics,
others are hard to interpret, and most of them have at least some terms that
seem out of place. If you were able to do better, feel free to share your
methods on the blog at http://rare-technologies.com/lda-training-tips/ !


.. GENERATED FROM PYTHON SOURCE LINES 280-290

.. code-block:: default


    top_topics = model.top_topics(corpus) #, num_words=20)

    # Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.
    avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics
    print('Average topic coherence: %.4f.' % avg_topic_coherence)

    from pprint import pprint
    pprint(top_topics)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    2021-03-19 14:12:02,008 : INFO : CorpusAccumulator accumulated stats from 1000 documents
    Average topic coherence: -1.1072.
    [([(0.023360161, 'neuron'),
       (0.013864572, 'cell'),
       (0.0085508, 'spike'),
       (0.007835109, 'response'),
       (0.0077002184, 'synaptic'),
       (0.006420619, 'firing'),
       (0.0063291225, 'activity'),
       (0.005894408, 'stimulus'),
       (0.005635916, 'signal'),
       (0.005319338, 'frequency'),
       (0.0044079474, 'potential'),
       (0.0042212, 'connection'),
       (0.003969707, 'fig'),
       (0.0038775448, 'phase'),
       (0.0037467096, 'synapsis'),
       (0.0035546266, 'channel'),
       (0.0035464808, 'dynamic'),
       (0.0035111816, 'memory'),
       (0.003500412, 'simulation'),
       (0.0033668294, 'temporal')],
      -0.8843724877515563),
     ([(0.007043698, 'gaussian'),
       (0.0058810986, 'noise'),
       (0.005357382, 'estimate'),
       (0.005118217, 'likelihood'),
       (0.004725707, 'approximation'),
       (0.0047162576, 'prior'),
       (0.004589121, 'bayesian'),
       (0.0044163894, 'density'),
       (0.004383228, 'mixture'),
       (0.0043818722, 'variance'),
       (0.004343727, 'matrix'),
       (0.003920799, 'log'),
       (0.0039041233, 'sample'),
       (0.0038657538, 'posterior'),
       (0.0038494268, 'hidden'),
       (0.003747304, 'prediction'),
       (0.0035524433, 'generalization'),
       (0.003297515, 'em'),
       (0.0031830291, 'optimal'),
       (0.0029574349, 'estimation')],
      -0.9201121458749306),
     ([(0.013338742, 'visual'),
       (0.011440194, 'cell'),
       (0.010699649, 'field'),
       (0.009350259, 'image'),
       (0.008701173, 'motion'),
       (0.008576538, 'map'),
       (0.0077895345, 'direction'),
       (0.0073878667, 'orientation'),
       (0.006964441, 'eye'),
       (0.0066007036, 'response'),
       (0.0062312516, 'stimulus'),
       (0.006194355, 'spatial'),
       (0.0055934438, 'receptive'),
       (0.005137706, 'receptive_field'),
       (0.00512753, 'object'),
       (0.004664231, 'layer'),
       (0.0046304427, 'activity'),
       (0.0045092506, 'position'),
       (0.004168487, 'cortex'),
       (0.0040872716, 'location')],
      -0.9666086669197183),
     ([(0.009677556, 'hidden'),
       (0.008472348, 'image'),
       (0.0066851787, 'character'),
       (0.0064806826, 'layer'),
       (0.005060741, 'hidden_unit'),
       (0.004902215, 'recognition'),
       (0.004825573, 'digit'),
       (0.0043749292, 'attractor'),
       (0.0043325345, 'energy'),
       (0.00431843, 'dynamic'),
       (0.0038877935, 'matrix'),
       (0.003805258, 'net'),
       (0.003757226, 'field'),
       (0.0035065063, 'transformation'),
       (0.0034933372, 'dimensional'),
       (0.0034391459, 'distance'),
       (0.0031490896, 'gradient'),
       (0.0031419578, 'solution'),
       (0.002954112, 'map'),
       (0.0028736237, 'minimum')],
      -1.011100924928429),
     ([(0.010836434, 'circuit'),
       (0.009359381, 'chip'),
       (0.008903197, 'analog'),
       (0.00655248, 'neuron'),
       (0.006147317, 'threshold'),
       (0.0050505013, 'image'),
       (0.0048734145, 'bit'),
       (0.0048433533, 'voltage'),
       (0.004609887, 'memory'),
       (0.004231914, 'vlsi'),
       (0.0042090695, 'implementation'),
       (0.004113957, 'net'),
       (0.003907882, 'gate'),
       (0.0038376434, 'layer'),
       (0.0034949183, 'pp'),
       (0.003291277, 'element'),
       (0.0032199384, 'node'),
       (0.0030992834, 'signal'),
       (0.0029631325, 'design'),
       (0.0028471586, 'processor')],
      -1.0450720584710176),
     ([(0.008781833, 'hidden'),
       (0.008109003, 'net'),
       (0.0069496827, 'layer'),
       (0.006155399, 'rule'),
       (0.005891262, 'node'),
       (0.0051560537, 'hidden_unit'),
       (0.0041502067, 'architecture'),
       (0.0041317134, 'activation'),
       (0.0041251457, 'sequence'),
       (0.0040346556, 'propagation'),
       (0.0036248995, 'back'),
       (0.0035959794, 'recurrent'),
       (0.0031377305, 'class'),
       (0.0030542722, 'trained'),
       (0.0030384492, 'code'),
       (0.002923781, 'expert'),
       (0.0028879363, 'string'),
       (0.0027964872, 'learn'),
       (0.0027678378, 'table'),
       (0.0027654031, 'connection')],
      -1.122278491657109),
     ([(0.014161764, 'recognition'),
       (0.011104057, 'speech'),
       (0.010318562, 'word'),
       (0.010277273, 'image'),
       (0.00809512, 'object'),
       (0.0063050594, 'signal'),
       (0.0053472514, 'layer'),
       (0.005024713, 'classification'),
       (0.0050242324, 'face'),
       (0.004580911, 'trained'),
       (0.004409548, 'human'),
       (0.0043301815, 'context'),
       (0.0042581595, 'frame'),
       (0.0040203724, 'hidden'),
       (0.004008649, 'speaker'),
       (0.0035841789, 'class'),
       (0.0033736168, 'sequence'),
       (0.0032663026, 'hmm'),
       (0.0032505158, 'architecture'),
       (0.0031761383, 'view')],
      -1.1844643136695376),
     ([(0.0071913837, 'matrix'),
       (0.006639144, 'gradient'),
       (0.0058832015, 'kernel'),
       (0.0058791665, 'component'),
       (0.0047264574, 'class'),
       (0.0042780563, 'density'),
       (0.004226884, 'xi'),
       (0.004164046, 'convergence'),
       (0.0041592806, 'source'),
       (0.0040763966, 'loss'),
       (0.00392406, 'basis'),
       (0.0036241056, 'regression'),
       (0.0035536229, 'approximation'),
       (0.0033525354, 'independent'),
       (0.0032649476, 'bound'),
       (0.0031867179, 'mixture'),
       (0.0031306876, 'let'),
       (0.0030615225, 'signal'),
       (0.0030061873, 'support'),
       (0.0029361995, 'pca')],
      -1.2550214906161075),
     ([(0.012204602, 'tree'),
       (0.010181904, 'node'),
       (0.010171177, 'class'),
       (0.007966109, 'classifier'),
       (0.0075656017, 'decision'),
       (0.005655141, 'rule'),
       (0.0056041405, 'classification'),
       (0.0054354756, 'sample'),
       (0.0050921105, 'distance'),
       (0.0046420856, 'bound'),
       (0.0035473844, 'let'),
       (0.0032015098, 'measure'),
       (0.0031701634, 'cluster'),
       (0.0030615227, 'clustering'),
       (0.0030600468, 'graph'),
       (0.003044858, 'neighbor'),
       (0.0030077181, 'nearest'),
       (0.0029182513, 'call'),
       (0.0027482447, 'machine'),
       (0.0027105191, 'hypothesis')],
      -1.2831209969858721),
     ([(0.016391048, 'control'),
       (0.013031393, 'action'),
       (0.009197483, 'policy'),
       (0.008487638, 'reinforcement'),
       (0.0068111503, 'controller'),
       (0.0067618974, 'dynamic'),
       (0.006282514, 'robot'),
       (0.0061591244, 'optimal'),
       (0.005933612, 'trajectory'),
       (0.00556125, 'reinforcement_learning'),
       (0.004895806, 'environment'),
       (0.0044026882, 'goal'),
       (0.0042024464, 'reward'),
       (0.0037804258, 'position'),
       (0.0037499247, 'arm'),
       (0.003601292, 'motor'),
       (0.0034139594, 'sutton'),
       (0.0031908047, 'movement'),
       (0.003142896, 'td'),
       (0.0031323545, 'trial')],
      -1.4003243935908478)]




.. GENERATED FROM PYTHON SOURCE LINES 291-313

Things to experiment with
-------------------------

* ``no_above`` and ``no_below`` parameters in ``filter_extremes`` method.
* Adding trigrams or even higher order n-grams.
* Consider whether using a hold-out set or cross-validation is the way to go for you.
* Try other datasets.

Where to go from here
---------------------

* Check out a RaRe blog post on the AKSW topic coherence measure (http://rare-technologies.com/what-is-topic-coherence/).
* pyLDAvis (https://pyldavis.readthedocs.io/en/latest/index.html).
* Read some more Gensim tutorials (https://github.com/RaRe-Technologies/gensim/blob/develop/tutorials.md#tutorials).
* If you haven't already, read [1] and [2] (see references).

References
----------

1. "Latent Dirichlet Allocation", Blei et al. 2003.
2. "Online Learning for Latent Dirichlet Allocation", Hoffman et al. 2010.



.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 2 minutes  47.007 seconds)

**Estimated memory usage:**  658 MB


.. _sphx_glr_download_auto_examples_tutorials_run_lda.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: run_lda.py <run_lda.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: run_lda.ipynb <run_lda.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_

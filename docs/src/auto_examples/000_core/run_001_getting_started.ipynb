{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\nGetting Started with Gensim\n===========================\n\nA gentle introduction to Gensim.\n\nThis example demonstrates using gensim to:\n\n    1. Create a toy corpus and store it in memory\n    2. Create a Tf-Idf transformation of the corpus\n    3. Calculate the similarity between all the documents in the corpus\n\nLet's begin.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, let\u2019s create a small corpus of nine documents and twelve features [1]_:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "corpus = [\n    [(0, 1.0), (1, 1.0), (2, 1.0)],\n    [(2, 1.0), (3, 1.0), (4, 1.0), (5, 1.0), (6, 1.0), (8, 1.0)],\n    [(1, 1.0), (3, 1.0), (4, 1.0), (7, 1.0)],\n    [(0, 1.0), (4, 2.0), (7, 1.0)],\n    [(3, 1.0), (5, 1.0), (6, 1.0)],\n    [(9, 1.0)],\n    [(9, 1.0), (10, 1.0)],\n    [(9, 1.0), (10, 1.0), (11, 1.0)],\n    [(8, 1.0), (10, 1.0), (11, 1.0)],\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each of the elements in `corpus` corresponds to a document.\nA document consists of `features`.\nIn the above representation, we use tuples to represent features.\nSo, the first document included features 0, 1, and 2 only.\nThis representation is known as the `Vector Space Model <http://en.wikipedia.org/wiki/Vector_space_model>`_.\n\nIf you\u2019re not familiar with the vector space model, we\u2019ll bridge the gap between raw strings, corpora and sparse vectors in the next tutorial on `tut1`.\nIf you\u2019re familiar with the vector space model, you\u2019ll probably know that the way you parse your documents and convert them to vectors has major impact on the quality of any subsequent applications.\n\nIn `gensim`, a :dfn:`corpus` is simply an object which, when iterated over, returns its documents represented as sparse vectors. In this case we\u2019re using a list of list of tuples.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>In this example, the whole corpus is stored in memory, as a Python list.\n  However, the corpus interface only dictates that a corpus must support\n  iteration over its constituent documents. For very large corpora, it is\n  advantageous to keep the corpus on disk, and access its documents\n  sequentially, one at a time. All the operations and transformations are\n  implemented in such a way that makes them independent of the size of the\n  corpus, memory-wise.</p></div>\n\nNext, let\u2019s import gensim and initialize a :dfn:`transformation`:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gensim import models\n\ntfidf = models.TfidfModel(corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A transformation is used to convert documents from one vector representation into another.\nHere, we used `Tf-Idf <http://en.wikipedia.org/wiki/Tf%E2%80%93idf>`_, a simple transformation which takes documents represented as bag-of-words counts and applies a weighting which discounts common terms (or, equivalently, promotes rare terms). It also scales the resulting vector to unit length (in the `Euclidean norm <http://en.wikipedia.org/wiki/Norm_%28mathematics%29#Euclidean_norm>`_).\n\nTransformations are covered in detail in the tutorial on Topics and Transformations.\n\nSo, given a new vector corresponding to another document (*not* in the original corpus), we can get its representation via Tf-Idf as:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "vec = [(0, 1), (4, 1)]\nprint(tfidf[vec])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To transform the whole corpus via TfIdf and index it, in preparation for similarity queries:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gensim import similarities\n\nindex = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and to query the similarity of our query vector vec against every document in the corpus:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sims = index[tfidf[vec]]\nprint(list(enumerate(sims)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "How to read this output? Document number zero (the first document) has a similarity score of 0.466=46.6%, the second document has a similarity score of 19.1% etc.\nWe can make this slightly more readable by sorting:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for document_number, score in sorted(enumerate(sims), key=lambda x: x[1], reverse=True):\n    print(document_number, score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Thus, according to TfIdf document representation and cosine similarity measure, the most similar to our query document vec is document no. 3, with a similarity score of 82.1%. Note that in the TfIdf representation, any documents which do not share any common features with vec at all (documents no. 4\u20138) get a similarity score of 0.0. See the Similarity Queries tutorial for more detail.\n\n.. [1] This is the same corpus as used in\n       `Deerwester et al. (1990): Indexing by Latent Semantic Analysis <http://www.cs.bham.ac.uk/~pxt/IDA/lsa_ind.pdf>`_, Table 2.\n\nReview\n------\nIn this tutorial, we took our first steps with gensim.\nWe created a toy corpus in the vector space representation and transformed it using Tf-Idf.\nFinally, for each document in the corpus, we measured its similarity with a query document.\n\nNext, read the tutorials on `tut1` and `tut2`.\nWe will also revisit document similarity in `tut3`.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
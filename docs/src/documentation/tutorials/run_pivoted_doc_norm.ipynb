{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nPivoted Document Length Normalization\n=====================================\n\nThis tutorial demonstrates using Pivoted Document Length Normalization to\ncounter the effect of short document bias when working with TfIdf, thereby\nincreasing the classification accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In many cases, normalizing the tfidf weights for each term favors weight of terms of the documents with shorter length. The *pivoted document length normalization* scheme counters the effect of this bias for short documents by making tfidf independent of the document length.\n\nThis is achieved by *tilting* the normalization curve along the pivot point defined by user with some slope.\n\nRoughly following the equation:\n\n``pivoted_norm = (1 - slope) * pivot + slope * old_norm``\n\nThis scheme is proposed in the paper `Pivoted Document Length Normalization <http://singhal.info/pivoted-dln.pdf>`_ by Singhal, Buckley and Mitra.\n\nOverall this approach can increase the accuracy of the model where the document lengths are hugely varying in the entire corpus.\n\nIntroduction\n------------\n\nThis guide demonstrates how to perform pivoted document length normalization.\n\nWe will train a logistic regression to distinguish between text from two different newsgroups.\n\nOur results will show that using pivoted document length normalization yields a better model (higher classification accuracy).\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#\n# Download our dataset\n#\nimport gensim.downloader as api\nnws = api.load(\"20-newsgroups\")\n\n#\n# Pick texts from relevant newsgroups, split into training and test set.\n#\ncat1, cat2 = ('sci.electronics', 'sci.space')\n\n#\n# X_* contain the actual texts as strings.\n# Y_* contain labels, 0 for cat1 (sci.electronics) and 1 for cat2 (sci.space)\n#\nX_train = []\nX_test = []\ny_train = []\ny_test = []\n\nfor i in nws:\n    if i[\"set\"] == \"train\" and i[\"topic\"] == cat1:\n        X_train.append(i[\"data\"])\n        y_train.append(0)\n    elif i[\"set\"] == \"train\" and i[\"topic\"] == cat2:\n        X_train.append(i[\"data\"])\n        y_train.append(1)\n    elif i[\"set\"] == \"test\" and i[\"topic\"] == cat1:\n        X_test.append(i[\"data\"])\n        y_test.append(0)\n    elif i[\"set\"] == \"test\" and i[\"topic\"] == cat2:\n        X_test.append(i[\"data\"])\n        y_test.append(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preprocess the data\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gensim.parsing.preprocessing import preprocess_string\nfrom gensim.corpora import Dictionary\n\nid2word = Dictionary([preprocess_string(doc) for doc in X_train])\ntrain_corpus = [id2word.doc2bow(preprocess_string(doc)) for doc in X_train]\ntest_corpus = [id2word.doc2bow(preprocess_string(doc)) for doc in X_test]\n\nprint(len(X_train), len(X_test))\n\n# We perform our analysis on top k documents which is almost top 10% most scored documents\nk = len(X_test) // 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare our evaluation function\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gensim.sklearn_api.tfidf import TfIdfTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom gensim.matutils import corpus2csc\n\n# This function returns the model accuracy and indivitual document prob values using\n# gensim's TfIdfTransformer and sklearn's LogisticRegression\ndef get_tfidf_scores(kwargs):\n    tfidf_transformer = TfIdfTransformer(**kwargs).fit(train_corpus)\n\n    X_train_tfidf = corpus2csc(tfidf_transformer.transform(train_corpus), num_terms=len(id2word)).T\n    X_test_tfidf = corpus2csc(tfidf_transformer.transform(test_corpus), num_terms=len(id2word)).T\n\n    clf = LogisticRegression().fit(X_train_tfidf, y_train)\n\n    model_accuracy = clf.score(X_test_tfidf, y_test)\n    doc_scores = clf.decision_function(X_test_tfidf)\n\n    return model_accuracy, doc_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get TFIDF scores for corpus without pivoted document length normalisation\n-------------------------------------------------------------------------\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "params = {}\nmodel_accuracy, doc_scores = get_tfidf_scores(params)\nprint(model_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Examine the bias towards shorter documents\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\n# Sort the document scores by their scores and return a sorted list\n# of document score and corresponding document lengths.\ndef sort_length_by_score(doc_scores, X_test):\n    doc_scores = sorted(enumerate(doc_scores), key=lambda x: x[1])\n    doc_leng = np.empty(len(doc_scores))\n\n    ds = np.empty(len(doc_scores))\n\n    for i, _ in enumerate(doc_scores):\n        doc_leng[i] = len(X_test[_[0]])\n        ds[i] = _[1]\n\n    return ds, doc_leng\n\n\nprint(\n   \"Normal cosine normalisation favors short documents as our top {} \"\n   \"docs have a smaller mean doc length of {:.3f} compared to the corpus mean doc length of {:.3f}\"\n   .format(\n       k, sort_length_by_score(doc_scores, X_test)[1][:k].mean(), \n       sort_length_by_score(doc_scores, X_test)[1].mean()\n   )\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get TFIDF scores for corpus with pivoted document length normalisation\n----------------------------------------------------------------------\n\nTest various values of alpha (slope) and pick the best one.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "best_model_accuracy = 0\noptimum_slope = 0\nfor slope in np.arange(0, 1.1, 0.1):\n    params = {\"pivot\": 10, \"slope\": slope}\n\n    model_accuracy, doc_scores = get_tfidf_scores(params)\n\n    if model_accuracy > best_model_accuracy:\n        best_model_accuracy = model_accuracy\n        optimum_slope = slope\n\n    print(\"Score for slope {} is {}\".format(slope, model_accuracy))\n\nprint(\"We get best score of {} at slope {}\".format(best_model_accuracy, optimum_slope))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate the model with optimum slope\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "params = {\"pivot\": 10, \"slope\": optimum_slope}\nmodel_accuracy, doc_scores = get_tfidf_scores(params)\nprint(model_accuracy)\n\nprint(\n   \"With pivoted normalisation top {} docs have mean length of {:.3f} \"\n   \"which is much closer to the corpus mean doc length of {:.3f}\"\n   .format(\n       k, sort_length_by_score(doc_scores, X_test)[1][:k].mean(), \n       sort_length_by_score(doc_scores, X_test)[1].mean()\n   )\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualizing the pivoted normalization\n-------------------------------------\n\nSince cosine normalization favors retrieval of short documents from the plot\nwe can see that when slope was 1 (when pivoted normalisation was not applied)\nshort documents with length of around 500 had very good score hence the bias\nfor short documents can be seen. As we varied the value of slope from 1 to 0\nwe introdcued a new bias for long documents to counter the bias caused by\ncosine normalisation. Therefore at a certain point we got an optimum value of\nslope which is 0.5 where the overall accuracy of the model is increased.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as py\n\nbest_model_accuracy = 0\noptimum_slope = 0\n\nw = 2\nh = 2\nf, axarr = py.subplots(h, w, figsize=(15, 7))\n\nit = 0\nfor slope in [1, 0.2]:\n    params = {\"pivot\": 10, \"slope\": slope}\n\n    model_accuracy, doc_scores = get_tfidf_scores(params)\n\n    if model_accuracy > best_model_accuracy:\n        best_model_accuracy = model_accuracy\n        optimum_slope = slope\n\n    doc_scores, doc_leng = sort_length_by_score(doc_scores, X_test)\n\n    y = abs(doc_scores[:k, np.newaxis])\n    x = doc_leng[:k, np.newaxis]\n\n    py.subplot(1, 2, it+1).bar(x, y, width=20, linewidth=0)\n    py.title(\"slope = \" + str(slope) + \" Model accuracy = \" + str(model_accuracy))\n    py.ylim([0, 4.5])\n    py.xlim([0, 3200])\n    py.xlabel(\"document length\")\n    py.ylabel(\"confidence score\")\n    \n    it += 1\n\npy.tight_layout()\npy.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The above histogram plot helps us visualize the effect of ``slope``. For top\nk documents we have document length on the x axis and their respective scores\nof belonging to a specific class on y axis.  \n\nAs we decrease the slope the density of bins is shifted from low document\nlength (around ~250-500) to over ~500 document length. This suggests that the\npositive biasness which was seen at ``slope=1`` (or when regular tfidf was\nused) for short documents is now reduced. We get the optimum slope or the max\nmodel accuracy when slope is 0.2.\n\nConclusion\n==========\n\nUsing pivoted document normalization improved the classification accuracy significantly:\n\n* Before (slope=1, identical to default cosine normalization): 0.9682\n* After (slope=0.2): 0.9771\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Corpora and Vector Spaces &mdash; gensim documentation</title>
    <link rel="stylesheet" href="_static/default.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '#',
        VERSION:     '0.4.7',
        COLLAPSE_MODINDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="top" title="gensim documentation" href="index.html" />
    <link rel="up" title="Tutorial" href="tutorial.html" />
    <link rel="next" title="Topics and Transformations" href="tut2.html" />
    <link rel="prev" title="Tutorial" href="tutorial.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="modindex.html" title="Global Module Index"
             accesskey="M">modules</a> |</li>
        <li class="right" >
          <a href="tut2.html" title="Topics and Transformations"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="tutorial.html" title="Tutorial"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">gensim documentation</a> &raquo;</li>
          <li><a href="tutorial.html" accesskey="U">Tutorial</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="corpora-and-vector-spaces">
<span id="tut1"></span><h1>Corpora and Vector Spaces<a class="headerlink" href="#corpora-and-vector-spaces" title="Permalink to this headline">¶</a></h1>
<p>Don&#8217;t forget to set</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">logging</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logging</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span> <span class="c"># will suppress DEBUG level events</span>
</pre></div>
</div>
<p>if you want to see logging events.</p>
<div class="section" id="from-strings-to-vectors">
<span id="second-example"></span><h2>From Strings to Vectors<a class="headerlink" href="#from-strings-to-vectors" title="Permalink to this headline">¶</a></h2>
<p>This time, let&#8217;s start from documents represented as strings:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">gensim</span> <span class="kn">import</span> <span class="n">corpora</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="n">similarities</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">documents</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;Human machine interface for lab abc computer applications&quot;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>             <span class="s">&quot;A survey of user opinion of computer system response time&quot;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>             <span class="s">&quot;The EPS user interface management system&quot;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>             <span class="s">&quot;System and human system engineering testing of EPS&quot;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>             <span class="s">&quot;Relation of user perceived response time to error measurement&quot;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>             <span class="s">&quot;The generation of random binary unordered trees&quot;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>             <span class="s">&quot;The intersection graph of paths in trees&quot;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>             <span class="s">&quot;Graph minors IV Widths of trees and well quasi ordering&quot;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>             <span class="s">&quot;Graph minors A survey&quot;</span><span class="p">]</span>
</pre></div>
</div>
<p>This is a tiny corpus of nine documents, each consisting of only a single sentence.</p>
<p>First, let&#8217;s tokenize the documents, remove common words (using a toy stoplist)
as well as words that only appear once in the corpus:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="c"># remove common words and tokenize</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stoplist</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="s">&#39;for a of the and to in&#39;</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">texts</span> <span class="o">=</span> <span class="p">[[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">document</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stoplist</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span>         <span class="k">for</span> <span class="n">document</span> <span class="ow">in</span> <span class="n">documents</span><span class="p">]</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c"># remove words that appear only once</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">allTokens</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="p">[])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokensOnce</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">allTokens</span><span class="p">)</span> <span class="k">if</span> <span class="n">allTokens</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">texts</span> <span class="o">=</span> <span class="p">[[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">text</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">tokensOnce</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span>         <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">]</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">texts</span>
<span class="go">[[&#39;human&#39;, &#39;interface&#39;, &#39;computer&#39;],</span>
<span class="go"> [&#39;survey&#39;, &#39;user&#39;, &#39;computer&#39;, &#39;system&#39;, &#39;response&#39;, &#39;time&#39;],</span>
<span class="go"> [&#39;eps&#39;, &#39;user&#39;, &#39;interface&#39;, &#39;system&#39;],</span>
<span class="go"> [&#39;system&#39;, &#39;human&#39;, &#39;system&#39;, &#39;eps&#39;],</span>
<span class="go"> [&#39;user&#39;, &#39;response&#39;, &#39;time&#39;],</span>
<span class="go"> [&#39;trees&#39;],</span>
<span class="go"> [&#39;graph&#39;, &#39;trees&#39;],</span>
<span class="go"> [&#39;graph&#39;, &#39;minors&#39;, &#39;trees&#39;],</span>
<span class="go"> [&#39;graph&#39;, &#39;minors&#39;, &#39;survey&#39;]]</span>
</pre></div>
</div>
<p>Your way of processing the documents will likely vary; here, we only split on whitespace
to tokenize, followed by lowercasing each word. In fact, we use this particular
(simplistic and inefficient) setup to mimick the experiment done in Deerwester et al.&#8217;s
original LSA article <a class="footnote-reference" href="#id3" id="id1">[1]</a>.</p>
<p>The ways to process documents are so varied and application- and language-dependent that we
decided to <em>not</em> constrain them by any interface. Instead, a document is represented
by the features extracted from it, not by its &#8220;surface&#8221; string form: how you get to
the features is up to you. Below we describe one common, general-purpose approach (called
<em>bag-of-words</em>), but keep in mind that different application domains call for
different features, and, as always, it&#8217;s <a class="reference external" href="http://en.wikipedia.org/wiki/Garbage_In,_Garbage_Out">garbage in, garbage out</a>...</p>
<p>To convert documents to vectors, we will use a document representation called
<a class="reference external" href="http://en.wikipedia.org/wiki/Bag_of_words">bag-of-words</a>. In this representation,
each document is represented by one vector where each vector element represents
a question-answer pair, in the style of:</p>
<blockquote>
&#8220;How many times does the word <cite>system</cite> appear in the document? Once.&#8221;</blockquote>
<p>It is advantageous to represent the questions only by their (integer) ids. The mapping
between the questions and ids is called a dictionary:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">dictionary</span> <span class="o">=</span> <span class="n">corpora</span><span class="o">.</span><span class="n">Dictionary</span><span class="o">.</span><span class="n">fromDocuments</span><span class="p">(</span><span class="n">texts</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dictionary</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s">&#39;/tmp/dictionary.pkl&#39;</span><span class="p">)</span> <span class="c"># store the dictionary, for future reference</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">dictionary</span>
<span class="go">Dictionary(12 unique tokens)</span>
</pre></div>
</div>
<p>Here we assigned a unique integer id to all words appearing in the corpus by calling
<tt class="xref docutils literal"><span class="pre">Dictionary.fromDocuments()</span></tt>. This sweeps across the texts, collecting words
and relevant statistics. In the end, we see there are twelve distinct words in the
processed corpus, which means each document will be represented by twelve numbers (ie., by a 12-D vector).
To see the mapping between words and their ids:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">token2id</span>
<span class="go">{&#39;minors&#39;: 11, &#39;graph&#39;: 10, &#39;system&#39;: 5, &#39;trees&#39;: 9, &#39;eps&#39;: 8, &#39;computer&#39;: 0,</span>
<span class="go">&#39;survey&#39;: 4, &#39;user&#39;: 7, &#39;human&#39;: 1, &#39;time&#39;: 6, &#39;interface&#39;: 2, &#39;response&#39;: 3}</span>
</pre></div>
</div>
<p>To actually convert tokenized documents to vectors:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">newDoc</span> <span class="o">=</span> <span class="s">&quot;Human computer interaction&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">newVec</span> <span class="o">=</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">newDoc</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">newVec</span> <span class="c"># the word &quot;interaction&quot; does not appear in the dictionary and is ignored</span>
<span class="go">[(0, 1), (1, 1)]</span>
</pre></div>
</div>
<p>The function <tt class="xref docutils literal"><span class="pre">doc2bow()</span></tt> simply counts the number of occurences of
each distinct word, converts the word to its integer word id
and returns the result as a sparse vector. The sparse vector <tt class="docutils literal"><span class="pre">[(0,</span> <span class="pre">1),</span> <span class="pre">(1,</span> <span class="pre">1)]</span></tt>
therefore reads: in the document <cite>&#8220;Human computer interaction&#8221;</cite>, the words <cite>computer</cite>
(id 0) and <cite>human</cite> (id 1) appear once; the other ten dictionary words appear (implicitly) zero times.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">dictionary</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corpora</span><span class="o">.</span><span class="n">MmCorpus</span><span class="o">.</span><span class="n">saveCorpus</span><span class="p">(</span><span class="s">&#39;/tmp/deerwester.mm&#39;</span><span class="p">,</span> <span class="n">corpus</span><span class="p">)</span> <span class="c"># store to disk, for later use</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">corpus</span>
<span class="go">[[(0, 1.0), (1, 1.0), (2, 1.0)],</span>
<span class="go"> [(2, 1.0), (3, 1.0), (4, 1.0), (5, 1.0), (6, 1.0), (8, 1.0)],</span>
<span class="go"> [(1, 1.0), (3, 1.0), (4, 1.0), (7, 1.0)],</span>
<span class="go"> [(0, 1.0), (4, 2.0), (7, 1.0)],</span>
<span class="go"> [(3, 1.0), (5, 1.0), (6, 1.0)],</span>
<span class="go"> [(9, 1.0)],</span>
<span class="go"> [(9, 1.0), (10, 1.0)],</span>
<span class="go"> [(9, 1.0), (10, 1.0), (11, 1.0)],</span>
<span class="go"> [(8, 1.0), (10, 1.0), (11, 1.0)]]</span>
</pre></div>
</div>
<p>By now it should be clear that the vector feature with <tt class="docutils literal"><span class="pre">id=10</span></tt> stands for the question &#8220;How many
times does the word <cite>graph</cite> appear in the document?&#8221; and that the answer is &#8220;zero&#8221; for
the first six documents and &#8220;one&#8221; for the remaining three. As a matter of fact,
we have arrived at exactly the same corpus of vectors as in the <a class="reference external" href="tutorial.html#first-example"><em>Quick Example</em></a>.</p>
<p>And that is all there is to it! At least as far as bag-of-words representation is concerned.
Of course, what we do with such corpus is another question; it is not at all clear
how counting the frequency of distinct words could be useful. As it turns out, it isn&#8217;t, and
we will need to apply a transformation on this simple representation first, before
we can use it to compute any meaningful document vs. document similarities.
Transformations are covered in the <a class="reference external" href="tut2.html"><em>next tutorial</em></a>, but before that, let&#8217;s
briefly turn our attention to <em>corpus persistency</em>.</p>
</div>
<div class="section" id="corpus-formats">
<span id="id2"></span><h2>Corpus Formats<a class="headerlink" href="#corpus-formats" title="Permalink to this headline">¶</a></h2>
<p>There exist several file formats for storing a Vector Space corpus (~sequence of vectors) to disk.
<cite>Gensim</cite> implements them via the <em>streaming corpus interface</em> mentioned earlier:
documents are read from disk in a lazy fashion, one document at a time, without the whole
corpus being read into main memory at once.</p>
<p>One of the more notable formats is the <a class="reference external" href="http://math.nist.gov/MatrixMarket/formats.html">Market Matrix format</a>.
To save a corpus in the Matrix Market format:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">gensim</span> <span class="kn">import</span> <span class="n">corpora</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corpus</span> <span class="o">=</span> <span class="p">[[(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)],</span> <span class="p">[]]</span> <span class="c"># create a toy corpus of 2 documents (one of them empty, for the heck of it)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corpora</span><span class="o">.</span><span class="n">MmCorpus</span><span class="o">.</span><span class="n">saveCorpus</span><span class="p">(</span><span class="s">&#39;/tmp/corpus.mm&#39;</span><span class="p">,</span> <span class="n">corpus</span><span class="p">)</span>
</pre></div>
</div>
<p>Other formats include <a class="reference external" href="svmlight.joachims.org/">Joachim&#8217;s SVMlight format</a>,
<a class="reference external" href="www.cs.princeton.edu/~blei/lda-c/">Blei&#8217;s LDA-C format</a> and
<a class="reference external" href="http://gibbslda.sourceforge.net/">GibbsLDA++ format</a>.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">corpora</span><span class="o">.</span><span class="n">SvmLightCorpus</span><span class="o">.</span><span class="n">saveCorpus</span><span class="p">(</span><span class="s">&#39;/tmp/corpus.svmlight&#39;</span><span class="p">,</span> <span class="n">corpus</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corpora</span><span class="o">.</span><span class="n">BleiCorpus</span><span class="o">.</span><span class="n">saveCorpus</span><span class="p">(</span><span class="s">&#39;/tmp/corpus.lda-c&#39;</span><span class="p">,</span> <span class="n">corpus</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corpora</span><span class="o">.</span><span class="n">LowCorpus</span><span class="o">.</span><span class="n">saveCorpus</span><span class="p">(</span><span class="s">&#39;/tmp/corpus.low&#39;</span><span class="p">,</span> <span class="n">corpus</span><span class="p">)</span>
</pre></div>
</div>
<p>Conversely, to load a corpus iterator from a Matrix Market file:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">corpus</span> <span class="o">=</span> <span class="n">corpora</span><span class="o">.</span><span class="n">MmCorpus</span><span class="p">(</span><span class="s">&#39;/tmp/corpus.mm&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Corpus objects are streams, so typically you won&#8217;t be able to print them directly:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">corpus</span>
<span class="go">MmCorpus(2 documents, 2 features, 1 non-zero entries)</span>
</pre></div>
</div>
<p>Instead, to view the contents of a corpus:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="c"># one way of printing a corpus: load it entirely into memory</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="nb">list</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span> <span class="c"># calling list() will convert any sequence to a plain Python list</span>
<span class="go">[[(1, 0.5)], []]</span>
</pre></div>
</div>
<p>or</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="c"># another way of doing it: print one document at a time, making use of the streaming interface</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">print</span> <span class="n">doc</span>
<span class="go">[(1, 0.5)]</span>
<span class="go">[]</span>
</pre></div>
</div>
<p>The second way is obviously more memory-friendly, but for testing and development
purposes, nothing beats the simplicity of calling <tt class="docutils literal"><span class="pre">list(corpus)</span></tt>.</p>
<p>To save the same corpus in Blei&#8217;s LDA-C format,</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">corpora</span><span class="o">.</span><span class="n">BleiCorpus</span><span class="o">.</span><span class="n">saveCorpus</span><span class="p">(</span><span class="s">&#39;/tmp/corpus.lda-c&#39;</span><span class="p">,</span> <span class="n">corpus</span><span class="p">)</span>
</pre></div>
</div>
<p>In this way, <cite>gensim</cite> can also be used as a simple <strong>I/O format conversion tool</strong>:
just load a document stream using one format and immediately save it in another format.</p>
<p>For a complete reference, see the <a class="reference external" href="apiref.html"><em>API documentation</em></a>. Or continue
to the next tutorial on <a class="reference external" href="tut2.html"><em>Topics and Transformations</em></a>.</p>
<hr class="docutils" />
<table class="docutils footnote" frame="void" id="id3" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[1]</a></td><td>This is the same corpus as used in
<a class="reference external" href="http://www.cs.bham.ac.uk/~pxt/IDA/lsa_ind.pdf">Deerwester et al. (1990): Indexing by Latent Semantic Analysis</a>, Table 2.</td></tr>
</tbody>
</table>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <h3><a href="index.html">Table Of Contents</a></h3>
            <ul>
<li><a class="reference external" href="#">Corpora and Vector Spaces</a><ul>
<li><a class="reference external" href="#from-strings-to-vectors">From Strings to Vectors</a></li>
<li><a class="reference external" href="#corpus-formats">Corpus Formats</a></li>
</ul>
</li>
</ul>

            <h4>Previous topic</h4>
            <p class="topless"><a href="tutorial.html"
                                  title="previous chapter">Tutorial</a></p>
            <h4>Next topic</h4>
            <p class="topless"><a href="tut2.html"
                                  title="next chapter">Topics and Transformations</a></p>
          <div id="searchbox" style="display: none">
            <h3>Quick search</h3>
              <form class="search" action="search.html" method="get">
                <input type="text" name="q" size="18" />
                <input type="submit" value="Go" />
                <input type="hidden" name="check_keywords" value="yes" />
                <input type="hidden" name="area" value="default" />
              </form>
              <p class="searchtip" style="font-size: 90%">
              Enter search terms or a module, class or function name.
              </p>
          </div>
          <script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="modindex.html" title="Global Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="tut2.html" title="Topics and Transformations"
             >next</a> |</li>
        <li class="right" >
          <a href="tutorial.html" title="Tutorial"
             >previous</a> |</li>
        <li><a href="index.html">gensim documentation</a> &raquo;</li>
          <li><a href="tutorial.html" >Tutorial</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
      &copy; Copyright 2010, Radim Řehůřek.
    </div>
  </body>
</html>